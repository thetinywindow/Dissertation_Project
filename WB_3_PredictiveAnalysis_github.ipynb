{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WB3 - Predictive Analysis\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing packages\n",
    "\n",
    "#############################\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "#import sweetviz\n",
    "\n",
    "#pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "The third and most extensive workbook (WB3) contains the predictive model building (supervised learning classifier). Refer to WB1 for detailed insights in the data cleaning process, and WB2 for the descriptive insights gathered to this point. The analysis performed in this workbook build on top of the previously seen and conducted analysis.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8942, 248)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3072: DtypeWarning:\n",
      "\n",
      "Columns (146) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "\n",
    "############################# Cleaned Data #############################\n",
    "#load questions only\n",
    "df_pred = pd.read_csv('/project/DATA/Kaggle_Survey/Data_Cleaning/CLEANED_prediction.csv')\n",
    "print(df_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time from Start to Finish (seconds)</th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q2_OTHER_TEXT</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q5_OTHER_TEXT</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q7</th>\n",
       "      <th>Q8</th>\n",
       "      <th>Q9_Part_1</th>\n",
       "      <th>Q9_Part_2</th>\n",
       "      <th>Q9_Part_3</th>\n",
       "      <th>Q9_Part_4</th>\n",
       "      <th>Q9_Part_5</th>\n",
       "      <th>Q9_Part_6</th>\n",
       "      <th>Q9_Part_7</th>\n",
       "      <th>Q9_Part_8</th>\n",
       "      <th>Q9_OTHER_TEXT</th>\n",
       "      <th>Q10</th>\n",
       "      <th>Q11</th>\n",
       "      <th>Q12_Part_1</th>\n",
       "      <th>Q12_Part_2</th>\n",
       "      <th>Q12_Part_3</th>\n",
       "      <th>Q12_Part_4</th>\n",
       "      <th>Q12_Part_5</th>\n",
       "      <th>Q12_Part_6</th>\n",
       "      <th>Q12_Part_7</th>\n",
       "      <th>Q12_Part_8</th>\n",
       "      <th>Q12_Part_9</th>\n",
       "      <th>Q12_Part_10</th>\n",
       "      <th>Q12_Part_11</th>\n",
       "      <th>Q12_Part_12</th>\n",
       "      <th>Q12_OTHER_TEXT</th>\n",
       "      <th>Q13_Part_1</th>\n",
       "      <th>Q13_Part_2</th>\n",
       "      <th>Q13_Part_3</th>\n",
       "      <th>Q13_Part_4</th>\n",
       "      <th>Q13_Part_5</th>\n",
       "      <th>Q13_Part_6</th>\n",
       "      <th>Q13_Part_7</th>\n",
       "      <th>Q13_Part_8</th>\n",
       "      <th>Q13_Part_9</th>\n",
       "      <th>Q13_Part_10</th>\n",
       "      <th>Q13_Part_11</th>\n",
       "      <th>Q13_Part_12</th>\n",
       "      <th>Q13_OTHER_TEXT</th>\n",
       "      <th>Q14</th>\n",
       "      <th>Q14_Part_1_TEXT</th>\n",
       "      <th>Q14_Part_2_TEXT</th>\n",
       "      <th>Q14_Part_3_TEXT</th>\n",
       "      <th>Q14_Part_4_TEXT</th>\n",
       "      <th>Q14_Part_5_TEXT</th>\n",
       "      <th>Q14_OTHER_TEXT</th>\n",
       "      <th>Q15</th>\n",
       "      <th>Q16_Part_1</th>\n",
       "      <th>Q16_Part_2</th>\n",
       "      <th>Q16_Part_3</th>\n",
       "      <th>Q16_Part_4</th>\n",
       "      <th>Q16_Part_5</th>\n",
       "      <th>Q16_Part_6</th>\n",
       "      <th>Q16_Part_7</th>\n",
       "      <th>Q16_Part_8</th>\n",
       "      <th>Q16_Part_9</th>\n",
       "      <th>Q16_Part_10</th>\n",
       "      <th>Q16_Part_11</th>\n",
       "      <th>Q16_Part_12</th>\n",
       "      <th>Q16_OTHER_TEXT</th>\n",
       "      <th>Q17_Part_1</th>\n",
       "      <th>Q17_Part_2</th>\n",
       "      <th>Q17_Part_3</th>\n",
       "      <th>Q17_Part_4</th>\n",
       "      <th>Q17_Part_5</th>\n",
       "      <th>Q17_Part_6</th>\n",
       "      <th>Q17_Part_7</th>\n",
       "      <th>Q17_Part_8</th>\n",
       "      <th>Q17_Part_9</th>\n",
       "      <th>Q17_Part_10</th>\n",
       "      <th>Q17_Part_11</th>\n",
       "      <th>Q17_Part_12</th>\n",
       "      <th>Q17_OTHER_TEXT</th>\n",
       "      <th>Q18_Part_1</th>\n",
       "      <th>Q18_Part_2</th>\n",
       "      <th>Q18_Part_3</th>\n",
       "      <th>Q18_Part_4</th>\n",
       "      <th>Q18_Part_5</th>\n",
       "      <th>Q18_Part_6</th>\n",
       "      <th>Q18_Part_7</th>\n",
       "      <th>Q18_Part_8</th>\n",
       "      <th>Q18_Part_9</th>\n",
       "      <th>Q18_Part_10</th>\n",
       "      <th>Q18_Part_11</th>\n",
       "      <th>Q18_Part_12</th>\n",
       "      <th>Q18_OTHER_TEXT</th>\n",
       "      <th>Q19</th>\n",
       "      <th>Q19_OTHER_TEXT</th>\n",
       "      <th>Q20_Part_1</th>\n",
       "      <th>Q20_Part_2</th>\n",
       "      <th>Q20_Part_3</th>\n",
       "      <th>Q20_Part_4</th>\n",
       "      <th>Q20_Part_5</th>\n",
       "      <th>Q20_Part_6</th>\n",
       "      <th>Q20_Part_7</th>\n",
       "      <th>Q20_Part_8</th>\n",
       "      <th>Q20_Part_9</th>\n",
       "      <th>Q20_Part_10</th>\n",
       "      <th>Q20_Part_11</th>\n",
       "      <th>Q20_Part_12</th>\n",
       "      <th>Q20_OTHER_TEXT</th>\n",
       "      <th>Q21_Part_1</th>\n",
       "      <th>Q21_Part_2</th>\n",
       "      <th>Q21_Part_3</th>\n",
       "      <th>Q21_Part_4</th>\n",
       "      <th>Q21_Part_5</th>\n",
       "      <th>Q21_OTHER_TEXT</th>\n",
       "      <th>Q22</th>\n",
       "      <th>Q23</th>\n",
       "      <th>Q24_Part_1</th>\n",
       "      <th>Q24_Part_2</th>\n",
       "      <th>Q24_Part_3</th>\n",
       "      <th>Q24_Part_4</th>\n",
       "      <th>Q24_Part_5</th>\n",
       "      <th>Q24_Part_6</th>\n",
       "      <th>Q24_Part_7</th>\n",
       "      <th>Q24_Part_8</th>\n",
       "      <th>Q24_Part_9</th>\n",
       "      <th>Q24_Part_10</th>\n",
       "      <th>Q24_Part_11</th>\n",
       "      <th>Q24_Part_12</th>\n",
       "      <th>Q24_OTHER_TEXT</th>\n",
       "      <th>Q25_Part_1</th>\n",
       "      <th>Q25_Part_2</th>\n",
       "      <th>Q25_Part_3</th>\n",
       "      <th>Q25_Part_4</th>\n",
       "      <th>Q25_Part_5</th>\n",
       "      <th>Q25_Part_6</th>\n",
       "      <th>Q25_Part_7</th>\n",
       "      <th>Q25_Part_8</th>\n",
       "      <th>Q25_OTHER_TEXT</th>\n",
       "      <th>Q26_Part_1</th>\n",
       "      <th>Q26_Part_2</th>\n",
       "      <th>Q26_Part_3</th>\n",
       "      <th>Q26_Part_4</th>\n",
       "      <th>Q26_Part_5</th>\n",
       "      <th>Q26_Part_6</th>\n",
       "      <th>Q26_Part_7</th>\n",
       "      <th>Q26_OTHER_TEXT</th>\n",
       "      <th>Q27_Part_1</th>\n",
       "      <th>Q27_Part_2</th>\n",
       "      <th>Q27_Part_3</th>\n",
       "      <th>Q27_Part_4</th>\n",
       "      <th>Q27_Part_5</th>\n",
       "      <th>Q27_Part_6</th>\n",
       "      <th>Q27_OTHER_TEXT</th>\n",
       "      <th>Q28_Part_1</th>\n",
       "      <th>Q28_Part_2</th>\n",
       "      <th>Q28_Part_3</th>\n",
       "      <th>Q28_Part_4</th>\n",
       "      <th>Q28_Part_5</th>\n",
       "      <th>Q28_Part_6</th>\n",
       "      <th>Q28_Part_7</th>\n",
       "      <th>Q28_Part_8</th>\n",
       "      <th>Q28_Part_9</th>\n",
       "      <th>Q28_Part_10</th>\n",
       "      <th>Q28_Part_11</th>\n",
       "      <th>Q28_Part_12</th>\n",
       "      <th>Q28_OTHER_TEXT</th>\n",
       "      <th>Q29_Part_1</th>\n",
       "      <th>Q29_Part_2</th>\n",
       "      <th>Q29_Part_3</th>\n",
       "      <th>Q29_Part_4</th>\n",
       "      <th>Q29_Part_5</th>\n",
       "      <th>Q29_Part_6</th>\n",
       "      <th>Q29_Part_7</th>\n",
       "      <th>Q29_Part_8</th>\n",
       "      <th>Q29_Part_9</th>\n",
       "      <th>Q29_Part_10</th>\n",
       "      <th>Q29_Part_11</th>\n",
       "      <th>Q29_Part_12</th>\n",
       "      <th>Q29_OTHER_TEXT</th>\n",
       "      <th>Q30_Part_1</th>\n",
       "      <th>Q30_Part_2</th>\n",
       "      <th>Q30_Part_3</th>\n",
       "      <th>Q30_Part_4</th>\n",
       "      <th>Q30_Part_5</th>\n",
       "      <th>Q30_Part_6</th>\n",
       "      <th>Q30_Part_7</th>\n",
       "      <th>Q30_Part_8</th>\n",
       "      <th>Q30_Part_9</th>\n",
       "      <th>Q30_Part_10</th>\n",
       "      <th>Q30_Part_11</th>\n",
       "      <th>Q30_Part_12</th>\n",
       "      <th>Q30_OTHER_TEXT</th>\n",
       "      <th>Q31_Part_1</th>\n",
       "      <th>Q31_Part_2</th>\n",
       "      <th>Q31_Part_3</th>\n",
       "      <th>Q31_Part_4</th>\n",
       "      <th>Q31_Part_5</th>\n",
       "      <th>Q31_Part_6</th>\n",
       "      <th>Q31_Part_7</th>\n",
       "      <th>Q31_Part_8</th>\n",
       "      <th>Q31_Part_9</th>\n",
       "      <th>Q31_Part_10</th>\n",
       "      <th>Q31_Part_11</th>\n",
       "      <th>Q31_Part_12</th>\n",
       "      <th>Q31_OTHER_TEXT</th>\n",
       "      <th>Q32_Part_1</th>\n",
       "      <th>Q32_Part_2</th>\n",
       "      <th>Q32_Part_3</th>\n",
       "      <th>Q32_Part_4</th>\n",
       "      <th>Q32_Part_5</th>\n",
       "      <th>Q32_Part_6</th>\n",
       "      <th>Q32_Part_7</th>\n",
       "      <th>Q32_Part_8</th>\n",
       "      <th>Q32_Part_9</th>\n",
       "      <th>Q32_Part_10</th>\n",
       "      <th>Q32_Part_11</th>\n",
       "      <th>Q32_Part_12</th>\n",
       "      <th>Q32_OTHER_TEXT</th>\n",
       "      <th>Q33_Part_1</th>\n",
       "      <th>Q33_Part_2</th>\n",
       "      <th>Q33_Part_3</th>\n",
       "      <th>Q33_Part_4</th>\n",
       "      <th>Q33_Part_5</th>\n",
       "      <th>Q33_Part_6</th>\n",
       "      <th>Q33_Part_7</th>\n",
       "      <th>Q33_Part_8</th>\n",
       "      <th>Q33_Part_9</th>\n",
       "      <th>Q33_Part_10</th>\n",
       "      <th>Q33_Part_11</th>\n",
       "      <th>Q33_Part_12</th>\n",
       "      <th>Q33_OTHER_TEXT</th>\n",
       "      <th>Q34_Part_1</th>\n",
       "      <th>Q34_Part_2</th>\n",
       "      <th>Q34_Part_3</th>\n",
       "      <th>Q34_Part_4</th>\n",
       "      <th>Q34_Part_5</th>\n",
       "      <th>Q34_Part_6</th>\n",
       "      <th>Q34_Part_7</th>\n",
       "      <th>Q34_Part_8</th>\n",
       "      <th>Q34_Part_9</th>\n",
       "      <th>Q34_Part_10</th>\n",
       "      <th>Q34_Part_11</th>\n",
       "      <th>Q34_Part_12</th>\n",
       "      <th>Q34_OTHER_TEXT</th>\n",
       "      <th>valid_response</th>\n",
       "      <th>yearly_comp_numerical</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>510</td>\n",
       "      <td>22-24</td>\n",
       "      <td>Male</td>\n",
       "      <td>-1</td>\n",
       "      <td>France</td>\n",
       "      <td>Master’s degree</td>\n",
       "      <td>Data/Software Engineer</td>\n",
       "      <td>-1</td>\n",
       "      <td>1000-9,999 employees</td>\n",
       "      <td>0</td>\n",
       "      <td>I do not know</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>30,000-39,999</td>\n",
       "      <td>$0 (USD)</td>\n",
       "      <td>Twitter (data science influencers)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kaggle (forums, blog, social media, etc)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Blogs (Towards Data Science, Medium, Analytics...</td>\n",
       "      <td>Journal Publications (traditional publications...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Coursera</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DataCamp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kaggle Courses (i.e. Kaggle Learn)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Udemy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>Basic statistical software (Microsoft Excel, G...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1-2 years</td>\n",
       "      <td>Jupyter (JupyterLab, Jupyter Notebooks, etc)</td>\n",
       "      <td>RStudio</td>\n",
       "      <td>PyCharm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MATLAB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Spyder</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>Python</td>\n",
       "      <td>R</td>\n",
       "      <td>SQL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Java</td>\n",
       "      <td>Javascript</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MATLAB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>Python</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Matplotlib</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>CPUs</td>\n",
       "      <td>GPUs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>Never</td>\n",
       "      <td>1-2 years</td>\n",
       "      <td>Linear or Logistic Regression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>34999.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time from Start to Finish (seconds)     Q1    Q2  Q2_OTHER_TEXT      Q3               Q4                      Q5  Q5_OTHER_TEXT                    Q6 Q7             Q8 Q9_Part_1 Q9_Part_2 Q9_Part_3 Q9_Part_4 Q9_Part_5 Q9_Part_6 Q9_Part_7 Q9_Part_8  Q9_OTHER_TEXT            Q10       Q11                          Q12_Part_1 Q12_Part_2 Q12_Part_3                                Q12_Part_4 Q12_Part_5 Q12_Part_6 Q12_Part_7                                         Q12_Part_8                                         Q12_Part_9 Q12_Part_10 Q12_Part_11 Q12_Part_12  Q12_OTHER_TEXT Q13_Part_1 Q13_Part_2 Q13_Part_3 Q13_Part_4 Q13_Part_5                          Q13_Part_6 Q13_Part_7 Q13_Part_8 Q13_Part_9 Q13_Part_10 Q13_Part_11 Q13_Part_12  Q13_OTHER_TEXT                                                Q14  Q14_Part_1_TEXT  Q14_Part_2_TEXT  Q14_Part_3_TEXT  Q14_Part_4_TEXT  Q14_Part_5_TEXT  Q14_OTHER_TEXT        Q15                                     Q16_Part_1 Q16_Part_2 Q16_Part_3 Q16_Part_4  \\\n",
       "0                                  510  22-24  Male             -1  France  Master’s degree  Data/Software Engineer             -1  1000-9,999 employees  0  I do not know       NaN       NaN       NaN       NaN       NaN       NaN       NaN       NaN             -1  30,000-39,999  $0 (USD)  Twitter (data science influencers)        NaN        NaN  Kaggle (forums, blog, social media, etc)        NaN        NaN        NaN  Blogs (Towards Data Science, Medium, Analytics...  Journal Publications (traditional publications...         NaN         NaN         NaN              -1        NaN   Coursera        NaN   DataCamp        NaN  Kaggle Courses (i.e. Kaggle Learn)        NaN      Udemy        NaN         NaN         NaN         NaN              -1  Basic statistical software (Microsoft Excel, G...                0               -1               -1               -1               -1              -1  1-2 years  Jupyter (JupyterLab, Jupyter Notebooks, etc)    RStudio    PyCharm         NaN   \n",
       "\n",
       "  Q16_Part_5 Q16_Part_6  Q16_Part_7 Q16_Part_8 Q16_Part_9 Q16_Part_10 Q16_Part_11 Q16_Part_12  Q16_OTHER_TEXT Q17_Part_1 Q17_Part_2 Q17_Part_3 Q17_Part_4 Q17_Part_5 Q17_Part_6 Q17_Part_7 Q17_Part_8 Q17_Part_9 Q17_Part_10 Q17_Part_11 Q17_Part_12  Q17_OTHER_TEXT Q18_Part_1 Q18_Part_2 Q18_Part_3 Q18_Part_4 Q18_Part_5 Q18_Part_6  Q18_Part_7 Q18_Part_8 Q18_Part_9 Q18_Part_10 Q18_Part_11 Q18_Part_12  Q18_OTHER_TEXT     Q19  Q19_OTHER_TEXT Q20_Part_1    Q20_Part_2 Q20_Part_3 Q20_Part_4 Q20_Part_5 Q20_Part_6 Q20_Part_7 Q20_Part_8 Q20_Part_9 Q20_Part_10 Q20_Part_11 Q20_Part_12  Q20_OTHER_TEXT Q21_Part_1 Q21_Part_2 Q21_Part_3 Q21_Part_4 Q21_Part_5  Q21_OTHER_TEXT    Q22        Q23                     Q24_Part_1 Q24_Part_2 Q24_Part_3 Q24_Part_4 Q24_Part_5 Q24_Part_6 Q24_Part_7 Q24_Part_8 Q24_Part_9 Q24_Part_10 Q24_Part_11 Q24_Part_12  Q24_OTHER_TEXT Q25_Part_1 Q25_Part_2 Q25_Part_3 Q25_Part_4 Q25_Part_5 Q25_Part_6 Q25_Part_7 Q25_Part_8  Q25_OTHER_TEXT Q26_Part_1 Q26_Part_2 Q26_Part_3  \\\n",
       "0    MATLAB         NaN    Spyder          NaN        NaN         NaN         NaN         NaN              -1        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN         NaN        None         NaN              -1     Python          R        SQL        NaN        NaN       Java  Javascript        NaN        NaN      MATLAB         NaN         NaN              -1  Python              -1        NaN   Matplotlib         NaN        NaN        NaN        NaN        NaN        NaN        NaN         NaN         NaN         NaN              -1       CPUs       GPUs        NaN        NaN        NaN              -1  Never  1-2 years  Linear or Logistic Regression        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN         NaN         NaN         NaN              -1        NaN        NaN        NaN        NaN        NaN        NaN       None        NaN              -1        NaN        NaN        NaN   \n",
       "\n",
       "  Q26_Part_4 Q26_Part_5 Q26_Part_6 Q26_Part_7  Q26_OTHER_TEXT Q27_Part_1 Q27_Part_2 Q27_Part_3 Q27_Part_4 Q27_Part_5 Q27_Part_6  Q27_OTHER_TEXT Q28_Part_1 Q28_Part_2 Q28_Part_3 Q28_Part_4 Q28_Part_5 Q28_Part_6 Q28_Part_7 Q28_Part_8 Q28_Part_9 Q28_Part_10 Q28_Part_11 Q28_Part_12  Q28_OTHER_TEXT Q29_Part_1 Q29_Part_2 Q29_Part_3 Q29_Part_4 Q29_Part_5 Q29_Part_6 Q29_Part_7 Q29_Part_8 Q29_Part_9 Q29_Part_10 Q29_Part_11 Q29_Part_12  Q29_OTHER_TEXT Q30_Part_1 Q30_Part_2 Q30_Part_3 Q30_Part_4 Q30_Part_5 Q30_Part_6 Q30_Part_7 Q30_Part_8 Q30_Part_9 Q30_Part_10 Q30_Part_11 Q30_Part_12  Q30_OTHER_TEXT Q31_Part_1 Q31_Part_2 Q31_Part_3 Q31_Part_4 Q31_Part_5 Q31_Part_6 Q31_Part_7 Q31_Part_8 Q31_Part_9 Q31_Part_10 Q31_Part_11 Q31_Part_12  Q31_OTHER_TEXT Q32_Part_1 Q32_Part_2 Q32_Part_3 Q32_Part_4 Q32_Part_5 Q32_Part_6 Q32_Part_7 Q32_Part_8 Q32_Part_9 Q32_Part_10 Q32_Part_11 Q32_Part_12  Q32_OTHER_TEXT Q33_Part_1 Q33_Part_2 Q33_Part_3 Q33_Part_4 Q33_Part_5 Q33_Part_6 Q33_Part_7 Q33_Part_8 Q33_Part_9  \\\n",
       "0        NaN        NaN        NaN        NaN              -1        NaN        NaN        NaN        NaN        NaN        NaN              -1        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN         NaN        None         NaN              -1        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN         NaN         NaN         NaN              -1        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN         NaN         NaN         NaN              -1        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN         NaN         NaN         NaN              -1        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN         NaN         NaN         NaN              -1        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "\n",
       "  Q33_Part_10 Q33_Part_11 Q33_Part_12  Q33_OTHER_TEXT Q34_Part_1 Q34_Part_2 Q34_Part_3 Q34_Part_4 Q34_Part_5 Q34_Part_6 Q34_Part_7 Q34_Part_8 Q34_Part_9 Q34_Part_10 Q34_Part_11 Q34_Part_12  Q34_OTHER_TEXT  valid_response  yearly_comp_numerical  \n",
       "0         NaN         NaN         NaN              -1        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN         NaN         NaN         NaN              -1               1                34999.5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Time from Start to Finish (seconds)', 'Q1', 'Q2', 'Q2_OTHER_TEXT', 'Q3', 'Q4', 'Q5', 'Q5_OTHER_TEXT', 'Q6', 'Q7',\n",
       "       ...\n",
       "       'Q34_Part_6', 'Q34_Part_7', 'Q34_Part_8', 'Q34_Part_9', 'Q34_Part_10', 'Q34_Part_11', 'Q34_Part_12', 'Q34_OTHER_TEXT', 'valid_response', 'yearly_comp_numerical'], dtype='object', length=248)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53610.50827555357\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Q5\n",
       "Business/Data Analyst      34674.142051\n",
       "DBA/Database Engineer      47323.390152\n",
       "Data Scientist             71292.753043\n",
       "Data/Software Engineer     53372.335742\n",
       "Product/Project Manager    61497.482055\n",
       "Researcher                 43664.603767\n",
       "Name: yearly_comp_numerical, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compensation by profession\n",
    "###################################\n",
    "print(df_pred['yearly_comp_numerical'].mean())\n",
    "df_pred.groupby(df_pred['Q5'])['yearly_comp_numerical'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time from Start to Finish (seconds)</th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q2_OTHER_TEXT</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q5_OTHER_TEXT</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q7</th>\n",
       "      <th>Q8</th>\n",
       "      <th>Q9_Part_1</th>\n",
       "      <th>Q9_Part_2</th>\n",
       "      <th>Q9_Part_3</th>\n",
       "      <th>Q9_Part_4</th>\n",
       "      <th>Q9_Part_5</th>\n",
       "      <th>Q9_Part_6</th>\n",
       "      <th>Q9_Part_7</th>\n",
       "      <th>Q9_Part_8</th>\n",
       "      <th>Q9_OTHER_TEXT</th>\n",
       "      <th>Q10</th>\n",
       "      <th>Q11</th>\n",
       "      <th>Q12_Part_1</th>\n",
       "      <th>Q12_Part_2</th>\n",
       "      <th>Q12_Part_3</th>\n",
       "      <th>Q12_Part_4</th>\n",
       "      <th>Q12_Part_5</th>\n",
       "      <th>Q12_Part_6</th>\n",
       "      <th>Q12_Part_7</th>\n",
       "      <th>Q12_Part_8</th>\n",
       "      <th>Q12_Part_9</th>\n",
       "      <th>Q12_Part_10</th>\n",
       "      <th>Q12_Part_11</th>\n",
       "      <th>Q12_Part_12</th>\n",
       "      <th>Q12_OTHER_TEXT</th>\n",
       "      <th>Q13_Part_1</th>\n",
       "      <th>Q13_Part_2</th>\n",
       "      <th>Q13_Part_3</th>\n",
       "      <th>Q13_Part_4</th>\n",
       "      <th>Q13_Part_5</th>\n",
       "      <th>Q13_Part_6</th>\n",
       "      <th>Q13_Part_7</th>\n",
       "      <th>Q13_Part_8</th>\n",
       "      <th>Q13_Part_9</th>\n",
       "      <th>Q13_Part_10</th>\n",
       "      <th>Q13_Part_11</th>\n",
       "      <th>Q13_Part_12</th>\n",
       "      <th>Q13_OTHER_TEXT</th>\n",
       "      <th>Q14</th>\n",
       "      <th>Q14_Part_1_TEXT</th>\n",
       "      <th>Q14_Part_2_TEXT</th>\n",
       "      <th>Q14_Part_3_TEXT</th>\n",
       "      <th>Q14_Part_4_TEXT</th>\n",
       "      <th>Q14_Part_5_TEXT</th>\n",
       "      <th>Q14_OTHER_TEXT</th>\n",
       "      <th>Q15</th>\n",
       "      <th>Q16_Part_1</th>\n",
       "      <th>Q16_Part_2</th>\n",
       "      <th>Q16_Part_3</th>\n",
       "      <th>Q16_Part_4</th>\n",
       "      <th>Q16_Part_5</th>\n",
       "      <th>Q16_Part_6</th>\n",
       "      <th>Q16_Part_7</th>\n",
       "      <th>Q16_Part_8</th>\n",
       "      <th>Q16_Part_9</th>\n",
       "      <th>Q16_Part_10</th>\n",
       "      <th>Q16_Part_11</th>\n",
       "      <th>Q16_Part_12</th>\n",
       "      <th>Q16_OTHER_TEXT</th>\n",
       "      <th>Q17_Part_1</th>\n",
       "      <th>Q17_Part_2</th>\n",
       "      <th>Q17_Part_3</th>\n",
       "      <th>Q17_Part_4</th>\n",
       "      <th>Q17_Part_5</th>\n",
       "      <th>Q17_Part_6</th>\n",
       "      <th>Q17_Part_7</th>\n",
       "      <th>Q17_Part_8</th>\n",
       "      <th>Q17_Part_9</th>\n",
       "      <th>Q17_Part_10</th>\n",
       "      <th>Q17_Part_11</th>\n",
       "      <th>Q17_Part_12</th>\n",
       "      <th>Q17_OTHER_TEXT</th>\n",
       "      <th>Q18_Part_1</th>\n",
       "      <th>Q18_Part_2</th>\n",
       "      <th>Q18_Part_3</th>\n",
       "      <th>Q18_Part_4</th>\n",
       "      <th>Q18_Part_5</th>\n",
       "      <th>Q18_Part_6</th>\n",
       "      <th>Q18_Part_7</th>\n",
       "      <th>Q18_Part_8</th>\n",
       "      <th>Q18_Part_9</th>\n",
       "      <th>Q18_Part_10</th>\n",
       "      <th>Q18_Part_11</th>\n",
       "      <th>Q18_Part_12</th>\n",
       "      <th>Q18_OTHER_TEXT</th>\n",
       "      <th>Q19</th>\n",
       "      <th>Q19_OTHER_TEXT</th>\n",
       "      <th>Q20_Part_1</th>\n",
       "      <th>Q20_Part_2</th>\n",
       "      <th>Q20_Part_3</th>\n",
       "      <th>Q20_Part_4</th>\n",
       "      <th>Q20_Part_5</th>\n",
       "      <th>Q20_Part_6</th>\n",
       "      <th>Q20_Part_7</th>\n",
       "      <th>Q20_Part_8</th>\n",
       "      <th>Q20_Part_9</th>\n",
       "      <th>Q20_Part_10</th>\n",
       "      <th>Q20_Part_11</th>\n",
       "      <th>Q20_Part_12</th>\n",
       "      <th>Q20_OTHER_TEXT</th>\n",
       "      <th>Q21_Part_1</th>\n",
       "      <th>Q21_Part_2</th>\n",
       "      <th>Q21_Part_3</th>\n",
       "      <th>Q21_Part_4</th>\n",
       "      <th>Q21_Part_5</th>\n",
       "      <th>Q21_OTHER_TEXT</th>\n",
       "      <th>Q22</th>\n",
       "      <th>Q23</th>\n",
       "      <th>Q24_Part_1</th>\n",
       "      <th>Q24_Part_2</th>\n",
       "      <th>Q24_Part_3</th>\n",
       "      <th>Q24_Part_4</th>\n",
       "      <th>Q24_Part_5</th>\n",
       "      <th>Q24_Part_6</th>\n",
       "      <th>Q24_Part_7</th>\n",
       "      <th>Q24_Part_8</th>\n",
       "      <th>Q24_Part_9</th>\n",
       "      <th>Q24_Part_10</th>\n",
       "      <th>Q24_Part_11</th>\n",
       "      <th>Q24_Part_12</th>\n",
       "      <th>Q24_OTHER_TEXT</th>\n",
       "      <th>Q25_Part_1</th>\n",
       "      <th>Q25_Part_2</th>\n",
       "      <th>Q25_Part_3</th>\n",
       "      <th>Q25_Part_4</th>\n",
       "      <th>Q25_Part_5</th>\n",
       "      <th>Q25_Part_6</th>\n",
       "      <th>Q25_Part_7</th>\n",
       "      <th>Q25_Part_8</th>\n",
       "      <th>Q25_OTHER_TEXT</th>\n",
       "      <th>Q26_Part_1</th>\n",
       "      <th>Q26_Part_2</th>\n",
       "      <th>Q26_Part_3</th>\n",
       "      <th>Q26_Part_4</th>\n",
       "      <th>Q26_Part_5</th>\n",
       "      <th>Q26_Part_6</th>\n",
       "      <th>Q26_Part_7</th>\n",
       "      <th>Q26_OTHER_TEXT</th>\n",
       "      <th>Q27_Part_1</th>\n",
       "      <th>Q27_Part_2</th>\n",
       "      <th>Q27_Part_3</th>\n",
       "      <th>Q27_Part_4</th>\n",
       "      <th>Q27_Part_5</th>\n",
       "      <th>Q27_Part_6</th>\n",
       "      <th>Q27_OTHER_TEXT</th>\n",
       "      <th>Q28_Part_1</th>\n",
       "      <th>Q28_Part_2</th>\n",
       "      <th>Q28_Part_3</th>\n",
       "      <th>Q28_Part_4</th>\n",
       "      <th>Q28_Part_5</th>\n",
       "      <th>Q28_Part_6</th>\n",
       "      <th>Q28_Part_7</th>\n",
       "      <th>Q28_Part_8</th>\n",
       "      <th>Q28_Part_9</th>\n",
       "      <th>Q28_Part_10</th>\n",
       "      <th>Q28_Part_11</th>\n",
       "      <th>Q28_Part_12</th>\n",
       "      <th>Q28_OTHER_TEXT</th>\n",
       "      <th>Q29_Part_1</th>\n",
       "      <th>Q29_Part_2</th>\n",
       "      <th>Q29_Part_3</th>\n",
       "      <th>Q29_Part_4</th>\n",
       "      <th>Q29_Part_5</th>\n",
       "      <th>Q29_Part_6</th>\n",
       "      <th>Q29_Part_7</th>\n",
       "      <th>Q29_Part_8</th>\n",
       "      <th>Q29_Part_9</th>\n",
       "      <th>Q29_Part_10</th>\n",
       "      <th>Q29_Part_11</th>\n",
       "      <th>Q29_Part_12</th>\n",
       "      <th>Q29_OTHER_TEXT</th>\n",
       "      <th>Q30_Part_1</th>\n",
       "      <th>Q30_Part_2</th>\n",
       "      <th>Q30_Part_3</th>\n",
       "      <th>Q30_Part_4</th>\n",
       "      <th>Q30_Part_5</th>\n",
       "      <th>Q30_Part_6</th>\n",
       "      <th>Q30_Part_7</th>\n",
       "      <th>Q30_Part_8</th>\n",
       "      <th>Q30_Part_9</th>\n",
       "      <th>Q30_Part_10</th>\n",
       "      <th>Q30_Part_11</th>\n",
       "      <th>Q30_Part_12</th>\n",
       "      <th>Q30_OTHER_TEXT</th>\n",
       "      <th>Q31_Part_1</th>\n",
       "      <th>Q31_Part_2</th>\n",
       "      <th>Q31_Part_3</th>\n",
       "      <th>Q31_Part_4</th>\n",
       "      <th>Q31_Part_5</th>\n",
       "      <th>Q31_Part_6</th>\n",
       "      <th>Q31_Part_7</th>\n",
       "      <th>Q31_Part_8</th>\n",
       "      <th>Q31_Part_9</th>\n",
       "      <th>Q31_Part_10</th>\n",
       "      <th>Q31_Part_11</th>\n",
       "      <th>Q31_Part_12</th>\n",
       "      <th>Q31_OTHER_TEXT</th>\n",
       "      <th>Q32_Part_1</th>\n",
       "      <th>Q32_Part_2</th>\n",
       "      <th>Q32_Part_3</th>\n",
       "      <th>Q32_Part_4</th>\n",
       "      <th>Q32_Part_5</th>\n",
       "      <th>Q32_Part_6</th>\n",
       "      <th>Q32_Part_7</th>\n",
       "      <th>Q32_Part_8</th>\n",
       "      <th>Q32_Part_9</th>\n",
       "      <th>Q32_Part_10</th>\n",
       "      <th>Q32_Part_11</th>\n",
       "      <th>Q32_Part_12</th>\n",
       "      <th>Q32_OTHER_TEXT</th>\n",
       "      <th>Q33_Part_1</th>\n",
       "      <th>Q33_Part_2</th>\n",
       "      <th>Q33_Part_3</th>\n",
       "      <th>Q33_Part_4</th>\n",
       "      <th>Q33_Part_5</th>\n",
       "      <th>Q33_Part_6</th>\n",
       "      <th>Q33_Part_7</th>\n",
       "      <th>Q33_Part_8</th>\n",
       "      <th>Q33_Part_9</th>\n",
       "      <th>Q33_Part_10</th>\n",
       "      <th>Q33_Part_11</th>\n",
       "      <th>Q33_Part_12</th>\n",
       "      <th>Q33_OTHER_TEXT</th>\n",
       "      <th>Q34_Part_1</th>\n",
       "      <th>Q34_Part_2</th>\n",
       "      <th>Q34_Part_3</th>\n",
       "      <th>Q34_Part_4</th>\n",
       "      <th>Q34_Part_5</th>\n",
       "      <th>Q34_Part_6</th>\n",
       "      <th>Q34_Part_7</th>\n",
       "      <th>Q34_Part_8</th>\n",
       "      <th>Q34_Part_9</th>\n",
       "      <th>Q34_Part_10</th>\n",
       "      <th>Q34_Part_11</th>\n",
       "      <th>Q34_Part_12</th>\n",
       "      <th>Q34_OTHER_TEXT</th>\n",
       "      <th>valid_response</th>\n",
       "      <th>yearly_comp_numerical</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>510</td>\n",
       "      <td>22-24</td>\n",
       "      <td>Male</td>\n",
       "      <td>-1</td>\n",
       "      <td>France</td>\n",
       "      <td>Master’s degree</td>\n",
       "      <td>Data/Software Engineer</td>\n",
       "      <td>-1</td>\n",
       "      <td>1000-9,999 employees</td>\n",
       "      <td>0</td>\n",
       "      <td>I do not know</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>30,000-39,999</td>\n",
       "      <td>$0 (USD)</td>\n",
       "      <td>Twitter (data science influencers)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kaggle (forums, blog, social media, etc)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Blogs (Towards Data Science, Medium, Analytics...</td>\n",
       "      <td>Journal Publications (traditional publications...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Coursera</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DataCamp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kaggle Courses (i.e. Kaggle Learn)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Udemy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>Basic statistical software (Microsoft Excel, G...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1-2 years</td>\n",
       "      <td>Jupyter (JupyterLab, Jupyter Notebooks, etc)</td>\n",
       "      <td>RStudio</td>\n",
       "      <td>PyCharm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MATLAB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Spyder</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>Python</td>\n",
       "      <td>R</td>\n",
       "      <td>SQL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Java</td>\n",
       "      <td>Javascript</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MATLAB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>Python</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Matplotlib</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>CPUs</td>\n",
       "      <td>GPUs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>Never</td>\n",
       "      <td>1-2 years</td>\n",
       "      <td>Linear or Logistic Regression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>34999.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>423</td>\n",
       "      <td>40-44</td>\n",
       "      <td>Male</td>\n",
       "      <td>-1</td>\n",
       "      <td>India</td>\n",
       "      <td>Professional degree</td>\n",
       "      <td>Data/Software Engineer</td>\n",
       "      <td>-1</td>\n",
       "      <td>&gt; 10,000 employees</td>\n",
       "      <td>20+</td>\n",
       "      <td>We have well established ML methods (i.e., mod...</td>\n",
       "      <td>Analyze and understand data to influence produ...</td>\n",
       "      <td>Build and/or run the data infrastructure that ...</td>\n",
       "      <td>Build prototypes to explore applying machine l...</td>\n",
       "      <td>Build and/or run a machine learning service th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>5,000-7,499</td>\n",
       "      <td>&gt; $100,000 ($USD)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kaggle (forums, blog, social media, etc)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>YouTube (Cloud AI Adventures, Siraj Raval, etc)</td>\n",
       "      <td>Podcasts (Chai Time Data Science, Linear Digre...</td>\n",
       "      <td>Blogs (Towards Data Science, Medium, Analytics...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Coursera</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DataCamp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kaggle Courses (i.e. Kaggle Learn)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Udemy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>Cloud-based data software &amp; APIs (AWS, GCP, Az...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>I have never written code</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>6249.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>470</td>\n",
       "      <td>50-54</td>\n",
       "      <td>Male</td>\n",
       "      <td>-1</td>\n",
       "      <td>France</td>\n",
       "      <td>Master’s degree</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>-1</td>\n",
       "      <td>0-49 employees</td>\n",
       "      <td>3-4</td>\n",
       "      <td>We have well established ML methods (i.e., mod...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Build prototypes to explore applying machine l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Do research that advances the state of the art...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>60,000-69,999</td>\n",
       "      <td>$10,000-$99,999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>YouTube (Cloud AI Adventures, Siraj Raval, etc)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Blogs (Towards Data Science, Medium, Analytics...</td>\n",
       "      <td>Journal Publications (traditional publications...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>Advanced statistical software (SPSS, SAS, etc.)</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>20+ years</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RStudio</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>Python</td>\n",
       "      <td>R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>Java</td>\n",
       "      <td>-1</td>\n",
       "      <td>Ggplot / ggplot2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>CPUs</td>\n",
       "      <td>GPUs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>Never</td>\n",
       "      <td>10-15 years</td>\n",
       "      <td>Linear or Logistic Regression</td>\n",
       "      <td>Decision Trees or Random Forests</td>\n",
       "      <td>Gradient Boosting Machines (xgboost, lightgbm,...</td>\n",
       "      <td>Bayesian Approaches</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Convolutional Neural Networks</td>\n",
       "      <td>Generative Adversarial Networks</td>\n",
       "      <td>Recurrent Neural Networks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Automated model selection (e.g. auto-sklearn, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Automated hyperparameter tuning (e.g. hyperopt...</td>\n",
       "      <td>Automation of full ML pipelines (e.g. Google A...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>Word embeddings/vectors (GLoVe, fastText, word...</td>\n",
       "      <td>Encoder-decorder models (seq2seq, vanilla tran...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>Scikit-learn</td>\n",
       "      <td>TensorFlow</td>\n",
       "      <td>Keras</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>Xgboost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Caret</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Amazon Web Services (AWS)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>AWS Elastic Compute Cloud (EC2)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AWS Elastic MapReduce</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RapidMiner</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Auto-Keras</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PostgresSQL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AWS Relational Database Service</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>64999.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>529</td>\n",
       "      <td>22-24</td>\n",
       "      <td>Male</td>\n",
       "      <td>-1</td>\n",
       "      <td>India</td>\n",
       "      <td>Master’s degree</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>-1</td>\n",
       "      <td>50-249 employees</td>\n",
       "      <td>20+</td>\n",
       "      <td>We are exploring ML methods (and may one day p...</td>\n",
       "      <td>Analyze and understand data to influence produ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Experimentation and iteration to improve exist...</td>\n",
       "      <td>Do research that advances the state of the art...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>10,000-14,999</td>\n",
       "      <td>$100-$999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kaggle (forums, blog, social media, etc)</td>\n",
       "      <td>Course Forums (forums.fast.ai, etc)</td>\n",
       "      <td>YouTube (Cloud AI Adventures, Siraj Raval, etc)</td>\n",
       "      <td>Podcasts (Chai Time Data Science, Linear Digre...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Journal Publications (traditional publications...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>Udacity</td>\n",
       "      <td>Coursera</td>\n",
       "      <td>edX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kaggle Courses (i.e. Kaggle Learn)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Udemy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>Local development environments (RStudio, Jupyt...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>3-5 years</td>\n",
       "      <td>Jupyter (JupyterLab, Jupyter Notebooks, etc)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Spyder</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Notepad++</td>\n",
       "      <td>Sublime Text</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>Kaggle Notebooks (Kernels)</td>\n",
       "      <td>Google Colab</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Binder / JupyterHub</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>Python</td>\n",
       "      <td>R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bash</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>Python</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Matplotlib</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Plotly / Plotly Express</td>\n",
       "      <td>Bokeh</td>\n",
       "      <td>Seaborn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>CPUs</td>\n",
       "      <td>GPUs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>6-24 times</td>\n",
       "      <td>2-3 years</td>\n",
       "      <td>Linear or Logistic Regression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dense Neural Networks (MLPs, etc)</td>\n",
       "      <td>Convolutional Neural Networks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recurrent Neural Networks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>Automated data augmentation (e.g. imgaug, albu...</td>\n",
       "      <td>Automated feature engineering/selection (e.g. ...</td>\n",
       "      <td>Automated model selection (e.g. auto-sklearn, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Automation of full ML pipelines (e.g. Google A...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>General purpose image/video tools (PIL, cv2, s...</td>\n",
       "      <td>Image segmentation methods (U-Net, Mask R-CNN,...</td>\n",
       "      <td>Object detection methods (YOLOv3, RetinaNet, etc)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>Word embeddings/vectors (GLoVe, fastText, word...</td>\n",
       "      <td>Encoder-decorder models (seq2seq, vanilla tran...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>Scikit-learn</td>\n",
       "      <td>TensorFlow</td>\n",
       "      <td>Keras</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PyTorch</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>Google Cloud Platform (GCP)</td>\n",
       "      <td>Amazon Web Services (AWS)</td>\n",
       "      <td>Microsoft Azure</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Google Compute Engine (GCE)</td>\n",
       "      <td>AWS Lambda</td>\n",
       "      <td>Azure Virtual Machines</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>Google BigQuery</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Databricks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>SAS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Azure Machine Learning Studio</td>\n",
       "      <td>Google Cloud Machine Learning Engine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>Google AutoML</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tpot</td>\n",
       "      <td>Auto-Keras</td>\n",
       "      <td>Auto-Sklearn</td>\n",
       "      <td>Auto_ml</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>MySQL</td>\n",
       "      <td>PostgresSQL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>12499.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>624</td>\n",
       "      <td>22-24</td>\n",
       "      <td>Female</td>\n",
       "      <td>-1</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Bachelor’s degree</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>-1</td>\n",
       "      <td>&gt; 10,000 employees</td>\n",
       "      <td>20+</td>\n",
       "      <td>We recently started using ML methods (i.e., mo...</td>\n",
       "      <td>Analyze and understand data to influence produ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Build prototypes to explore applying machine l...</td>\n",
       "      <td>Build and/or run a machine learning service th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>80,000-89,999</td>\n",
       "      <td>$0 (USD)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hacker News (https://news.ycombinator.com/)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Blogs (Towards Data Science, Medium, Analytics...</td>\n",
       "      <td>Journal Publications (traditional publications...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Udemy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>University Courses (resulting in a university ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>Local development environments (RStudio, Jupyt...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>3-5 years</td>\n",
       "      <td>Jupyter (JupyterLab, Jupyter Notebooks, etc)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Spyder</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Microsoft Azure Notebooks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AWS Notebook Products (EMR Notebooks, Sagemake...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>Python</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>Python</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Matplotlib</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Plotly / Plotly Express</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>CPUs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>Once</td>\n",
       "      <td>3-4 years</td>\n",
       "      <td>Linear or Logistic Regression</td>\n",
       "      <td>Decision Trees or Random Forests</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Convolutional Neural Networks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>General purpose image/video tools (PIL, cv2, s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Image classification and other general purpose...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>Scikit-learn</td>\n",
       "      <td>TensorFlow</td>\n",
       "      <td>Keras</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Spark MLib</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>84999.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8937</th>\n",
       "      <td>331</td>\n",
       "      <td>30-34</td>\n",
       "      <td>Male</td>\n",
       "      <td>-1</td>\n",
       "      <td>China</td>\n",
       "      <td>Master’s degree</td>\n",
       "      <td>Business/Data Analyst</td>\n",
       "      <td>-1</td>\n",
       "      <td>250-999 employees</td>\n",
       "      <td>3-4</td>\n",
       "      <td>We recently started using ML methods (i.e., mo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Build and/or run a machine learning service th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>7,500-9,999</td>\n",
       "      <td>$1000-$9,999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hacker News (https://news.ycombinator.com/)</td>\n",
       "      <td>Reddit (r/machinelearning, r/datascience, etc)</td>\n",
       "      <td>Kaggle (forums, blog, social media, etc)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>Udacity</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>Cloud-based data software &amp; APIs (AWS, GCP, Az...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1-2 years</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>8749.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8938</th>\n",
       "      <td>290</td>\n",
       "      <td>30-34</td>\n",
       "      <td>Female</td>\n",
       "      <td>-1</td>\n",
       "      <td>India</td>\n",
       "      <td>Master’s degree</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>-1</td>\n",
       "      <td>&gt; 10,000 employees</td>\n",
       "      <td>15-19</td>\n",
       "      <td>We recently started using ML methods (i.e., mo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Build prototypes to explore applying machine l...</td>\n",
       "      <td>Build and/or run a machine learning service th...</td>\n",
       "      <td>Experimentation and iteration to improve exist...</td>\n",
       "      <td>Do research that advances the state of the art...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>7,500-9,999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>8749.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8939</th>\n",
       "      <td>1480</td>\n",
       "      <td>70+</td>\n",
       "      <td>Male</td>\n",
       "      <td>-1</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>Professional degree</td>\n",
       "      <td>Business/Data Analyst</td>\n",
       "      <td>-1</td>\n",
       "      <td>250-999 employees</td>\n",
       "      <td>1-2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8940</th>\n",
       "      <td>346</td>\n",
       "      <td>22-24</td>\n",
       "      <td>Male</td>\n",
       "      <td>-1</td>\n",
       "      <td>India</td>\n",
       "      <td>Bachelor’s degree</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>-1</td>\n",
       "      <td>50-249 employees</td>\n",
       "      <td>3-4</td>\n",
       "      <td>We use ML methods for generating insights (but...</td>\n",
       "      <td>Analyze and understand data to influence produ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>7,500-9,999</td>\n",
       "      <td>$100-$999</td>\n",
       "      <td>Twitter (data science influencers)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>YouTube (Cloud AI Adventures, Siraj Raval, etc)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>Udacity</td>\n",
       "      <td>Coursera</td>\n",
       "      <td>edX</td>\n",
       "      <td>DataCamp</td>\n",
       "      <td>DataQuest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fast.ai</td>\n",
       "      <td>Udemy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>8749.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8941</th>\n",
       "      <td>567</td>\n",
       "      <td>50-54</td>\n",
       "      <td>Male</td>\n",
       "      <td>-1</td>\n",
       "      <td>France</td>\n",
       "      <td>Bachelor’s degree</td>\n",
       "      <td>Data/Software Engineer</td>\n",
       "      <td>-1</td>\n",
       "      <td>&gt; 10,000 employees</td>\n",
       "      <td>20+</td>\n",
       "      <td>We have well established ML methods (i.e., mod...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Build and/or run the data infrastructure that ...</td>\n",
       "      <td>Build prototypes to explore applying machine l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>60,000-69,999</td>\n",
       "      <td>$0 (USD)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Blogs (Towards Data Science, Medium, Analytics...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Coursera</td>\n",
       "      <td>edX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Udemy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>Local development environments (RStudio, Jupyt...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>25</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>3-5 years</td>\n",
       "      <td>Jupyter (JupyterLab, Jupyter Notebooks, etc)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Visual Studio / Visual Studio Code</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IBM Watson Studio</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>Python</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SQL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Java</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bash</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>Python</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Matplotlib</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>CPUs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>Never</td>\n",
       "      <td>4-5 years</td>\n",
       "      <td>Linear or Logistic Regression</td>\n",
       "      <td>Decision Trees or Random Forests</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Automated model selection (e.g. auto-sklearn, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Automated hyperparameter tuning (e.g. hyperopt...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>Scikit-learn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Spark MLib</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>64999.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8942 rows × 248 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Time from Start to Finish (seconds)     Q1      Q2  Q2_OTHER_TEXT                        Q3                   Q4                      Q5  Q5_OTHER_TEXT                    Q6     Q7                                                 Q8                                          Q9_Part_1                                          Q9_Part_2                                          Q9_Part_3                                          Q9_Part_4                                          Q9_Part_5                                          Q9_Part_6 Q9_Part_7 Q9_Part_8  Q9_OTHER_TEXT            Q10                Q11                          Q12_Part_1                                   Q12_Part_2                                      Q12_Part_3                                Q12_Part_4                           Q12_Part_5                                       Q12_Part_6                                         Q12_Part_7                                         Q12_Part_8  \\\n",
       "0                                     510  22-24    Male             -1                    France      Master’s degree  Data/Software Engineer             -1  1000-9,999 employees      0                                      I do not know                                                NaN                                                NaN                                                NaN                                                NaN                                                NaN                                                NaN       NaN       NaN             -1  30,000-39,999           $0 (USD)  Twitter (data science influencers)                                          NaN                                             NaN  Kaggle (forums, blog, social media, etc)                                  NaN                                              NaN                                                NaN  Blogs (Towards Data Science, Medium, Analytics...   \n",
       "1                                     423  40-44    Male             -1                     India  Professional degree  Data/Software Engineer             -1    > 10,000 employees    20+  We have well established ML methods (i.e., mod...  Analyze and understand data to influence produ...  Build and/or run the data infrastructure that ...  Build prototypes to explore applying machine l...  Build and/or run a machine learning service th...                                                NaN                                                NaN       NaN       NaN             -1    5,000-7,499  > $100,000 ($USD)                                 NaN                                          NaN                                             NaN  Kaggle (forums, blog, social media, etc)                                  NaN  YouTube (Cloud AI Adventures, Siraj Raval, etc)  Podcasts (Chai Time Data Science, Linear Digre...  Blogs (Towards Data Science, Medium, Analytics...   \n",
       "2                                     470  50-54    Male             -1                    France      Master’s degree          Data Scientist             -1        0-49 employees    3-4  We have well established ML methods (i.e., mod...                                                NaN                                                NaN  Build prototypes to explore applying machine l...                                                NaN                                                NaN  Do research that advances the state of the art...       NaN       NaN             -1  60,000-69,999    $10,000-$99,999                                 NaN                                          NaN                                             NaN                                       NaN                                  NaN  YouTube (Cloud AI Adventures, Siraj Raval, etc)                                                NaN  Blogs (Towards Data Science, Medium, Analytics...   \n",
       "3                                     529  22-24    Male             -1                     India      Master’s degree          Data Scientist             -1      50-249 employees    20+  We are exploring ML methods (and may one day p...  Analyze and understand data to influence produ...                                                NaN                                                NaN                                                NaN  Experimentation and iteration to improve exist...  Do research that advances the state of the art...       NaN       NaN             -1  10,000-14,999          $100-$999                                 NaN                                          NaN                                             NaN  Kaggle (forums, blog, social media, etc)  Course Forums (forums.fast.ai, etc)  YouTube (Cloud AI Adventures, Siraj Raval, etc)  Podcasts (Chai Time Data Science, Linear Digre...                                                NaN   \n",
       "4                                     624  22-24  Female             -1  United States of America    Bachelor’s degree          Data Scientist             -1    > 10,000 employees    20+  We recently started using ML methods (i.e., mo...  Analyze and understand data to influence produ...                                                NaN  Build prototypes to explore applying machine l...  Build and/or run a machine learning service th...                                                NaN                                                NaN       NaN       NaN             -1  80,000-89,999           $0 (USD)                                 NaN  Hacker News (https://news.ycombinator.com/)                                             NaN                                       NaN                                  NaN                                              NaN                                                NaN  Blogs (Towards Data Science, Medium, Analytics...   \n",
       "...                                   ...    ...     ...            ...                       ...                  ...                     ...            ...                   ...    ...                                                ...                                                ...                                                ...                                                ...                                                ...                                                ...                                                ...       ...       ...            ...            ...                ...                                 ...                                          ...                                             ...                                       ...                                  ...                                              ...                                                ...                                                ...   \n",
       "8937                                  331  30-34    Male             -1                     China      Master’s degree   Business/Data Analyst             -1     250-999 employees    3-4  We recently started using ML methods (i.e., mo...                                                NaN                                                NaN                                                NaN  Build and/or run a machine learning service th...                                                NaN                                                NaN       NaN       NaN             -1    7,500-9,999       $1000-$9,999                                 NaN  Hacker News (https://news.ycombinator.com/)  Reddit (r/machinelearning, r/datascience, etc)  Kaggle (forums, blog, social media, etc)                                  NaN                                              NaN                                                NaN                                                NaN   \n",
       "8938                                  290  30-34  Female             -1                     India      Master’s degree          Data Scientist             -1    > 10,000 employees  15-19  We recently started using ML methods (i.e., mo...                                                NaN                                                NaN  Build prototypes to explore applying machine l...  Build and/or run a machine learning service th...  Experimentation and iteration to improve exist...  Do research that advances the state of the art...       NaN       NaN             -1    7,500-9,999                NaN                                 NaN                                          NaN                                             NaN                                       NaN                                  NaN                                              NaN                                                NaN                                                NaN   \n",
       "8939                                 1480    70+    Male             -1                    Brazil  Professional degree   Business/Data Analyst             -1     250-999 employees    1-2                                                NaN                                                NaN                                                NaN                                                NaN                                                NaN                                                NaN                                                NaN       NaN       NaN             -1            NaN                NaN                                 NaN                                          NaN                                             NaN                                       NaN                                  NaN                                              NaN                                                NaN                                                NaN   \n",
       "8940                                  346  22-24    Male             -1                     India    Bachelor’s degree          Data Scientist             -1      50-249 employees    3-4  We use ML methods for generating insights (but...  Analyze and understand data to influence produ...                                                NaN                                                NaN                                                NaN                                                NaN                                                NaN       NaN       NaN             -1    7,500-9,999          $100-$999  Twitter (data science influencers)                                          NaN                                             NaN                                       NaN                                  NaN  YouTube (Cloud AI Adventures, Siraj Raval, etc)                                                NaN                                                NaN   \n",
       "8941                                  567  50-54    Male             -1                    France    Bachelor’s degree  Data/Software Engineer             -1    > 10,000 employees    20+  We have well established ML methods (i.e., mod...                                                NaN  Build and/or run the data infrastructure that ...  Build prototypes to explore applying machine l...                                                NaN                                                NaN                                                NaN       NaN       NaN             -1  60,000-69,999           $0 (USD)                                 NaN                                          NaN                                             NaN                                       NaN                                  NaN                                              NaN                                                NaN  Blogs (Towards Data Science, Medium, Analytics...   \n",
       "\n",
       "                                             Q12_Part_9 Q12_Part_10 Q12_Part_11 Q12_Part_12  Q12_OTHER_TEXT Q13_Part_1 Q13_Part_2 Q13_Part_3 Q13_Part_4 Q13_Part_5                          Q13_Part_6 Q13_Part_7 Q13_Part_8 Q13_Part_9                                        Q13_Part_10 Q13_Part_11 Q13_Part_12  Q13_OTHER_TEXT                                                Q14  Q14_Part_1_TEXT  Q14_Part_2_TEXT  Q14_Part_3_TEXT  Q14_Part_4_TEXT  Q14_Part_5_TEXT  Q14_OTHER_TEXT                        Q15                                     Q16_Part_1 Q16_Part_2 Q16_Part_3 Q16_Part_4 Q16_Part_5                            Q16_Part_6  Q16_Part_7 Q16_Part_8     Q16_Part_9       Q16_Part_10 Q16_Part_11 Q16_Part_12  Q16_OTHER_TEXT                    Q17_Part_1      Q17_Part_2                   Q17_Part_3 Q17_Part_4 Q17_Part_5 Q17_Part_6             Q17_Part_7           Q17_Part_8 Q17_Part_9                                        Q17_Part_10 Q17_Part_11 Q17_Part_12  Q17_OTHER_TEXT Q18_Part_1  \\\n",
       "0     Journal Publications (traditional publications...         NaN         NaN         NaN              -1        NaN   Coursera        NaN   DataCamp        NaN  Kaggle Courses (i.e. Kaggle Learn)        NaN      Udemy        NaN                                                NaN         NaN         NaN              -1  Basic statistical software (Microsoft Excel, G...                0               -1               -1               -1               -1              -1                  1-2 years  Jupyter (JupyterLab, Jupyter Notebooks, etc)    RStudio    PyCharm         NaN    MATLAB                                    NaN    Spyder          NaN            NaN               NaN         NaN         NaN              -1                           NaN             NaN                          NaN        NaN        NaN        NaN                    NaN                  NaN        NaN                                                NaN        None         NaN              -1     Python   \n",
       "1                                                   NaN         NaN         NaN         NaN              -1        NaN   Coursera        NaN   DataCamp        NaN  Kaggle Courses (i.e. Kaggle Learn)        NaN      Udemy        NaN                                                NaN         NaN         NaN              -1  Cloud-based data software & APIs (AWS, GCP, Az...               -1               -1               -1               -1                0              -1  I have never written code                                            NaN        NaN        NaN        NaN        NaN                                   NaN         NaN        NaN            NaN               NaN         NaN         NaN              -1                           NaN             NaN                          NaN        NaN        NaN        NaN                    NaN                  NaN        NaN                                                NaN         NaN         NaN              -1        NaN   \n",
       "2     Journal Publications (traditional publications...         NaN         NaN         NaN              -1        NaN        NaN        NaN        NaN        NaN                                 NaN        NaN        NaN        NaN                                                NaN        None         NaN              -1    Advanced statistical software (SPSS, SAS, etc.)               -1                0               -1               -1               -1              -1                  20+ years                                            NaN   RStudio         NaN        NaN        NaN                                   NaN         NaN        NaN            NaN               NaN         NaN       Other              -1                           NaN             NaN                          NaN        NaN        NaN        NaN                    NaN                  NaN        NaN                                                NaN        None         NaN              -1     Python   \n",
       "3     Journal Publications (traditional publications...         NaN         NaN         NaN              -1    Udacity   Coursera        edX        NaN        NaN  Kaggle Courses (i.e. Kaggle Learn)        NaN      Udemy        NaN                                                NaN         NaN         NaN              -1  Local development environments (RStudio, Jupyt...               -1               -1               -1                2               -1              -1                  3-5 years  Jupyter (JupyterLab, Jupyter Notebooks, etc)         NaN        NaN        NaN        NaN                                   NaN    Spyder          NaN    Notepad++      Sublime Text           NaN         NaN              -1   Kaggle Notebooks (Kernels)    Google Colab                           NaN        NaN        NaN        NaN   Binder / JupyterHub                   NaN        NaN                                                NaN         NaN         NaN              -1     Python   \n",
       "4     Journal Publications (traditional publications...         NaN         NaN         NaN              -1        NaN        NaN        NaN        NaN        NaN                                 NaN        NaN      Udemy        NaN  University Courses (resulting in a university ...         NaN         NaN              -1  Local development environments (RStudio, Jupyt...               -1               -1               -1                3               -1              -1                  3-5 years  Jupyter (JupyterLab, Jupyter Notebooks, etc)         NaN        NaN        NaN        NaN                                   NaN    Spyder          NaN            NaN               NaN         NaN         NaN              -1                           NaN             NaN   Microsoft Azure Notebooks         NaN        NaN        NaN                    NaN                  NaN        NaN  AWS Notebook Products (EMR Notebooks, Sagemake...         NaN         NaN              -1     Python   \n",
       "...                                                 ...         ...         ...         ...             ...        ...        ...        ...        ...        ...                                 ...        ...        ...        ...                                                ...         ...         ...             ...                                                ...              ...              ...              ...              ...              ...             ...                        ...                                            ...        ...        ...        ...        ...                                   ...         ...        ...            ...               ...         ...         ...             ...                           ...             ...                          ...        ...        ...        ...                    ...                  ...        ...                                                ...         ...         ...             ...        ...   \n",
       "8937                                                NaN         NaN         NaN         NaN              -1    Udacity        NaN        NaN        NaN        NaN                                 NaN        NaN        NaN        NaN                                                NaN         NaN         NaN              -1  Cloud-based data software & APIs (AWS, GCP, Az...               -1               -1               -1               -1                1              -1                  1-2 years                                            NaN        NaN        NaN        NaN        NaN                                   NaN         NaN        NaN            NaN               NaN         NaN         NaN              -1                           NaN             NaN                          NaN        NaN        NaN        NaN                    NaN                  NaN        NaN                                                NaN         NaN         NaN              -1        NaN   \n",
       "8938                                                NaN         NaN         NaN         NaN              -1        NaN        NaN        NaN        NaN        NaN                                 NaN        NaN        NaN        NaN                                                NaN         NaN         NaN              -1                                                NaN               -1               -1               -1               -1               -1              -1                        NaN                                            NaN        NaN        NaN        NaN        NaN                                   NaN         NaN        NaN            NaN               NaN         NaN         NaN              -1                           NaN             NaN                          NaN        NaN        NaN        NaN                    NaN                  NaN        NaN                                                NaN         NaN         NaN              -1        NaN   \n",
       "8939                                                NaN         NaN         NaN         NaN              -1        NaN        NaN        NaN        NaN        NaN                                 NaN        NaN        NaN        NaN                                                NaN         NaN         NaN              -1                                                NaN               -1               -1               -1               -1               -1              -1                        NaN                                            NaN        NaN        NaN        NaN        NaN                                   NaN         NaN        NaN            NaN               NaN         NaN         NaN              -1                           NaN             NaN                          NaN        NaN        NaN        NaN                    NaN                  NaN        NaN                                                NaN         NaN         NaN              -1        NaN   \n",
       "8940                                                NaN         NaN         NaN         NaN              -1    Udacity   Coursera        edX   DataCamp  DataQuest                                 NaN    Fast.ai      Udemy        NaN                                                NaN         NaN         NaN              -1                                                NaN               -1               -1               -1               -1               -1              -1                        NaN                                            NaN        NaN        NaN        NaN        NaN                                   NaN         NaN        NaN            NaN               NaN         NaN         NaN              -1                           NaN             NaN                          NaN        NaN        NaN        NaN                    NaN                  NaN        NaN                                                NaN         NaN         NaN              -1        NaN   \n",
       "8941                                                NaN         NaN         NaN         NaN              -1        NaN   Coursera        edX        NaN        NaN                                 NaN        NaN      Udemy        NaN                                                NaN         NaN         NaN              -1  Local development environments (RStudio, Jupyt...               -1               -1               -1               25               -1              -1                  3-5 years  Jupyter (JupyterLab, Jupyter Notebooks, etc)         NaN        NaN        NaN        NaN   Visual Studio / Visual Studio Code          NaN        NaN            NaN               NaN         NaN         NaN              -1                           NaN             NaN                          NaN        NaN        NaN        NaN                    NaN   IBM Watson Studio         NaN                                                NaN         NaN         NaN              -1     Python   \n",
       "\n",
       "     Q18_Part_2 Q18_Part_3 Q18_Part_4 Q18_Part_5 Q18_Part_6  Q18_Part_7 Q18_Part_8 Q18_Part_9 Q18_Part_10 Q18_Part_11 Q18_Part_12  Q18_OTHER_TEXT     Q19  Q19_OTHER_TEXT          Q20_Part_1    Q20_Part_2 Q20_Part_3 Q20_Part_4 Q20_Part_5                 Q20_Part_6 Q20_Part_7 Q20_Part_8 Q20_Part_9 Q20_Part_10 Q20_Part_11 Q20_Part_12  Q20_OTHER_TEXT Q21_Part_1 Q21_Part_2 Q21_Part_3 Q21_Part_4 Q21_Part_5  Q21_OTHER_TEXT         Q22          Q23                     Q24_Part_1                        Q24_Part_2                                         Q24_Part_3           Q24_Part_4 Q24_Part_5                         Q24_Part_6                     Q24_Part_7                       Q24_Part_8                 Q24_Part_9 Q24_Part_10 Q24_Part_11 Q24_Part_12  Q24_OTHER_TEXT                                         Q25_Part_1                                         Q25_Part_2                                         Q25_Part_3 Q25_Part_4                                         Q25_Part_5  \\\n",
       "0             R        SQL        NaN        NaN       Java  Javascript        NaN        NaN      MATLAB         NaN         NaN              -1  Python              -1                 NaN   Matplotlib         NaN        NaN        NaN                        NaN        NaN        NaN        NaN         NaN         NaN         NaN              -1       CPUs       GPUs        NaN        NaN        NaN              -1       Never    1-2 years  Linear or Logistic Regression                               NaN                                                NaN                  NaN        NaN                                NaN                            NaN                              NaN                        NaN         NaN         NaN         NaN              -1                                                NaN                                                NaN                                                NaN        NaN                                                NaN   \n",
       "1           NaN        NaN        NaN        NaN        NaN         NaN        NaN        NaN         NaN         NaN         NaN              -1     NaN              -1                 NaN           NaN        NaN        NaN        NaN                        NaN        NaN        NaN        NaN         NaN         NaN         NaN              -1        NaN        NaN        NaN        NaN        NaN              -1         NaN          NaN                            NaN                               NaN                                                NaN                  NaN        NaN                                NaN                            NaN                              NaN                        NaN         NaN         NaN         NaN              -1                                                NaN                                                NaN                                                NaN        NaN                                                NaN   \n",
       "2             R        NaN        NaN        NaN        NaN         NaN        NaN        NaN         NaN         NaN         NaN              -1    Java              -1   Ggplot / ggplot2            NaN        NaN        NaN        NaN                        NaN        NaN        NaN        NaN         NaN         NaN         NaN              -1       CPUs       GPUs        NaN        NaN        NaN              -1       Never  10-15 years  Linear or Logistic Regression  Decision Trees or Random Forests  Gradient Boosting Machines (xgboost, lightgbm,...  Bayesian Approaches        NaN                                NaN  Convolutional Neural Networks  Generative Adversarial Networks  Recurrent Neural Networks         NaN         NaN         NaN              -1                                                NaN                                                NaN  Automated model selection (e.g. auto-sklearn, ...        NaN  Automated hyperparameter tuning (e.g. hyperopt...   \n",
       "3             R        NaN        NaN        NaN        NaN         NaN        NaN       Bash         NaN         NaN         NaN              -1  Python              -1                 NaN   Matplotlib         NaN        NaN        NaN   Plotly / Plotly Express      Bokeh    Seaborn         NaN         NaN         NaN         NaN              -1       CPUs       GPUs        NaN        NaN        NaN              -1  6-24 times    2-3 years  Linear or Logistic Regression                               NaN                                                NaN                  NaN        NaN  Dense Neural Networks (MLPs, etc)  Convolutional Neural Networks                              NaN  Recurrent Neural Networks         NaN         NaN         NaN              -1  Automated data augmentation (e.g. imgaug, albu...  Automated feature engineering/selection (e.g. ...  Automated model selection (e.g. auto-sklearn, ...        NaN                                                NaN   \n",
       "4           NaN        NaN        NaN        NaN        NaN         NaN        NaN        NaN         NaN         NaN         NaN              -1  Python              -1                 NaN   Matplotlib         NaN        NaN        NaN   Plotly / Plotly Express         NaN        NaN        NaN         NaN         NaN         NaN              -1       CPUs        NaN        NaN        NaN        NaN              -1        Once    3-4 years  Linear or Logistic Regression  Decision Trees or Random Forests                                                NaN                  NaN        NaN                                NaN  Convolutional Neural Networks                              NaN                        NaN         NaN         NaN         NaN              -1                                                NaN                                                NaN                                                NaN        NaN                                                NaN   \n",
       "...         ...        ...        ...        ...        ...         ...        ...        ...         ...         ...         ...             ...     ...             ...                 ...           ...        ...        ...        ...                        ...        ...        ...        ...         ...         ...         ...             ...        ...        ...        ...        ...        ...             ...         ...          ...                            ...                               ...                                                ...                  ...        ...                                ...                            ...                              ...                        ...         ...         ...         ...             ...                                                ...                                                ...                                                ...        ...                                                ...   \n",
       "8937        NaN        NaN        NaN        NaN        NaN         NaN        NaN        NaN         NaN         NaN         NaN              -1     NaN              -1                 NaN           NaN        NaN        NaN        NaN                        NaN        NaN        NaN        NaN         NaN         NaN         NaN              -1        NaN        NaN        NaN        NaN        NaN              -1         NaN          NaN                            NaN                               NaN                                                NaN                  NaN        NaN                                NaN                            NaN                              NaN                        NaN         NaN         NaN         NaN              -1                                                NaN                                                NaN                                                NaN        NaN                                                NaN   \n",
       "8938        NaN        NaN        NaN        NaN        NaN         NaN        NaN        NaN         NaN         NaN         NaN              -1     NaN              -1                 NaN           NaN        NaN        NaN        NaN                        NaN        NaN        NaN        NaN         NaN         NaN         NaN              -1        NaN        NaN        NaN        NaN        NaN              -1         NaN          NaN                            NaN                               NaN                                                NaN                  NaN        NaN                                NaN                            NaN                              NaN                        NaN         NaN         NaN         NaN              -1                                                NaN                                                NaN                                                NaN        NaN                                                NaN   \n",
       "8939        NaN        NaN        NaN        NaN        NaN         NaN        NaN        NaN         NaN         NaN         NaN              -1     NaN              -1                 NaN           NaN        NaN        NaN        NaN                        NaN        NaN        NaN        NaN         NaN         NaN         NaN              -1        NaN        NaN        NaN        NaN        NaN              -1         NaN          NaN                            NaN                               NaN                                                NaN                  NaN        NaN                                NaN                            NaN                              NaN                        NaN         NaN         NaN         NaN              -1                                                NaN                                                NaN                                                NaN        NaN                                                NaN   \n",
       "8940        NaN        NaN        NaN        NaN        NaN         NaN        NaN        NaN         NaN         NaN         NaN              -1     NaN              -1                 NaN           NaN        NaN        NaN        NaN                        NaN        NaN        NaN        NaN         NaN         NaN         NaN              -1        NaN        NaN        NaN        NaN        NaN              -1         NaN          NaN                            NaN                               NaN                                                NaN                  NaN        NaN                                NaN                            NaN                              NaN                        NaN         NaN         NaN         NaN              -1                                                NaN                                                NaN                                                NaN        NaN                                                NaN   \n",
       "8941        NaN        SQL        NaN        NaN       Java         NaN        NaN       Bash         NaN         NaN         NaN              -1  Python              -1                 NaN   Matplotlib         NaN        NaN        NaN                        NaN        NaN        NaN        NaN         NaN         NaN         NaN              -1       CPUs        NaN        NaN        NaN        NaN              -1       Never    4-5 years  Linear or Logistic Regression  Decision Trees or Random Forests                                                NaN                  NaN        NaN                                NaN                            NaN                              NaN                        NaN         NaN         NaN         NaN              -1                                                NaN                                                NaN  Automated model selection (e.g. auto-sklearn, ...        NaN  Automated hyperparameter tuning (e.g. hyperopt...   \n",
       "\n",
       "                                             Q25_Part_6 Q25_Part_7 Q25_Part_8  Q25_OTHER_TEXT                                         Q26_Part_1                                         Q26_Part_2                                         Q26_Part_3                                         Q26_Part_4 Q26_Part_5 Q26_Part_6 Q26_Part_7  Q26_OTHER_TEXT                                         Q27_Part_1                                         Q27_Part_2 Q27_Part_3 Q27_Part_4 Q27_Part_5 Q27_Part_6  Q27_OTHER_TEXT       Q28_Part_1     Q28_Part_2 Q28_Part_3     Q28_Part_4 Q28_Part_5 Q28_Part_6 Q28_Part_7 Q28_Part_8    Q28_Part_9 Q28_Part_10 Q28_Part_11 Q28_Part_12  Q28_OTHER_TEXT                     Q29_Part_1                   Q29_Part_2         Q29_Part_3 Q29_Part_4 Q29_Part_5 Q29_Part_6 Q29_Part_7 Q29_Part_8 Q29_Part_9 Q29_Part_10 Q29_Part_11 Q29_Part_12  Q29_OTHER_TEXT                       Q30_Part_1                   Q30_Part_2  Q30_Part_3              Q30_Part_4 Q30_Part_5 Q30_Part_6  \\\n",
       "0                                                   NaN       None        NaN              -1                                                NaN                                                NaN                                                NaN                                                NaN        NaN        NaN        NaN              -1                                                NaN                                                NaN        NaN        NaN        NaN        NaN              -1              NaN            NaN        NaN            NaN        NaN        NaN        NaN        NaN           NaN         NaN        None         NaN              -1                            NaN                          NaN                NaN        NaN        NaN        NaN        NaN        NaN        NaN         NaN         NaN         NaN              -1                              NaN                          NaN         NaN                     NaN        NaN        NaN   \n",
       "1                                                   NaN        NaN        NaN              -1                                                NaN                                                NaN                                                NaN                                                NaN        NaN        NaN        NaN              -1                                                NaN                                                NaN        NaN        NaN        NaN        NaN              -1              NaN            NaN        NaN            NaN        NaN        NaN        NaN        NaN           NaN         NaN         NaN         NaN              -1                            NaN                          NaN                NaN        NaN        NaN        NaN        NaN        NaN        NaN         NaN         NaN         NaN              -1                              NaN                          NaN         NaN                     NaN        NaN        NaN   \n",
       "2     Automation of full ML pipelines (e.g. Google A...        NaN        NaN              -1                                                NaN                                                NaN                                                NaN                                                NaN        NaN       None        NaN              -1  Word embeddings/vectors (GLoVe, fastText, word...  Encoder-decorder models (seq2seq, vanilla tran...        NaN        NaN        NaN        NaN              -1    Scikit-learn     TensorFlow      Keras    RandomForest   Xgboost         NaN     Caret         NaN           NaN         NaN         NaN         NaN              -1                            NaN   Amazon Web Services (AWS)                 NaN        NaN        NaN        NaN        NaN        NaN        NaN         NaN         NaN         NaN              -1  AWS Elastic Compute Cloud (EC2)                          NaN         NaN                     NaN        NaN        NaN   \n",
       "3     Automation of full ML pipelines (e.g. Google A...        NaN        NaN              -1  General purpose image/video tools (PIL, cv2, s...  Image segmentation methods (U-Net, Mask R-CNN,...  Object detection methods (YOLOv3, RetinaNet, etc)                                                NaN        NaN        NaN        NaN              -1  Word embeddings/vectors (GLoVe, fastText, word...  Encoder-decorder models (seq2seq, vanilla tran...        NaN        NaN        NaN        NaN              -1    Scikit-learn     TensorFlow      Keras             NaN        NaN   PyTorch         NaN        NaN           NaN         NaN         NaN         NaN              -1   Google Cloud Platform (GCP)    Amazon Web Services (AWS)    Microsoft Azure         NaN        NaN        NaN        NaN        NaN        NaN         NaN         NaN         NaN              -1                              NaN  Google Compute Engine (GCE)  AWS Lambda  Azure Virtual Machines        NaN        NaN   \n",
       "4                                                   NaN       None        NaN              -1  General purpose image/video tools (PIL, cv2, s...                                                NaN                                                NaN  Image classification and other general purpose...        NaN        NaN        NaN              -1                                                NaN                                                NaN        NaN        NaN        NaN        NaN              -1    Scikit-learn     TensorFlow      Keras             NaN        NaN        NaN        NaN        NaN   Spark MLib          NaN         NaN         NaN              -1                            NaN                          NaN                NaN        NaN        NaN        NaN        NaN        NaN        NaN         NaN         NaN         NaN              -1                              NaN                          NaN         NaN                     NaN        NaN        NaN   \n",
       "...                                                 ...        ...        ...             ...                                                ...                                                ...                                                ...                                                ...        ...        ...        ...             ...                                                ...                                                ...        ...        ...        ...        ...             ...              ...            ...        ...            ...        ...        ...        ...        ...           ...         ...         ...         ...             ...                            ...                          ...                ...        ...        ...        ...        ...        ...        ...         ...         ...         ...             ...                              ...                          ...         ...                     ...        ...        ...   \n",
       "8937                                                NaN        NaN        NaN              -1                                                NaN                                                NaN                                                NaN                                                NaN        NaN        NaN        NaN              -1                                                NaN                                                NaN        NaN        NaN        NaN        NaN              -1              NaN            NaN        NaN            NaN        NaN        NaN        NaN        NaN           NaN         NaN         NaN         NaN              -1                            NaN                          NaN                NaN        NaN        NaN        NaN        NaN        NaN        NaN         NaN         NaN         NaN              -1                              NaN                          NaN         NaN                     NaN        NaN        NaN   \n",
       "8938                                                NaN        NaN        NaN              -1                                                NaN                                                NaN                                                NaN                                                NaN        NaN        NaN        NaN              -1                                                NaN                                                NaN        NaN        NaN        NaN        NaN              -1              NaN            NaN        NaN            NaN        NaN        NaN        NaN        NaN           NaN         NaN         NaN         NaN              -1                            NaN                          NaN                NaN        NaN        NaN        NaN        NaN        NaN        NaN         NaN         NaN         NaN              -1                              NaN                          NaN         NaN                     NaN        NaN        NaN   \n",
       "8939                                                NaN        NaN        NaN              -1                                                NaN                                                NaN                                                NaN                                                NaN        NaN        NaN        NaN              -1                                                NaN                                                NaN        NaN        NaN        NaN        NaN              -1              NaN            NaN        NaN            NaN        NaN        NaN        NaN        NaN           NaN         NaN         NaN         NaN              -1                            NaN                          NaN                NaN        NaN        NaN        NaN        NaN        NaN        NaN         NaN         NaN         NaN              -1                              NaN                          NaN         NaN                     NaN        NaN        NaN   \n",
       "8940                                                NaN        NaN        NaN              -1                                                NaN                                                NaN                                                NaN                                                NaN        NaN        NaN        NaN              -1                                                NaN                                                NaN        NaN        NaN        NaN        NaN              -1              NaN            NaN        NaN            NaN        NaN        NaN        NaN        NaN           NaN         NaN         NaN         NaN              -1                            NaN                          NaN                NaN        NaN        NaN        NaN        NaN        NaN        NaN         NaN         NaN         NaN              -1                              NaN                          NaN         NaN                     NaN        NaN        NaN   \n",
       "8941                                                NaN        NaN        NaN              -1                                                NaN                                                NaN                                                NaN                                                NaN        NaN        NaN        NaN              -1                                                NaN                                                NaN        NaN        NaN        NaN        NaN              -1    Scikit-learn             NaN        NaN            NaN        NaN        NaN        NaN        NaN   Spark MLib          NaN         NaN         NaN              -1                            NaN                          NaN                NaN        NaN        NaN        NaN        NaN        NaN        NaN         NaN         NaN         NaN              -1                              NaN                          NaN         NaN                     NaN        NaN        NaN   \n",
       "\n",
       "     Q30_Part_7 Q30_Part_8 Q30_Part_9 Q30_Part_10 Q30_Part_11 Q30_Part_12  Q30_OTHER_TEXT       Q31_Part_1 Q31_Part_2  Q31_Part_3             Q31_Part_4 Q31_Part_5 Q31_Part_6 Q31_Part_7 Q31_Part_8 Q31_Part_9 Q31_Part_10 Q31_Part_11 Q31_Part_12  Q31_OTHER_TEXT Q32_Part_1 Q32_Part_2                     Q32_Part_3                            Q32_Part_4 Q32_Part_5 Q32_Part_6 Q32_Part_7  Q32_Part_8 Q32_Part_9 Q32_Part_10 Q32_Part_11 Q32_Part_12  Q32_OTHER_TEXT       Q33_Part_1 Q33_Part_2 Q33_Part_3 Q33_Part_4 Q33_Part_5     Q33_Part_6       Q33_Part_7  Q33_Part_8 Q33_Part_9 Q33_Part_10 Q33_Part_11 Q33_Part_12  Q33_OTHER_TEXT Q34_Part_1   Q34_Part_2 Q34_Part_3 Q34_Part_4 Q34_Part_5 Q34_Part_6                       Q34_Part_7 Q34_Part_8 Q34_Part_9 Q34_Part_10 Q34_Part_11 Q34_Part_12  Q34_OTHER_TEXT  valid_response  yearly_comp_numerical  \n",
       "0           NaN        NaN        NaN         NaN         NaN         NaN              -1              NaN        NaN         NaN                    NaN        NaN        NaN        NaN        NaN        NaN         NaN         NaN         NaN              -1        NaN        NaN                            NaN                                   NaN        NaN        NaN        NaN         NaN        NaN         NaN         NaN         NaN              -1              NaN        NaN        NaN        NaN        NaN            NaN              NaN         NaN        NaN         NaN         NaN         NaN              -1        NaN          NaN        NaN        NaN        NaN        NaN                              NaN        NaN        NaN         NaN         NaN         NaN              -1               1                34999.5  \n",
       "1           NaN        NaN        NaN         NaN         NaN         NaN              -1              NaN        NaN         NaN                    NaN        NaN        NaN        NaN        NaN        NaN         NaN         NaN         NaN              -1        NaN        NaN                            NaN                                   NaN        NaN        NaN        NaN         NaN        NaN         NaN         NaN         NaN              -1              NaN        NaN        NaN        NaN        NaN            NaN              NaN         NaN        NaN         NaN         NaN         NaN              -1        NaN          NaN        NaN        NaN        NaN        NaN                              NaN        NaN        NaN         NaN         NaN         NaN              -1               1                 6249.5  \n",
       "2           NaN        NaN        NaN         NaN         NaN         NaN              -1              NaN        NaN         NaN  AWS Elastic MapReduce        NaN        NaN        NaN        NaN        NaN         NaN         NaN         NaN              -1        NaN        NaN                            NaN                                   NaN        NaN        NaN        NaN  RapidMiner        NaN         NaN         NaN         NaN              -1              NaN        NaN        NaN        NaN        NaN    Auto-Keras               NaN         NaN        NaN         NaN         NaN         NaN              -1        NaN  PostgresSQL        NaN        NaN        NaN        NaN  AWS Relational Database Service        NaN        NaN         NaN         NaN         NaN              -1               1                64999.5  \n",
       "3           NaN        NaN        NaN         NaN         NaN         NaN              -1  Google BigQuery        NaN  Databricks                    NaN        NaN        NaN        NaN        NaN        NaN         NaN         NaN         NaN              -1        SAS        NaN  Azure Machine Learning Studio  Google Cloud Machine Learning Engine        NaN        NaN        NaN         NaN        NaN         NaN         NaN         NaN              -1   Google AutoML         NaN        NaN        NaN      Tpot     Auto-Keras     Auto-Sklearn     Auto_ml         NaN         NaN         NaN         NaN              -1      MySQL  PostgresSQL        NaN        NaN        NaN        NaN                              NaN        NaN        NaN         NaN         NaN         NaN              -1               1                12499.5  \n",
       "4           NaN        NaN        NaN         NaN         NaN         NaN              -1              NaN        NaN         NaN                    NaN        NaN        NaN        NaN        NaN        NaN         NaN         NaN         NaN              -1        NaN        NaN                            NaN                                   NaN        NaN        NaN        NaN         NaN        NaN         NaN         NaN         NaN              -1              NaN        NaN        NaN        NaN        NaN            NaN              NaN         NaN        NaN         NaN         NaN         NaN              -1        NaN          NaN        NaN        NaN        NaN        NaN                              NaN        NaN        NaN         NaN         NaN         NaN              -1               1                84999.5  \n",
       "...         ...        ...        ...         ...         ...         ...             ...              ...        ...         ...                    ...        ...        ...        ...        ...        ...         ...         ...         ...             ...        ...        ...                            ...                                   ...        ...        ...        ...         ...        ...         ...         ...         ...             ...              ...        ...        ...        ...        ...            ...              ...         ...        ...         ...         ...         ...             ...        ...          ...        ...        ...        ...        ...                              ...        ...        ...         ...         ...         ...             ...             ...                    ...  \n",
       "8937        NaN        NaN        NaN         NaN         NaN         NaN              -1              NaN        NaN         NaN                    NaN        NaN        NaN        NaN        NaN        NaN         NaN         NaN         NaN              -1        NaN        NaN                            NaN                                   NaN        NaN        NaN        NaN         NaN        NaN         NaN         NaN         NaN              -1              NaN        NaN        NaN        NaN        NaN            NaN              NaN         NaN        NaN         NaN         NaN         NaN              -1        NaN          NaN        NaN        NaN        NaN        NaN                              NaN        NaN        NaN         NaN         NaN         NaN              -1               1                 8749.5  \n",
       "8938        NaN        NaN        NaN         NaN         NaN         NaN              -1              NaN        NaN         NaN                    NaN        NaN        NaN        NaN        NaN        NaN         NaN         NaN         NaN              -1        NaN        NaN                            NaN                                   NaN        NaN        NaN        NaN         NaN        NaN         NaN         NaN         NaN              -1              NaN        NaN        NaN        NaN        NaN            NaN              NaN         NaN        NaN         NaN         NaN         NaN              -1        NaN          NaN        NaN        NaN        NaN        NaN                              NaN        NaN        NaN         NaN         NaN         NaN              -1               1                 8749.5  \n",
       "8939        NaN        NaN        NaN         NaN         NaN         NaN              -1              NaN        NaN         NaN                    NaN        NaN        NaN        NaN        NaN        NaN         NaN         NaN         NaN              -1        NaN        NaN                            NaN                                   NaN        NaN        NaN        NaN         NaN        NaN         NaN         NaN         NaN              -1              NaN        NaN        NaN        NaN        NaN            NaN              NaN         NaN        NaN         NaN         NaN         NaN              -1        NaN          NaN        NaN        NaN        NaN        NaN                              NaN        NaN        NaN         NaN         NaN         NaN              -1               1                    0.0  \n",
       "8940        NaN        NaN        NaN         NaN         NaN         NaN              -1              NaN        NaN         NaN                    NaN        NaN        NaN        NaN        NaN        NaN         NaN         NaN         NaN              -1        NaN        NaN                            NaN                                   NaN        NaN        NaN        NaN         NaN        NaN         NaN         NaN         NaN              -1              NaN        NaN        NaN        NaN        NaN            NaN              NaN         NaN        NaN         NaN         NaN         NaN              -1        NaN          NaN        NaN        NaN        NaN        NaN                              NaN        NaN        NaN         NaN         NaN         NaN              -1               1                 8749.5  \n",
       "8941        NaN        NaN        NaN         NaN         NaN         NaN              -1              NaN        NaN         NaN                    NaN        NaN        NaN        NaN        NaN        NaN         NaN         NaN         NaN              -1        NaN        NaN                            NaN                                   NaN        NaN        NaN        NaN         NaN        NaN         NaN         NaN         NaN              -1              NaN        NaN        NaN        NaN        NaN            NaN              NaN         NaN        NaN         NaN         NaN         NaN              -1        NaN          NaN        NaN        NaN        NaN        NaN                              NaN        NaN        NaN         NaN         NaN         NaN              -1               1                64999.5  \n",
       "\n",
       "[8942 rows x 248 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "In order to find cut-off point between compensation levels quartiles were used.\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.250      8749.5\n",
       "0.500     34999.5\n",
       "0.750     74999.5\n",
       "0.800     94999.5\n",
       "0.825     94999.5\n",
       "0.850    112499.5\n",
       "0.875    112499.5\n",
       "0.900    137499.5\n",
       "0.950    174999.5\n",
       "Name: yearly_comp_numerical, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#quantiles of compensation\n",
    "###################################\n",
    "df_pred.yearly_comp_numerical.quantile([0.25,0.5,0.75,0.8,0.825,0.85,0.875,0.9,0.95])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "The following outlines the feature selection (and transformation) process for the predictive model. The initial selection was based on a variable’s theoretical relevance for the classification model, followed by an iterative validation of the selection on the classifier itself.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "Dataframe (before Feature Selection): (8942, 248)\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "#size of dataset\n",
    "###################################\n",
    "print('-'*10)\n",
    "print('Dataframe (before Feature Selection):', df_pred.shape)\n",
    "print('-'*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape Questions:  34\n",
      "Shape Responses:  34\n"
     ]
    }
   ],
   "source": [
    "#combining the ressponses and questions on a per question basis\n",
    "###################################\n",
    "\n",
    "#dict for questions\n",
    "questions = {\n",
    "    'Q1': 'What is your gender?',\n",
    "    'Q2': 'What is your age (# years)?',\n",
    "    'Q3': 'In which country do you currently reside?',\n",
    "    'Q4': 'What is the highest level of formal education that you have attained or plan to attain within the next 2 years?',\n",
    "    'Q5': 'Which best describes your undergraduate major?',\n",
    "    'Q6': 'Select the title most similar to your current role (or most recent title if retired)',\n",
    "    'Q7': 'In what industry is your current employer/contract (or your most recent employer if retired)?',\n",
    "    'Q8': 'Does your current employer incorporate machine leanring?',\n",
    "    'Q9': 'Select any activities that make up an important part of your role at work.',\n",
    "    'Q10': 'What is your current yearly compensation?',\n",
    "    'Q11': 'Approximately how much money have you spent on machine learning and/or cloud computing products at your work in the past 5 years?',\n",
    "    'Q12': 'Who/what are your favorite media sources that report on data science topics?',\n",
    "    'Q13': 'On which platforms have you begun or completed data science courses?',\n",
    "    'Q14': 'What is the primary tool that you use at work or school to analyze data?',\n",
    "    'Q15': 'How long have you been writing code to analyze data?',\n",
    "    'Q16': 'Which of the following integrated development environments (IDEs) do you use on a regular basis?',\n",
    "    'Q17': 'Which of the following hosted notebook products do you use on a regular basis?',\n",
    "    'Q18': 'What programming languages do you use on a regular basis?',\n",
    "    'Q19': 'What programming language would you recommend an aspiring data scientist to learn first?',\n",
    "    'Q20': 'What data visualization libraries or tools do you use on a regular basis?',\n",
    "    'Q21': 'Which types of specialized hardware do you use on a regular basis?',\n",
    "    'Q22': 'Have you ever used a TPU (tensor processing unit)?',\n",
    "    'Q23': 'For how many years have you used machine learning methods?',\n",
    "    'Q24': 'Which of the following ML algorithms do you use on a regular basis?',\n",
    "    'Q25': 'Which categories of ML tools do you use on a regular basis?',\n",
    "    'Q26': 'Which categories of computer vision methods do you use on a regular basis?',\n",
    "    'Q27': 'Which of the following natural language processing (NLP) methods do you use on a regular basis?',\n",
    "    'Q28': 'Which of the following machine learning frameworks do you use on a regular basis?',\n",
    "    'Q29': 'Which of the following cloud computing platforms do you use on a regular basis?',\n",
    "    'Q30': 'Which specific cloud computing products do you use on a regular basis?',\n",
    "    'Q31': 'Which specific big data / analytics products do you use on a regular basis?',\n",
    "    'Q32': 'Which of the following machine learning products do you use on a regular basis?',\n",
    "    'Q33': 'Which automated machine learning tools (or partial AutoML tools) do you use on a regular basis?',\n",
    "    'Q34': 'Which of the following relational database products do you use on a regular basis?',\n",
    "}\n",
    "#questions\n",
    "\n",
    "#dict for responses\n",
    "responses = {'Q1': df_pred.iloc[:,1],'Q2': df_pred.iloc[:,2],'Q3': df_pred.iloc[:,4],\n",
    "           'Q4': df_pred.iloc[:,5],'Q5': df_pred.iloc[:,6],'Q6': df_pred.iloc[:,8],\n",
    "           'Q7': df_pred.iloc[:,9],'Q8': df_pred.iloc[:,10],'Q9': df_pred.iloc[:,11:19],\n",
    "           'Q10': df_pred.iloc[:,20],'Q11': df_pred.iloc[:,21],'Q12': df_pred.iloc[:,22:34],\n",
    "           'Q13': df_pred.iloc[:,35:47],'Q14': df_pred.iloc[:,48:49],'Q15': df_pred.iloc[:,55:56],\n",
    "           'Q16': df_pred.iloc[:,56:69],'Q17': df_pred.iloc[:,69:82],'Q18': df_pred.iloc[:,82:95],\n",
    "           'Q19': df_pred.iloc[:,95:97],'Q20': df_pred.iloc[:,97:110],'Q21': df_pred.iloc[:,110:116],\n",
    "           'Q22': df_pred.iloc[:,116:117],'Q23': df_pred.iloc[:,117:118],'Q24': df_pred.iloc[:,118:131],\n",
    "           'Q25': df_pred.iloc[:,131:140],'Q26': df_pred.iloc[:,140:148],'Q27': df_pred.iloc[:,148:155],\n",
    "           'Q28': df_pred.iloc[:,155:168],'Q29': df_pred.iloc[:,168:181],'Q30': df_pred.iloc[:,181:194],\n",
    "           'Q31': df_pred.iloc[:,194:207],'Q32': df_pred.iloc[:,207:220],'Q33': df_pred.iloc[:,220:233],\n",
    "           'Q34': df_pred.iloc[:,233:246],\n",
    "          } \n",
    "#responses\n",
    "\n",
    "#output\n",
    "print('Shape Questions: ',len(questions))\n",
    "print('Shape Responses: ',len(responses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions to handle predcition data are defined\n",
    "##############################\n",
    "\n",
    "#normalize labels of defined dicts\n",
    "def normalize_labels(insert_label):\n",
    "    try:\n",
    "        label_short = insert_label.split('<>')[1] \n",
    "    except IndexError:\n",
    "        label_short = insert_label.split('<>')[0]\n",
    "    return label_short\n",
    "\n",
    "#function to treat question data accordingly\n",
    "def handle_data(data, idx, tresh):\n",
    "    result = pd.get_dummies(data, prefix_sep='<>', drop_first=False)\n",
    "    #print(result)\n",
    "    cols = [normalize_labels(str(x)) for x in result.columns]\n",
    "    try:\n",
    "        Qtext = df_pred['Q{}'.format(idx)]\n",
    "    except KeyError:\n",
    "        try:\n",
    "            Qtext = df_pred['Q{}_Part_1'.format(idx)]\n",
    "        except KeyError:\n",
    "            Qtext = df_pred['Q{}_MULTIPLE_CHOICE'.format(idx)]\n",
    "            \n",
    "    #renaming of features\n",
    "    prefix = 'Q{}-'.format(idx)\n",
    "    result.columns = [prefix + x for x in cols]\n",
    "    \n",
    "    #filter for questions below required reponse rate\n",
    "    percent_answer = result.sum() / result.shape[0]\n",
    "    #print(percent_answer)\n",
    "    for row in percent_answer.iteritems():\n",
    "        if row[1] < tresh:\n",
    "            result = result.drop(row[0], axis=1)\n",
    "    return result\n",
    "\n",
    "#code inspored by similar classification prediction: https://www.kaggle.com/andresionek/what-makes-a-kaggler-valuable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "As outlined in great detail within the report, data selection for the prediction model is crucial. The below selects several questions most important for the prediction.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#question selection for predition model\n",
    "##############################\n",
    "\n",
    "############################################################################\n",
    "questions = [1,2,3,4,5,6,7,8,9,11,12,13,14,15,22,23,26]\n",
    "############################################################################\n",
    "\n",
    "dict_treat_data = {}\n",
    "\n",
    "#removing questions w/ less than 5% respondents answering\n",
    "for sq in questions:\n",
    "    #print('Q{}'.format(sq))\n",
    "    dict_treat_data['Q{}'.format(sq)] = handle_data(responses['Q{}'.format(sq)], sq, 0.05)\n",
    "    #print(treated_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Variable Engineering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Target variables engineering commenced. As outlined every response with annual compensation above the 75% quartile (74999,5) is labeled as 'top25' of professionals.\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8942, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>top25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  top25\n",
       "0      0      0\n",
       "1      1      0\n",
       "2      2      0\n",
       "3      3      0\n",
       "4      4      1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transform for analysis of top quartile in terms of compensation\n",
    "##############################\n",
    "\n",
    "clean_dataset = (df_pred.yearly_comp_numerical >= 74999.5).reset_index().astype(int)\n",
    "#print(clean_dataset)\n",
    "clean_dataset.columns = ['index', 'top25']\n",
    "\n",
    "#output\n",
    "print(clean_dataset.shape)\n",
    "clean_dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset:  (8942, 97)\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top25</th>\n",
       "      <th>Q1-22-24</th>\n",
       "      <th>Q1-25-29</th>\n",
       "      <th>Q1-30-34</th>\n",
       "      <th>Q1-35-39</th>\n",
       "      <th>Q1-40-44</th>\n",
       "      <th>Q1-45-49</th>\n",
       "      <th>Q2-Female</th>\n",
       "      <th>Q2-Male</th>\n",
       "      <th>Q3-India</th>\n",
       "      <th>Q3-Other</th>\n",
       "      <th>Q3-United States of America</th>\n",
       "      <th>Q4-Bachelor’s degree</th>\n",
       "      <th>Q4-Doctoral degree</th>\n",
       "      <th>Q4-Master’s degree</th>\n",
       "      <th>Q5-Business/Data Analyst</th>\n",
       "      <th>Q5-Data Scientist</th>\n",
       "      <th>Q5-Data/Software Engineer</th>\n",
       "      <th>Q5-Product/Project Manager</th>\n",
       "      <th>Q5-Researcher</th>\n",
       "      <th>Q6-0-49 employees</th>\n",
       "      <th>Q6-1000-9,999 employees</th>\n",
       "      <th>Q6-250-999 employees</th>\n",
       "      <th>Q6-50-249 employees</th>\n",
       "      <th>Q6-&gt; 10,000 employees</th>\n",
       "      <th>Q7-0</th>\n",
       "      <th>Q7-1-2</th>\n",
       "      <th>Q7-10-14</th>\n",
       "      <th>Q7-20+</th>\n",
       "      <th>Q7-3-4</th>\n",
       "      <th>Q7-5-9</th>\n",
       "      <th>Q8-I do not know</th>\n",
       "      <th>Q8-No (we do not use ML methods)</th>\n",
       "      <th>Q8-We are exploring ML methods (and may one day put a model into production)</th>\n",
       "      <th>Q8-We have well established ML methods (i.e., models in production for more than 2 years)</th>\n",
       "      <th>Q8-We recently started using ML methods (i.e., models in production for less than 2 years)</th>\n",
       "      <th>Q8-We use ML methods for generating insights (but do not put working models into production)</th>\n",
       "      <th>Q9-Analyze and understand data to influence product or business decisions</th>\n",
       "      <th>Q9-Build and/or run the data infrastructure that my business uses for storing, analyzing, and operationalizing data</th>\n",
       "      <th>Q9-Build prototypes to explore applying machine learning to new areas</th>\n",
       "      <th>Q9-Build and/or run a machine learning service that operationally improves my product or workflows</th>\n",
       "      <th>Q9-Experimentation and iteration to improve existing ML models</th>\n",
       "      <th>Q9-Do research that advances the state of the art of machine learning</th>\n",
       "      <th>Q11-$0 (USD)</th>\n",
       "      <th>Q11-$1-$99</th>\n",
       "      <th>Q11-$10,000-$99,999</th>\n",
       "      <th>Q11-$100-$999</th>\n",
       "      <th>Q11-$1000-$9,999</th>\n",
       "      <th>Q11-&gt; $100,000 ($USD)</th>\n",
       "      <th>Q12-Twitter (data science influencers)</th>\n",
       "      <th>Q12-Hacker News (https://news.ycombinator.com/)</th>\n",
       "      <th>Q12-Reddit (r/machinelearning, r/datascience, etc)</th>\n",
       "      <th>Q12-Kaggle (forums, blog, social media, etc)</th>\n",
       "      <th>Q12-Course Forums (forums.fast.ai, etc)</th>\n",
       "      <th>Q12-YouTube (Cloud AI Adventures, Siraj Raval, etc)</th>\n",
       "      <th>Q12-Podcasts (Chai Time Data Science, Linear Digressions, etc)</th>\n",
       "      <th>Q12-Blogs (Towards Data Science, Medium, Analytics Vidhya, KDnuggets etc)</th>\n",
       "      <th>Q12-Journal Publications (traditional publications, preprint journals, etc)</th>\n",
       "      <th>Q12-Slack Communities (ods.ai, kagglenoobs, etc)</th>\n",
       "      <th>Q12-Other</th>\n",
       "      <th>Q13-Udacity</th>\n",
       "      <th>Q13-Coursera</th>\n",
       "      <th>Q13-edX</th>\n",
       "      <th>Q13-DataCamp</th>\n",
       "      <th>Q13-Kaggle Courses (i.e. Kaggle Learn)</th>\n",
       "      <th>Q13-Fast.ai</th>\n",
       "      <th>Q13-Udemy</th>\n",
       "      <th>Q13-LinkedIn Learning</th>\n",
       "      <th>Q13-University Courses (resulting in a university degree)</th>\n",
       "      <th>Q13-None</th>\n",
       "      <th>Q13-Other</th>\n",
       "      <th>Q14-Advanced statistical software (SPSS, SAS, etc.)</th>\n",
       "      <th>Q14-Basic statistical software (Microsoft Excel, Google Sheets, etc.)</th>\n",
       "      <th>Q14-Business intelligence software (Salesforce, Tableau, Spotfire, etc.)</th>\n",
       "      <th>Q14-Cloud-based data software &amp; APIs (AWS, GCP, Azure, etc.)</th>\n",
       "      <th>Q14-Local development environments (RStudio, JupyterLab, etc.)</th>\n",
       "      <th>Q14-Other</th>\n",
       "      <th>Q15-1-2 years</th>\n",
       "      <th>Q15-10-20 years</th>\n",
       "      <th>Q15-3-5 years</th>\n",
       "      <th>Q15-5-10 years</th>\n",
       "      <th>Q15-&lt; 1 years</th>\n",
       "      <th>Q22-2-5 times</th>\n",
       "      <th>Q22-Never</th>\n",
       "      <th>Q22-Once</th>\n",
       "      <th>Q23-1-2 years</th>\n",
       "      <th>Q23-2-3 years</th>\n",
       "      <th>Q23-3-4 years</th>\n",
       "      <th>Q23-4-5 years</th>\n",
       "      <th>Q23-5-10 years</th>\n",
       "      <th>Q23-&lt; 1 years</th>\n",
       "      <th>Q26-General purpose image/video tools (PIL, cv2, skimage, etc)</th>\n",
       "      <th>Q26-Image segmentation methods (U-Net, Mask R-CNN, etc)</th>\n",
       "      <th>Q26-Object detection methods (YOLOv3, RetinaNet, etc)</th>\n",
       "      <th>Q26-Image classification and other general purpose networks (VGG, Inception, ResNet, ResNeXt, NASNet, EfficientNet, etc)</th>\n",
       "      <th>Q26-Generative Networks (GAN, VAE, etc)</th>\n",
       "      <th>Q26-None</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   top25  Q1-22-24  Q1-25-29  Q1-30-34  Q1-35-39  Q1-40-44  Q1-45-49  Q2-Female  Q2-Male  Q3-India  Q3-Other  Q3-United States of America  Q4-Bachelor’s degree  Q4-Doctoral degree  Q4-Master’s degree  Q5-Business/Data Analyst  Q5-Data Scientist  Q5-Data/Software Engineer  Q5-Product/Project Manager  Q5-Researcher  Q6-0-49 employees  Q6-1000-9,999 employees  Q6-250-999 employees  Q6-50-249 employees  Q6-> 10,000 employees  Q7-0  Q7-1-2  Q7-10-14  Q7-20+  Q7-3-4  Q7-5-9  Q8-I do not know  Q8-No (we do not use ML methods)  Q8-We are exploring ML methods (and may one day put a model into production)  Q8-We have well established ML methods (i.e., models in production for more than 2 years)  Q8-We recently started using ML methods (i.e., models in production for less than 2 years)  Q8-We use ML methods for generating insights (but do not put working models into production)  Q9-Analyze and understand data to influence product or business decisions  \\\n",
       "0      0         1         0         0         0         0         0          0        1         0         0                            0                     0                   0                   1                         0                  0                          1                           0              0                  0                        1                     0                    0                      0     1       0         0       0       0       0                 1                                 0                                                  0                                                                             0                                                                                          0                                                                                           0                                                                                             0                           \n",
       "1      0         0         0         0         0         1         0          0        1         1         0                            0                     0                   0                   0                         0                  0                          1                           0              0                  0                        0                     0                    0                      1     0       0         0       1       0       0                 0                                 0                                                  0                                                                             1                                                                                          0                                                                                           0                                                                                             1                           \n",
       "2      0         0         0         0         0         0         0          0        1         0         0                            0                     0                   0                   1                         0                  1                          0                           0              0                  1                        0                     0                    0                      0     0       0         0       0       1       0                 0                                 0                                                  0                                                                             1                                                                                          0                                                                                           0                                                                                             0                           \n",
       "3      0         1         0         0         0         0         0          0        1         1         0                            0                     0                   0                   1                         0                  1                          0                           0              0                  0                        0                     0                    1                      0     0       0         0       1       0       0                 0                                 0                                                  1                                                                             0                                                                                          0                                                                                           0                                                                                             1                           \n",
       "4      1         1         0         0         0         0         0          1        0         0         0                            1                     1                   0                   0                         0                  1                          0                           0              0                  0                        0                     0                    0                      1     0       0         0       1       0       0                 0                                 0                                                  0                                                                             0                                                                                          1                                                                                           0                                                                                             1                           \n",
       "\n",
       "   Q9-Build and/or run the data infrastructure that my business uses for storing, analyzing, and operationalizing data  Q9-Build prototypes to explore applying machine learning to new areas  Q9-Build and/or run a machine learning service that operationally improves my product or workflows  Q9-Experimentation and iteration to improve existing ML models  Q9-Do research that advances the state of the art of machine learning  Q11-$0 (USD)  Q11-$1-$99  Q11-$10,000-$99,999  Q11-$100-$999  Q11-$1000-$9,999  Q11-> $100,000 ($USD)  Q12-Twitter (data science influencers)  Q12-Hacker News (https://news.ycombinator.com/)  Q12-Reddit (r/machinelearning, r/datascience, etc)  Q12-Kaggle (forums, blog, social media, etc)  Q12-Course Forums (forums.fast.ai, etc)  Q12-YouTube (Cloud AI Adventures, Siraj Raval, etc)  Q12-Podcasts (Chai Time Data Science, Linear Digressions, etc)  Q12-Blogs (Towards Data Science, Medium, Analytics Vidhya, KDnuggets etc)  \\\n",
       "0                                                  0                                                                                                                    0                                                                      0                                                                                                   0                                                               0                                 1           0                    0              0                 0                      0                                       1                                                0                                                  0                                              1                                        0                                                  0                                                    0                                                               1                           \n",
       "1                                                  1                                                                                                                    1                                                                      1                                                                                                   0                                                               0                                 0           0                    0              0                 0                      1                                       0                                                0                                                  0                                              1                                        0                                                  1                                                    1                                                               1                           \n",
       "2                                                  0                                                                                                                    1                                                                      0                                                                                                   0                                                               1                                 0           0                    1              0                 0                      0                                       0                                                0                                                  0                                              0                                        0                                                  1                                                    0                                                               1                           \n",
       "3                                                  0                                                                                                                    0                                                                      0                                                                                                   1                                                               1                                 0           0                    0              1                 0                      0                                       0                                                0                                                  0                                              1                                        1                                                  1                                                    1                                                               0                           \n",
       "4                                                  0                                                                                                                    1                                                                      1                                                                                                   0                                                               0                                 1           0                    0              0                 0                      0                                       0                                                1                                                  0                                              0                                        0                                                  0                                                    0                                                               1                           \n",
       "\n",
       "   Q12-Journal Publications (traditional publications, preprint journals, etc)  Q12-Slack Communities (ods.ai, kagglenoobs, etc)  Q12-Other  Q13-Udacity  Q13-Coursera  Q13-edX  Q13-DataCamp  Q13-Kaggle Courses (i.e. Kaggle Learn)  Q13-Fast.ai  Q13-Udemy  Q13-LinkedIn Learning  Q13-University Courses (resulting in a university degree)  Q13-None  Q13-Other  Q14-Advanced statistical software (SPSS, SAS, etc.)  Q14-Basic statistical software (Microsoft Excel, Google Sheets, etc.)  Q14-Business intelligence software (Salesforce, Tableau, Spotfire, etc.)  Q14-Cloud-based data software & APIs (AWS, GCP, Azure, etc.)  Q14-Local development environments (RStudio, JupyterLab, etc.)  Q14-Other  Q15-1-2 years  Q15-10-20 years  Q15-3-5 years  Q15-5-10 years  Q15-< 1 years  Q22-2-5 times  Q22-Never  Q22-Once  Q23-1-2 years  Q23-2-3 years  Q23-3-4 years  Q23-4-5 years  Q23-5-10 years  Q23-< 1 years  Q26-General purpose image/video tools (PIL, cv2, skimage, etc)  \\\n",
       "0                                                  1                                                                           0          0            0             1        0             1                                       1            0          1                      0                                                  0                 0          0                                                  0                                                    1                                                                      0                                                                         0                                                             0                       0              1                0              0               0              0              0          1         0              1              0              0              0               0              0                                                  0                \n",
       "1                                                  0                                                                           0          0            0             1        0             1                                       1            0          1                      0                                                  0                 0          0                                                  0                                                    0                                                                      0                                                                         1                                                             0                       0              0                0              0               0              0              0          0         0              0              0              0              0               0              0                                                  0                \n",
       "2                                                  1                                                                           0          0            0             0        0             0                                       0            0          0                      0                                                  0                 1          0                                                  1                                                    0                                                                      0                                                                         0                                                             0                       0              0                0              0               0              0              0          1         0              0              0              0              0               0              0                                                  0                \n",
       "3                                                  1                                                                           0          0            1             1        1             0                                       1            0          1                      0                                                  0                 0          0                                                  0                                                    0                                                                      0                                                                         0                                                             1                       0              0                0              1               0              0              0          0         0              0              1              0              0               0              0                                                  1                \n",
       "4                                                  1                                                                           0          0            0             0        0             0                                       0            0          1                      0                                                  1                 0          0                                                  0                                                    0                                                                      0                                                                         0                                                             1                       0              0                0              1               0              0              0          0         1              0              0              1              0               0              0                                                  1                \n",
       "\n",
       "   Q26-Image segmentation methods (U-Net, Mask R-CNN, etc)  Q26-Object detection methods (YOLOv3, RetinaNet, etc)  Q26-Image classification and other general purpose networks (VGG, Inception, ResNet, ResNeXt, NASNet, EfficientNet, etc)  Q26-Generative Networks (GAN, VAE, etc)  Q26-None  \n",
       "0                                                  0                                                        0                                                      0                                                                                                               0         0  \n",
       "1                                                  0                                                        0                                                      0                                                                                                               0         0  \n",
       "2                                                  0                                                        0                                                      0                                                                                                               0         1  \n",
       "3                                                  1                                                        1                                                      0                                                                                                               0         0  \n",
       "4                                                  0                                                        0                                                      1                                                                                                               0         0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#comebine questions, resonsesn and target variable ('top25')\n",
    "##############################\n",
    "\n",
    "#combining loop\n",
    "for indicator, val in dict_treat_data.items():\n",
    "    val = val.reset_index(drop=True)\n",
    "    clean_dataset = clean_dataset.join(val, how='left')\n",
    "\n",
    "clean_dataset = clean_dataset.drop('index', axis=1)\n",
    "\n",
    "#output\n",
    "print('Cleaned dataset: ',clean_dataset.shape)\n",
    "print('-'*10)\n",
    "clean_dataset.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Following the creation of the normalized (and combined) data frame for preiction, one has to look at correlation / co-occurance of variables. Using build in python features the correlation matrix is calculated below.\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Frame following Correlation Cleaning:  (8942, 95)\n",
      "----------\n",
      "Dropped features: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Q2-Male',\n",
       " 'Q26-Image classification and other general purpose networks (VGG, Inception, ResNet, ResNeXt, NASNet, EfficientNet, etc)']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Correlation measures\n",
    "####################################\n",
    "\n",
    "#correlation matrix\n",
    "correl = clean_dataset.corr().abs()\n",
    "\n",
    "upper_tri = correl.where(np.triu(np.ones(correl.shape), k=1).astype(np.bool))\n",
    "\n",
    "#set correlation maximum at 0.6 and find respective variables\n",
    "drop_vars = [column for column in upper_tri.columns if any(upper_tri[column] > 0.6)]\n",
    "\n",
    "#dropping correlated features\n",
    "clean_dataset_dropped = clean_dataset.drop(drop_vars, axis=1)\n",
    "\n",
    "#output\n",
    "print('Data Frame following Correlation Cleaning: ',clean_dataset_dropped.shape)\n",
    "print('-'*10)\n",
    "print('Dropped features: ')\n",
    "drop_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of remaining NaNs:  0\n"
     ]
    }
   ],
   "source": [
    "#check for remaining NaNs in data\n",
    "####################################\n",
    "df = clean_dataset_dropped.isnull().sum().to_frame()\n",
    "#output\n",
    "print('Number of remaining NaNs: ',df[df[0] > 0].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Class Balance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "One can observe target variable inblance, in other words, one label being overproportionally represented. In this specific case label {0} = non-top earner represents the majority.\n",
    "As discussed within the final report sample imblance can cause model perfromance losses. Therefore, the following will downsample the majority class.\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top25</th>\n",
       "      <th>Q1-22-24</th>\n",
       "      <th>Q1-25-29</th>\n",
       "      <th>Q1-30-34</th>\n",
       "      <th>Q1-35-39</th>\n",
       "      <th>Q1-40-44</th>\n",
       "      <th>Q1-45-49</th>\n",
       "      <th>Q2-Female</th>\n",
       "      <th>Q3-India</th>\n",
       "      <th>Q3-Other</th>\n",
       "      <th>Q3-United States of America</th>\n",
       "      <th>Q4-Bachelor’s degree</th>\n",
       "      <th>Q4-Doctoral degree</th>\n",
       "      <th>Q4-Master’s degree</th>\n",
       "      <th>Q5-Business/Data Analyst</th>\n",
       "      <th>Q5-Data Scientist</th>\n",
       "      <th>Q5-Data/Software Engineer</th>\n",
       "      <th>Q5-Product/Project Manager</th>\n",
       "      <th>Q5-Researcher</th>\n",
       "      <th>Q6-0-49 employees</th>\n",
       "      <th>Q6-1000-9,999 employees</th>\n",
       "      <th>Q6-250-999 employees</th>\n",
       "      <th>Q6-50-249 employees</th>\n",
       "      <th>Q6-&gt; 10,000 employees</th>\n",
       "      <th>Q7-0</th>\n",
       "      <th>Q7-1-2</th>\n",
       "      <th>Q7-10-14</th>\n",
       "      <th>Q7-20+</th>\n",
       "      <th>Q7-3-4</th>\n",
       "      <th>Q7-5-9</th>\n",
       "      <th>Q8-I do not know</th>\n",
       "      <th>Q8-No (we do not use ML methods)</th>\n",
       "      <th>Q8-We are exploring ML methods (and may one day put a model into production)</th>\n",
       "      <th>Q8-We have well established ML methods (i.e., models in production for more than 2 years)</th>\n",
       "      <th>Q8-We recently started using ML methods (i.e., models in production for less than 2 years)</th>\n",
       "      <th>Q8-We use ML methods for generating insights (but do not put working models into production)</th>\n",
       "      <th>Q9-Analyze and understand data to influence product or business decisions</th>\n",
       "      <th>Q9-Build and/or run the data infrastructure that my business uses for storing, analyzing, and operationalizing data</th>\n",
       "      <th>Q9-Build prototypes to explore applying machine learning to new areas</th>\n",
       "      <th>Q9-Build and/or run a machine learning service that operationally improves my product or workflows</th>\n",
       "      <th>Q9-Experimentation and iteration to improve existing ML models</th>\n",
       "      <th>Q9-Do research that advances the state of the art of machine learning</th>\n",
       "      <th>Q11-$0 (USD)</th>\n",
       "      <th>Q11-$1-$99</th>\n",
       "      <th>Q11-$10,000-$99,999</th>\n",
       "      <th>Q11-$100-$999</th>\n",
       "      <th>Q11-$1000-$9,999</th>\n",
       "      <th>Q11-&gt; $100,000 ($USD)</th>\n",
       "      <th>Q12-Twitter (data science influencers)</th>\n",
       "      <th>Q12-Hacker News (https://news.ycombinator.com/)</th>\n",
       "      <th>Q12-Reddit (r/machinelearning, r/datascience, etc)</th>\n",
       "      <th>Q12-Kaggle (forums, blog, social media, etc)</th>\n",
       "      <th>Q12-Course Forums (forums.fast.ai, etc)</th>\n",
       "      <th>Q12-YouTube (Cloud AI Adventures, Siraj Raval, etc)</th>\n",
       "      <th>Q12-Podcasts (Chai Time Data Science, Linear Digressions, etc)</th>\n",
       "      <th>Q12-Blogs (Towards Data Science, Medium, Analytics Vidhya, KDnuggets etc)</th>\n",
       "      <th>Q12-Journal Publications (traditional publications, preprint journals, etc)</th>\n",
       "      <th>Q12-Slack Communities (ods.ai, kagglenoobs, etc)</th>\n",
       "      <th>Q12-Other</th>\n",
       "      <th>Q13-Udacity</th>\n",
       "      <th>Q13-Coursera</th>\n",
       "      <th>Q13-edX</th>\n",
       "      <th>Q13-DataCamp</th>\n",
       "      <th>Q13-Kaggle Courses (i.e. Kaggle Learn)</th>\n",
       "      <th>Q13-Fast.ai</th>\n",
       "      <th>Q13-Udemy</th>\n",
       "      <th>Q13-LinkedIn Learning</th>\n",
       "      <th>Q13-University Courses (resulting in a university degree)</th>\n",
       "      <th>Q13-None</th>\n",
       "      <th>Q13-Other</th>\n",
       "      <th>Q14-Advanced statistical software (SPSS, SAS, etc.)</th>\n",
       "      <th>Q14-Basic statistical software (Microsoft Excel, Google Sheets, etc.)</th>\n",
       "      <th>Q14-Business intelligence software (Salesforce, Tableau, Spotfire, etc.)</th>\n",
       "      <th>Q14-Cloud-based data software &amp; APIs (AWS, GCP, Azure, etc.)</th>\n",
       "      <th>Q14-Local development environments (RStudio, JupyterLab, etc.)</th>\n",
       "      <th>Q14-Other</th>\n",
       "      <th>Q15-1-2 years</th>\n",
       "      <th>Q15-10-20 years</th>\n",
       "      <th>Q15-3-5 years</th>\n",
       "      <th>Q15-5-10 years</th>\n",
       "      <th>Q15-&lt; 1 years</th>\n",
       "      <th>Q22-2-5 times</th>\n",
       "      <th>Q22-Never</th>\n",
       "      <th>Q22-Once</th>\n",
       "      <th>Q23-1-2 years</th>\n",
       "      <th>Q23-2-3 years</th>\n",
       "      <th>Q23-3-4 years</th>\n",
       "      <th>Q23-4-5 years</th>\n",
       "      <th>Q23-5-10 years</th>\n",
       "      <th>Q23-&lt; 1 years</th>\n",
       "      <th>Q26-General purpose image/video tools (PIL, cv2, skimage, etc)</th>\n",
       "      <th>Q26-Image segmentation methods (U-Net, Mask R-CNN, etc)</th>\n",
       "      <th>Q26-Object detection methods (YOLOv3, RetinaNet, etc)</th>\n",
       "      <th>Q26-Generative Networks (GAN, VAE, etc)</th>\n",
       "      <th>Q26-None</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8937</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8938</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8939</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8940</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8941</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8942 rows × 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      top25  Q1-22-24  Q1-25-29  Q1-30-34  Q1-35-39  Q1-40-44  Q1-45-49  Q2-Female  Q3-India  Q3-Other  Q3-United States of America  Q4-Bachelor’s degree  Q4-Doctoral degree  Q4-Master’s degree  Q5-Business/Data Analyst  Q5-Data Scientist  Q5-Data/Software Engineer  Q5-Product/Project Manager  Q5-Researcher  Q6-0-49 employees  Q6-1000-9,999 employees  Q6-250-999 employees  Q6-50-249 employees  Q6-> 10,000 employees  Q7-0  Q7-1-2  Q7-10-14  Q7-20+  Q7-3-4  Q7-5-9  Q8-I do not know  Q8-No (we do not use ML methods)  Q8-We are exploring ML methods (and may one day put a model into production)  Q8-We have well established ML methods (i.e., models in production for more than 2 years)  Q8-We recently started using ML methods (i.e., models in production for less than 2 years)  Q8-We use ML methods for generating insights (but do not put working models into production)  Q9-Analyze and understand data to influence product or business decisions  \\\n",
       "0         0         1         0         0         0         0         0          0         0         0                            0                     0                   0                   1                         0                  0                          1                           0              0                  0                        1                     0                    0                      0     1       0         0       0       0       0                 1                                 0                                                  0                                                                             0                                                                                          0                                                                                           0                                                                                             0                           \n",
       "1         0         0         0         0         0         1         0          0         1         0                            0                     0                   0                   0                         0                  0                          1                           0              0                  0                        0                     0                    0                      1     0       0         0       1       0       0                 0                                 0                                                  0                                                                             1                                                                                          0                                                                                           0                                                                                             1                           \n",
       "2         0         0         0         0         0         0         0          0         0         0                            0                     0                   0                   1                         0                  1                          0                           0              0                  1                        0                     0                    0                      0     0       0         0       0       1       0                 0                                 0                                                  0                                                                             1                                                                                          0                                                                                           0                                                                                             0                           \n",
       "3         0         1         0         0         0         0         0          0         1         0                            0                     0                   0                   1                         0                  1                          0                           0              0                  0                        0                     0                    1                      0     0       0         0       1       0       0                 0                                 0                                                  1                                                                             0                                                                                          0                                                                                           0                                                                                             1                           \n",
       "4         1         1         0         0         0         0         0          1         0         0                            1                     1                   0                   0                         0                  1                          0                           0              0                  0                        0                     0                    0                      1     0       0         0       1       0       0                 0                                 0                                                  0                                                                             0                                                                                          1                                                                                           0                                                                                             1                           \n",
       "...     ...       ...       ...       ...       ...       ...       ...        ...       ...       ...                          ...                   ...                 ...                 ...                       ...                ...                        ...                         ...            ...                ...                      ...                   ...                  ...                    ...   ...     ...       ...     ...     ...     ...               ...                               ...                                                ...                                                                           ...                                                                                        ...                                                                                         ...                                                                                           ...                           \n",
       "8937      0         0         0         1         0         0         0          0         0         0                            0                     0                   0                   1                         1                  0                          0                           0              0                  0                        0                     1                    0                      0     0       0         0       0       1       0                 0                                 0                                                  0                                                                             0                                                                                          1                                                                                           0                                                                                             0                           \n",
       "8938      0         0         0         1         0         0         0          1         1         0                            0                     0                   0                   1                         0                  1                          0                           0              0                  0                        0                     0                    0                      1     0       0         0       0       0       0                 0                                 0                                                  0                                                                             0                                                                                          1                                                                                           0                                                                                             0                           \n",
       "8939      0         0         0         0         0         0         0          0         0         0                            0                     0                   0                   0                         1                  0                          0                           0              0                  0                        0                     1                    0                      0     0       1         0       0       0       0                 0                                 0                                                  0                                                                             0                                                                                          0                                                                                           0                                                                                             0                           \n",
       "8940      0         1         0         0         0         0         0          0         1         0                            0                     1                   0                   0                         0                  1                          0                           0              0                  0                        0                     0                    1                      0     0       0         0       0       1       0                 0                                 0                                                  0                                                                             0                                                                                          0                                                                                           1                                                                                             1                           \n",
       "8941      0         0         0         0         0         0         0          0         0         0                            0                     1                   0                   0                         0                  0                          1                           0              0                  0                        0                     0                    0                      1     0       0         0       1       0       0                 0                                 0                                                  0                                                                             1                                                                                          0                                                                                           0                                                                                             0                           \n",
       "\n",
       "      Q9-Build and/or run the data infrastructure that my business uses for storing, analyzing, and operationalizing data  Q9-Build prototypes to explore applying machine learning to new areas  Q9-Build and/or run a machine learning service that operationally improves my product or workflows  Q9-Experimentation and iteration to improve existing ML models  Q9-Do research that advances the state of the art of machine learning  Q11-$0 (USD)  Q11-$1-$99  Q11-$10,000-$99,999  Q11-$100-$999  Q11-$1000-$9,999  Q11-> $100,000 ($USD)  Q12-Twitter (data science influencers)  Q12-Hacker News (https://news.ycombinator.com/)  Q12-Reddit (r/machinelearning, r/datascience, etc)  Q12-Kaggle (forums, blog, social media, etc)  Q12-Course Forums (forums.fast.ai, etc)  Q12-YouTube (Cloud AI Adventures, Siraj Raval, etc)  Q12-Podcasts (Chai Time Data Science, Linear Digressions, etc)  Q12-Blogs (Towards Data Science, Medium, Analytics Vidhya, KDnuggets etc)  \\\n",
       "0                                                     0                                                                                                                    0                                                                      0                                                                                                   0                                                               0                                 1           0                    0              0                 0                      0                                       1                                                0                                                  0                                              1                                        0                                                  0                                                    0                                                               1                           \n",
       "1                                                     1                                                                                                                    1                                                                      1                                                                                                   0                                                               0                                 0           0                    0              0                 0                      1                                       0                                                0                                                  0                                              1                                        0                                                  1                                                    1                                                               1                           \n",
       "2                                                     0                                                                                                                    1                                                                      0                                                                                                   0                                                               1                                 0           0                    1              0                 0                      0                                       0                                                0                                                  0                                              0                                        0                                                  1                                                    0                                                               1                           \n",
       "3                                                     0                                                                                                                    0                                                                      0                                                                                                   1                                                               1                                 0           0                    0              1                 0                      0                                       0                                                0                                                  0                                              1                                        1                                                  1                                                    1                                                               0                           \n",
       "4                                                     0                                                                                                                    1                                                                      1                                                                                                   0                                                               0                                 1           0                    0              0                 0                      0                                       0                                                1                                                  0                                              0                                        0                                                  0                                                    0                                                               1                           \n",
       "...                                                 ...                                                                                                                  ...                                                                    ...                                                                                                 ...                                                             ...                               ...         ...                  ...            ...               ...                    ...                                     ...                                              ...                                                ...                                            ...                                      ...                                                ...                                                  ...                                                             ...                           \n",
       "8937                                                  0                                                                                                                    0                                                                      1                                                                                                   0                                                               0                                 0           0                    0              0                 1                      0                                       0                                                1                                                  1                                              1                                        0                                                  0                                                    0                                                               0                           \n",
       "8938                                                  0                                                                                                                    1                                                                      1                                                                                                   1                                                               1                                 0           0                    0              0                 0                      0                                       0                                                0                                                  0                                              0                                        0                                                  0                                                    0                                                               0                           \n",
       "8939                                                  0                                                                                                                    0                                                                      0                                                                                                   0                                                               0                                 0           0                    0              0                 0                      0                                       0                                                0                                                  0                                              0                                        0                                                  0                                                    0                                                               0                           \n",
       "8940                                                  0                                                                                                                    0                                                                      0                                                                                                   0                                                               0                                 0           0                    0              1                 0                      0                                       1                                                0                                                  0                                              0                                        0                                                  1                                                    0                                                               0                           \n",
       "8941                                                  1                                                                                                                    1                                                                      0                                                                                                   0                                                               0                                 1           0                    0              0                 0                      0                                       0                                                0                                                  0                                              0                                        0                                                  0                                                    0                                                               1                           \n",
       "\n",
       "      Q12-Journal Publications (traditional publications, preprint journals, etc)  Q12-Slack Communities (ods.ai, kagglenoobs, etc)  Q12-Other  Q13-Udacity  Q13-Coursera  Q13-edX  Q13-DataCamp  Q13-Kaggle Courses (i.e. Kaggle Learn)  Q13-Fast.ai  Q13-Udemy  Q13-LinkedIn Learning  Q13-University Courses (resulting in a university degree)  Q13-None  Q13-Other  Q14-Advanced statistical software (SPSS, SAS, etc.)  Q14-Basic statistical software (Microsoft Excel, Google Sheets, etc.)  Q14-Business intelligence software (Salesforce, Tableau, Spotfire, etc.)  Q14-Cloud-based data software & APIs (AWS, GCP, Azure, etc.)  Q14-Local development environments (RStudio, JupyterLab, etc.)  Q14-Other  Q15-1-2 years  Q15-10-20 years  Q15-3-5 years  Q15-5-10 years  Q15-< 1 years  Q22-2-5 times  Q22-Never  Q22-Once  Q23-1-2 years  Q23-2-3 years  Q23-3-4 years  Q23-4-5 years  Q23-5-10 years  Q23-< 1 years  Q26-General purpose image/video tools (PIL, cv2, skimage, etc)  \\\n",
       "0                                                     1                                                                           0          0            0             1        0             1                                       1            0          1                      0                                                  0                 0          0                                                  0                                                    1                                                                      0                                                                         0                                                             0                       0              1                0              0               0              0              0          1         0              1              0              0              0               0              0                                                  0                \n",
       "1                                                     0                                                                           0          0            0             1        0             1                                       1            0          1                      0                                                  0                 0          0                                                  0                                                    0                                                                      0                                                                         1                                                             0                       0              0                0              0               0              0              0          0         0              0              0              0              0               0              0                                                  0                \n",
       "2                                                     1                                                                           0          0            0             0        0             0                                       0            0          0                      0                                                  0                 1          0                                                  1                                                    0                                                                      0                                                                         0                                                             0                       0              0                0              0               0              0              0          1         0              0              0              0              0               0              0                                                  0                \n",
       "3                                                     1                                                                           0          0            1             1        1             0                                       1            0          1                      0                                                  0                 0          0                                                  0                                                    0                                                                      0                                                                         0                                                             1                       0              0                0              1               0              0              0          0         0              0              1              0              0               0              0                                                  1                \n",
       "4                                                     1                                                                           0          0            0             0        0             0                                       0            0          1                      0                                                  1                 0          0                                                  0                                                    0                                                                      0                                                                         0                                                             1                       0              0                0              1               0              0              0          0         1              0              0              1              0               0              0                                                  1                \n",
       "...                                                 ...                                                                         ...        ...          ...           ...      ...           ...                                     ...          ...        ...                    ...                                                ...               ...        ...                                                ...                                                  ...                                                                    ...                                                                       ...                                                           ...                     ...            ...              ...            ...             ...            ...            ...        ...       ...            ...            ...            ...            ...             ...            ...                                                ...                \n",
       "8937                                                  0                                                                           0          0            1             0        0             0                                       0            0          0                      0                                                  0                 0          0                                                  0                                                    0                                                                      0                                                                         1                                                             0                       0              1                0              0               0              0              0          0         0              0              0              0              0               0              0                                                  0                \n",
       "8938                                                  0                                                                           0          0            0             0        0             0                                       0            0          0                      0                                                  0                 0          0                                                  0                                                    0                                                                      0                                                                         0                                                             0                       0              0                0              0               0              0              0          0         0              0              0              0              0               0              0                                                  0                \n",
       "8939                                                  0                                                                           0          0            0             0        0             0                                       0            0          0                      0                                                  0                 0          0                                                  0                                                    0                                                                      0                                                                         0                                                             0                       0              0                0              0               0              0              0          0         0              0              0              0              0               0              0                                                  0                \n",
       "8940                                                  0                                                                           0          0            1             1        1             1                                       0            1          1                      0                                                  0                 0          0                                                  0                                                    0                                                                      0                                                                         0                                                             0                       0              0                0              0               0              0              0          0         0              0              0              0              0               0              0                                                  0                \n",
       "8941                                                  0                                                                           0          0            0             1        1             0                                       0            0          1                      0                                                  0                 0          0                                                  0                                                    0                                                                      0                                                                         0                                                             1                       0              0                0              1               0              0              0          1         0              0              0              0              1               0              0                                                  0                \n",
       "\n",
       "      Q26-Image segmentation methods (U-Net, Mask R-CNN, etc)  Q26-Object detection methods (YOLOv3, RetinaNet, etc)  Q26-Generative Networks (GAN, VAE, etc)  Q26-None  \n",
       "0                                                     0                                                        0                                            0         0  \n",
       "1                                                     0                                                        0                                            0         0  \n",
       "2                                                     0                                                        0                                            0         1  \n",
       "3                                                     1                                                        1                                            0         0  \n",
       "4                                                     0                                                        0                                            0         0  \n",
       "...                                                 ...                                                      ...                                          ...       ...  \n",
       "8937                                                  0                                                        0                                            0         0  \n",
       "8938                                                  0                                                        0                                            0         0  \n",
       "8939                                                  0                                                        0                                            0         0  \n",
       "8940                                                  0                                                        0                                            0         0  \n",
       "8941                                                  0                                                        0                                            0         0  \n",
       "\n",
       "[8942 rows x 95 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_dataset_dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "top25\n",
       "0    6348\n",
       "1    2594\n",
       "Name: Q1-22-24, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#showcase target variable inbalance\n",
    "####################################\n",
    "clean_dataset_dropped.groupby('top25')['Q1-22-24'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Data Frame:\n",
      "0    6348\n",
      "1    2594\n",
      "Name: top25, dtype: int64\n",
      "--------------------\n",
      "Data Frame following Downsampling:\n",
      "1    2594\n",
      "0    2594\n",
      "Name: top25, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#sampling data inbalance in target variable\n",
    "####################################\n",
    "\n",
    "#import required libraries\n",
    "from sklearn.utils import resample\n",
    "\n",
    "#copy data frame up till now & print current shape\n",
    "df_sampling = clean_dataset_dropped.copy()\n",
    "print('Current Data Frame:')\n",
    "print(df_sampling.top25.value_counts())\n",
    "print('-'*20)\n",
    "\n",
    "#seperate target variable majority and minority classes\n",
    "df_majority = df_sampling[df_sampling.top25==0]\n",
    "df_minority = df_sampling[df_sampling.top25==1]\n",
    " \n",
    "#apply downsampling of target class (sample without replacement)\n",
    "df_majority_downsampled = resample(df_majority, \n",
    "                                 replace=False,    \n",
    "                                 n_samples=2594,    \n",
    "                                 random_state=42) \n",
    " \n",
    "#combine both classes back together minority class with downsampled majority class\n",
    "df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
    " \n",
    "#copy data frame for continuing analysis\n",
    "clean_dataset_dropped = df_downsampled.copy()    \n",
    "\n",
    "#output\n",
    "print('Data Frame following Downsampling:')\n",
    "print(df_downsampled.top25.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Continuesly mentioned during the report the dataset is split into training and testing datasets. The below code splits the data with a 80/20 ratio. Please find details below.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape: (4150, 95)\n",
      "Test Shape: (1038, 95)\n"
     ]
    }
   ],
   "source": [
    "#training and testing dataset \n",
    "####################################\n",
    "\n",
    "#import required libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#split data into train/test with 80/20 ration\n",
    "train, test = train_test_split(clean_dataset_dropped, test_size=0.2, random_state=42)\n",
    "\n",
    "#output\n",
    "print('Train Shape:', train.shape)\n",
    "print('Test Shape:', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Datasets:\n",
      "(4150,) (4150, 94)\n",
      "--------------------\n",
      "Testing Datasets:\n",
      "(1038,) (1038, 94)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split X and y variables for training and testing dataset\n",
    "####################################\n",
    "\n",
    "#training data\n",
    "ytrain = train['top25'].copy()\n",
    "Xtrain = train.drop(['top25'], axis=1).copy()\n",
    "\n",
    "#testing data\n",
    "ytest = test['top25'].copy()\n",
    "Xtest = test.drop(['top25'], axis=1).copy()\n",
    "\n",
    "#output\n",
    "print('Training Datasets:'),print(ytrain.shape, Xtrain.shape)\n",
    "print('-'*20)\n",
    "print('Testing Datasets:'),print(ytest.shape, Xtest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Prediction Performance (Overview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries\n",
    "####################################\n",
    "\n",
    "#individual model libraries\n",
    "from sklearn.linear_model import LogisticRegression #library for Logistic Regression\n",
    "from sklearn.ensemble import RandomForestClassifier #library for Random Forrest\n",
    "from sklearn.neighbors import KNeighborsClassifier #library for K-Neighbot\n",
    "from sklearn.tree import DecisionTreeClassifier #libraries for decision tree\n",
    "from sklearn import tree #libraries for ExtraTreesClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier #libraries for ExtraTreesClassifier\n",
    "from sklearn.linear_model import RidgeClassifier #libraries for RidgeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier #libraries for AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier #libraries for BaggingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier #libraries for GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB #libraries for GaussianNB\n",
    "from sklearn.svm import SVC #libraries for SVC\n",
    "from sklearn.linear_model import SGDClassifier #libraries for Stochastic Gradient Descent\n",
    "\n",
    "#libraries for model evaluation\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#libraries for cross validation\n",
    "from sklearn.model_selection import cross_val_predict \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "#turn off warnings for the model output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model overview; models used for prediction\n",
    "####################################\n",
    "\n",
    "model_dict = {'Logistic Regression':LogisticRegression(),\n",
    "              'Random Forrest':RandomForestClassifier(),\n",
    "              'Decision Tree Classifier':tree.DecisionTreeClassifier(),\n",
    "              'ExtraTrees Classifier':ExtraTreesClassifier(),\n",
    "              'KNeighbors Classifier':KNeighborsClassifier(),\n",
    "              'AdaBoost Classifier':AdaBoostClassifier(),\n",
    "              'Bagging Classifier':BaggingClassifier(),\n",
    "              'GradientBoosting Classifier':GradientBoostingClassifier(),\n",
    "              'Support Vector Machines':SVC(),\n",
    "              'Stochastic Gradient Descent':SGDClassifier(),\n",
    "              #'XGBoost':XGBClassifier(),\n",
    "              'GaussianNB':GaussianNB(),\n",
    "             }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "The below tables tabulates the model performance results of all analyzed models along Accuracy, Precision, Recall, F-Measure and Fitting Time.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Measure</th>\n",
       "      <th>fitting_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.802169</td>\n",
       "      <td>0.813896</td>\n",
       "      <td>0.786194</td>\n",
       "      <td>0.799805</td>\n",
       "      <td>0.119780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forrest</td>\n",
       "      <td>0.798795</td>\n",
       "      <td>0.816388</td>\n",
       "      <td>0.773730</td>\n",
       "      <td>0.794487</td>\n",
       "      <td>0.362677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>0.714699</td>\n",
       "      <td>0.709572</td>\n",
       "      <td>0.732023</td>\n",
       "      <td>0.720623</td>\n",
       "      <td>0.031206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ExtraTrees Classifier</td>\n",
       "      <td>0.805060</td>\n",
       "      <td>0.816246</td>\n",
       "      <td>0.790029</td>\n",
       "      <td>0.802923</td>\n",
       "      <td>0.417723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNeighbors Classifier</td>\n",
       "      <td>0.708434</td>\n",
       "      <td>0.728601</td>\n",
       "      <td>0.669223</td>\n",
       "      <td>0.697651</td>\n",
       "      <td>0.030609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AdaBoost Classifier</td>\n",
       "      <td>0.803855</td>\n",
       "      <td>0.819277</td>\n",
       "      <td>0.782359</td>\n",
       "      <td>0.800392</td>\n",
       "      <td>0.190333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bagging Classifier</td>\n",
       "      <td>0.786506</td>\n",
       "      <td>0.818810</td>\n",
       "      <td>0.738734</td>\n",
       "      <td>0.776714</td>\n",
       "      <td>0.160901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GradientBoosting Classifier</td>\n",
       "      <td>0.801687</td>\n",
       "      <td>0.821701</td>\n",
       "      <td>0.773250</td>\n",
       "      <td>0.796740</td>\n",
       "      <td>0.597340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Support Vector Machines</td>\n",
       "      <td>0.798313</td>\n",
       "      <td>0.816844</td>\n",
       "      <td>0.771812</td>\n",
       "      <td>0.793690</td>\n",
       "      <td>0.794107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Stochastic Gradient Descent</td>\n",
       "      <td>0.802892</td>\n",
       "      <td>0.819235</td>\n",
       "      <td>0.779962</td>\n",
       "      <td>0.799116</td>\n",
       "      <td>0.053656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.772771</td>\n",
       "      <td>0.758247</td>\n",
       "      <td>0.804410</td>\n",
       "      <td>0.780647</td>\n",
       "      <td>0.008987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Model  Train Accuracy  Precision    Recall  F1-Measure  fitting_time\n",
       "0           Logistic Regression        0.802169   0.813896  0.786194    0.799805      0.119780\n",
       "1                Random Forrest        0.798795   0.816388  0.773730    0.794487      0.362677\n",
       "2      Decision Tree Classifier        0.714699   0.709572  0.732023    0.720623      0.031206\n",
       "3         ExtraTrees Classifier        0.805060   0.816246  0.790029    0.802923      0.417723\n",
       "4         KNeighbors Classifier        0.708434   0.728601  0.669223    0.697651      0.030609\n",
       "5           AdaBoost Classifier        0.803855   0.819277  0.782359    0.800392      0.190333\n",
       "6            Bagging Classifier        0.786506   0.818810  0.738734    0.776714      0.160901\n",
       "7   GradientBoosting Classifier        0.801687   0.821701  0.773250    0.796740      0.597340\n",
       "8       Support Vector Machines        0.798313   0.816844  0.771812    0.793690      0.794107\n",
       "9   Stochastic Gradient Descent        0.802892   0.819235  0.779962    0.799116      0.053656\n",
       "10                   GaussianNB        0.772771   0.758247  0.804410    0.780647      0.008987"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model performance overview\n",
    "####################################\n",
    "\n",
    "#apply stratified k-fold with 5 splits\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True) #, random_state=42)\n",
    "folds = 3\n",
    "list_models_scores = list()\n",
    "\n",
    "#loop to generate overview\n",
    "for model_name, model in model_dict.items():\n",
    "    #perform cross valdiation\n",
    "    cv_score = cross_validate(model,Xtrain,ytrain, cv=folds, return_train_score=False, n_jobs=-1) #scoring = scoring\n",
    "    ypred = cross_val_predict(model, Xtrain, ytrain, cv=folds)\n",
    "    #list of scores\n",
    "    list_models_scores.append({'Model': model_name,\n",
    "                                     'Train Accuracy':accuracy_score(ytrain,ypred),\n",
    "                                     'Precision':precision_score(ytrain,ypred), \n",
    "                                     'Recall': recall_score(ytrain,ypred),\n",
    "                                     'F1-Measure': f1_score(ytrain,ypred),\n",
    "                                     'fitting_time': cv_score['fit_time'].mean()\n",
    "                                    })\n",
    "    \n",
    "    #output parameter specifics (if required)\n",
    "    #print(model_name , ' : ' , score['test_f1'])\n",
    "\n",
    "#output\n",
    "pd.DataFrame(list_models_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results used for report write-up\n",
    "\n",
    "#    Model\tTrain Accuracy\tPrecision\tRecall\tF1-Measure\tfitting_time\n",
    "#0\tLogistic Regression\t0.805153\t0.819527\t0.795215\t0.807188\t0.097739\n",
    "#1\tRandom Forrest\t0.796564\t0.809524\t0.788995\t0.799128\t0.275768\n",
    "#2\tDecision Tree Classifier\t0.711902\t0.720404\t0.716268\t0.718330\t0.024431\n",
    "#3\tExtraTrees Classifier\t0.796564\t0.810744\t0.787081\t0.798738\t0.402934\n",
    "#4\tKNeighbors Classifier\t0.708466\t0.737368\t0.670335\t0.702256\t0.026972\n",
    "#5\tAdaBoost Classifier\t0.792147\t0.804209\t0.786124\t0.795064\t0.151551\n",
    "#6\tBagging Classifier\t0.771534\t0.808081\t0.727273\t0.765550\t0.142447\n",
    "#7\tGradientBoosting Classifier\t0.801718\t0.820500\t0.785167\t0.802445\t0.560829\n",
    "#8\tSupport Vector Machines\t0.801963\t0.822524\t0.782775\t0.802157\t0.437847\n",
    "\n",
    "\n",
    "#9\tStochastic Gradient Descent\t0.786503\t0.778793\t0.815311\t0.796634\t0.055941\n",
    "#10\tGaussianNB\t0.766626\t0.763535\t0.789474\t0.776288\t0.008951"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "In order to further enhance the predictive capabilities of selected models subsequent hyperparameter tuning is undertaken. As outlined in the report different approaches can be adopted. The author used Gridsearch optimization to test different sets of parameters for each of the previously selected models.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define function to fit models for ensemble\n",
    "####################################\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def model_fit_ensemble(model, param_grid, folds):\n",
    "    model_gs = GridSearchCV(model, param_grid, cv=folds)\n",
    "    \n",
    "    #fit model to training data\n",
    "    model_gs.fit(Xtrain, ytrain)\n",
    "    #print(model_gs)\n",
    "\n",
    "    #save best model (based on model estimaors)\n",
    "    model_best = model_gs.best_estimator_\n",
    "    print(model_gs.best_estimator_)\n",
    "\n",
    "    ypred = cross_val_predict(model_best, Xtrain, ytrain, cv=folds)\n",
    "\n",
    "    model_accuracy = accuracy_score(ytrain,ypred) \n",
    "    model_precision = precision_score(ytrain,ypred)\n",
    "    model_recall = recall_score(ytrain,ypred)\n",
    "    model_f1 = f1_score(ytrain,ypred)\n",
    "\n",
    "    #output scores\n",
    "    print('Train Accuracy:',model_accuracy,\n",
    "          'Precision:',model_precision,\n",
    "          'Recall:', model_recall,\n",
    "          'F1 Score:', model_f1)\n",
    "    print('-'*10)\n",
    "    \n",
    "    return model_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(random_state=42, solver='liblinear')\n",
      "Train Accuracy: 0.8074698795180723 Precision: 0.8187221396731055 Recall: 0.7924256951102588 F1 Score: 0.8053593179049939\n",
      "----------\n",
      "RandomForestClassifier(max_depth=100, n_estimators=350, random_state=42)\n",
      "Train Accuracy: 0.8021686746987952 Precision: 0.8173607626693427 Recall: 0.7809204218600192 F1 Score: 0.7987251777396421\n",
      "----------\n",
      "AdaBoostClassifier(learning_rate=0.7, n_estimators=1000, random_state=42)\n",
      "Train Accuracy: 0.8060240963855422 Precision: 0.8166089965397924 Recall: 0.7919463087248322 F1 Score: 0.8040885860306644\n",
      "----------\n",
      "SVC(C=0.75, degree=0.5, probability=True, random_state=42)\n",
      "Train Accuracy: 0.8065060240963855 Precision: 0.8288057406458227 Recall: 0.7751677852348994 F1 Score: 0.801089918256131\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "#Gridsearch Optimization\n",
    "###################################\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "param_grid_LOG = [{'solver':['liblinear'],'random_state':[42]}]\n",
    "param_grid_RFC = [{'n_estimators':[350,500],'max_features':['auto'],'max_depth':[100,200],'random_state':[42]}]\n",
    "param_grid_ADA = [{'n_estimators':[1000],'algorithm':['SAMME.R'],'learning_rate':[0.7],'random_state':[42]}]\n",
    "param_grid_SVC = [{'random_state':[42],'degree':[0.5,0.6],'C':[0.75],'probability':[True]}]\n",
    "\n",
    "#save best models\n",
    "log_best = model_fit_ensemble(LogisticRegression(), param_grid_LOG, folds)\n",
    "rfc_best = model_fit_ensemble(RandomForestClassifier(), param_grid_RFC, folds)\n",
    "ada_best = model_fit_ensemble(AdaBoostClassifier(), param_grid_ADA, folds)\n",
    "svc_best = model_fit_ensemble(SVC(), param_grid_SVC, folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stored sscores used during analysis\n",
    "\n",
    "#LogisticRegression(random_state=42, solver='liblinear')\n",
    "#Train Accuracy: 0.8053987730061349 Precision: 0.8183603338242513 Recall: 0.7976076555023923 F1 Score: 0.8078507390356191\n",
    "#----------\n",
    "#RandomForestClassifier(max_depth=100, n_estimators=500, random_state=42)\n",
    "#Train Accuracy: 0.798282208588957 Precision: 0.8101761252446184 Recall: 0.7923444976076555 F1 Score: 0.8011611030478955\n",
    "#----------\n",
    "#AdaBoostClassifier(learning_rate=0.7, n_estimators=1000, random_state=42)\n",
    "#Train Accuracy: 0.7977914110429448 Precision: 0.8136769078295342 Recall: 0.785645933014354 F1 Score: 0.7994157740993184\n",
    "#----------\n",
    "#SVC(C=0.75, degree=0.5, probability=True, random_state=42)\n",
    "#Train Accuracy: 0.8034355828220859 Precision: 0.8273235144743525 Recall: 0.7794258373205741 F1 Score: 0.802660753880266\n",
    "#----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_best = LogisticRegression(random_state=42, solver='liblinear', fit_intercept=True)\n",
    "rfc_best = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    "                       criterion='gini', max_depth=100, max_features='auto',\n",
    "                       max_leaf_nodes=None, max_samples=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=350,\n",
    "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
    "                       warm_start=False)\n",
    "ada_best = AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=0.7,\n",
    "                       n_estimators=1000, random_state=42)\n",
    "svc_best = SVC(C=0.75, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
    "                        decision_function_shape='ovr', degree=0.5, gamma='scale', kernel='linear',\n",
    "                        max_iter=-1, probability=True, random_state=42, shrinking=True, tol=0.001,\n",
    "                        verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting Classifier "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "With the stand-alone machine learning algorithms outlined to this point reaching their maximum predictive power, the author reverts to ensemble methods in order to further enhance prediction performance. Therefore, following the individual study of models an ensemble method is used to create a Voting Classifer. It is based on the four previously fine-tuned models.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "Train Accuracy: 0.8093975903614458 Precision: 0.8235882058970515 Recall: 0.7900287631831256 F1: 0.8064595057499389\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#voting classifier\n",
    "####################################\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "#select models for voting\n",
    "voting_clf_param =[('LOG', log_best),('ADA', ada_best),('RFC', rfc_best),('SVC', svc_best)]\n",
    "\n",
    "#define voting classifier model\n",
    "vote_best = VotingClassifier(estimators=voting_clf_param, voting='soft',flatten_transform=False)\n",
    "\n",
    "#fit model\n",
    "vote_best.fit(Xtrain, ytrain)\n",
    "\n",
    "#predict model (k-fold, 5 folds)\n",
    "ypred = cross_val_predict(vote_best, Xtrain, ytrain, cv=folds)\n",
    "\n",
    "vote_accuracy = accuracy_score(ytrain,ypred)\n",
    "vote_precision = precision_score(ytrain,ypred)\n",
    "vote_recall = recall_score(ytrain,ypred)\n",
    "vote_f1 = f1_score(ytrain,ypred)\n",
    "\n",
    "    #output scores\n",
    "print('-'*10), print('Train Accuracy:',vote_accuracy,\n",
    "                     'Precision:',vote_precision,\n",
    "                     'Recall:',vote_recall,\n",
    "                     'F1:', vote_f1), print('-'*10)\n",
    "\n",
    "#saved scores used during write-up of report\n",
    "#Train Accuracy: 0.8103067484662577 Precision: 0.8242245199409158 Recall: 0.8009569377990431 F1: 0.812424168891046"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "The Voting Classifier outperforms the single classifier models across all metrics. Please see the above model results.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#boxplot of Cross-Validation for different models\n",
    "####################################\n",
    "\n",
    "#set values for boxplot as cross value scores from above dataframe\n",
    "#value_log = df_CV_scores['F1-Measure'].iloc[0]\n",
    "#value_rfc = df_CV_scores['F1-Measure'].iloc[1]\n",
    "#value_ada = df_CV_scores['F1-Measure'].iloc[2]\n",
    "#value_svc = df_CV_scores['F1-Measure'].iloc[3]\n",
    "\n",
    "#value_vote = df_CV_scores_voting['F1-Measure'].iloc[0]\n",
    "\n",
    "#plot data into boxplot\n",
    "#fig(figsize=(10, 6))\n",
    "\n",
    "#box_plot_data=[value_log,value_rfc,value_ada,value_svc,value_vote]\n",
    "#plt.boxplot(box_plot_data,patch_artist=True,labels=['Logistic Regression',\n",
    "#                                                    'Random Forrest Classifier',\n",
    "#                                                    'AdaBoost Classifier',\n",
    "#                                                    'Support Vector Machines',\n",
    "#                                                    'Voting Classifier',\n",
    "#                                                   ])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#fit models \n",
    "#log_best.fit(Xtrain, ytrain)\n",
    "#rfc_best.fit(Xtrain, ytrain)\n",
    "#ada_best.fit(Xtrain, ytrain)\n",
    "#svc_best.fit(Xtrain, ytrain)\n",
    "#voting_clf.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary Test on 'new data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "In order to test the models capabilities on different data the author decided to apply the Voting Classifier to his own survey response. In detail, the survey results are entered in the below list and used as a secondary seperate test dataset. \n",
    "Please be aware that this in no means prevent actual testing of the model.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Columns/Responses:  94\n"
     ]
    }
   ],
   "source": [
    "#define test model for author testing\n",
    "####################################\n",
    "\n",
    "#survey responses in form of list\n",
    "Xtest_author_list = list([1,0,0,0,0,0,\n",
    "                     0,     #\n",
    "                     0,1,0, #\n",
    "                     0,0,1, #\n",
    "                     0,0,0,0,0, #job titles\n",
    "                     1,0,0,0,0, #employee number\n",
    "                     0,0,0,0,0,0, #Q7\n",
    "                     0,0,1,0,0,0, #Q8\n",
    "                     1,0,0,0,0,0, #Q9\n",
    "                     0,0,0,0,0,0, #Q11\n",
    "                     0,0,0,0,0,0,0,1,1,0,0, #Q12\n",
    "                     0,1,0,1,0,0,0,0,0,0,0, #Q13\n",
    "                     0,1,0,0,0,0, #Q14\n",
    "                     0,0,1,0,0, #Q15\n",
    "                     1,0,0, #Q22\n",
    "                     1,0,0,0,0,0, #Q23\n",
    "                     0,0,0,0,1 #Q26\n",
    "                    ])\n",
    "\n",
    "#output\n",
    "print('Number of Columns/Responses: ',len(Xtest_author_list))\n",
    "\n",
    "#y-data for test\n",
    "ytest_author = pd.DataFrame([0], columns=['Q10'])\n",
    "#ytest_author\n",
    "\n",
    "#tranform x to dataframe\n",
    "Xtest_author = pd.DataFrame(Xtest_author_list, index=Xtest.columns).transpose()\n",
    "#Xtest_author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "#apply Voting Classifier to author test\n",
    "####################################\n",
    "\n",
    "ypred = vote_best.predict(Xtest_author)\n",
    "ypred_score = vote_best.predict_proba(Xtest_author)\n",
    "    \n",
    "accuracy = accuracy_score(ytest_author, ypred)\n",
    "print('Accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "The Voting Classifier itself does not allow judgement of its features, therefore, one has to take a closer look at the underlying models that form the Voting Classifier: \n",
    "\n",
    "- Logistic Regression\n",
    "- Support Vector Machines\n",
    "- Random Forest \n",
    "- AdaBoost\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg Intercept:  [-1.4456824]\n",
      "Top & Bottom 10 Coefficients for Logistic Regression\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q3-United States of America</td>\n",
       "      <td>3.04018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q11-&gt; $100,000 ($USD)</td>\n",
       "      <td>1.40643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q11-$10,000-$99,999</td>\n",
       "      <td>1.29894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q11-$1000-$9,999</td>\n",
       "      <td>1.06308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q11-$0 (USD)</td>\n",
       "      <td>0.752406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Q14-Cloud-based data software &amp; APIs (AWS, GCP...</td>\n",
       "      <td>0.674394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Q14-Business intelligence software (Salesforce...</td>\n",
       "      <td>0.601049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Q8-We have well established ML methods (i.e., ...</td>\n",
       "      <td>0.597345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Q11-$100-$999</td>\n",
       "      <td>0.570052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Q14-Other</td>\n",
       "      <td>0.562656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-------------------------</td>\n",
       "      <td>-------------------------</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Q5-Business/Data Analyst</td>\n",
       "      <td>-0.458366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Q15-3-5 years</td>\n",
       "      <td>-0.459524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Q6-0-49 employees</td>\n",
       "      <td>-0.4931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Q1-35-39</td>\n",
       "      <td>-0.503809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Q15-&lt; 1 years</td>\n",
       "      <td>-0.593181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Q1-30-34</td>\n",
       "      <td>-0.63788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Q15-1-2 years</td>\n",
       "      <td>-0.717175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Q1-25-29</td>\n",
       "      <td>-1.39451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Q3-India</td>\n",
       "      <td>-1.44436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Q1-22-24</td>\n",
       "      <td>-2.0907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                index                       coef\n",
       "0                         Q3-United States of America                    3.04018\n",
       "1                               Q11-> $100,000 ($USD)                    1.40643\n",
       "2                                 Q11-$10,000-$99,999                    1.29894\n",
       "3                                    Q11-$1000-$9,999                    1.06308\n",
       "4                                        Q11-$0 (USD)                   0.752406\n",
       "5   Q14-Cloud-based data software & APIs (AWS, GCP...                   0.674394\n",
       "6   Q14-Business intelligence software (Salesforce...                   0.601049\n",
       "7   Q8-We have well established ML methods (i.e., ...                   0.597345\n",
       "8                                       Q11-$100-$999                   0.570052\n",
       "9                                           Q14-Other                   0.562656\n",
       "0                           -------------------------  -------------------------\n",
       "84                           Q5-Business/Data Analyst                  -0.458366\n",
       "85                                      Q15-3-5 years                  -0.459524\n",
       "86                                  Q6-0-49 employees                    -0.4931\n",
       "87                                           Q1-35-39                  -0.503809\n",
       "88                                      Q15-< 1 years                  -0.593181\n",
       "89                                           Q1-30-34                   -0.63788\n",
       "90                                      Q15-1-2 years                  -0.717175\n",
       "91                                           Q1-25-29                   -1.39451\n",
       "92                                           Q3-India                   -1.44436\n",
       "93                                           Q1-22-24                    -2.0907"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#feature importance logistic regression\n",
    "#######################################\n",
    "\n",
    "#fit model\n",
    "log_best.fit(Xtrain, ytrain)\n",
    "\n",
    "#return logreg intercept\n",
    "print('LogReg Intercept: ',log_best.intercept_)\n",
    "\n",
    "#define coefficients\n",
    "df_log_coef = pd.DataFrame(log_best.coef_[0],Xtrain.columns).rename({0:'coef'},axis=1)\\\n",
    ".sort_values(by='coef',ascending=False).reset_index().rename({'index':'feature'})\n",
    "\n",
    "log_head = df_log_coef.head(10)\n",
    "log_tail = df_log_coef.tail(10)\n",
    "log_middle = pd.DataFrame([['-----'*5,'-----'*5]], columns = ['index', 'coef'])\n",
    "\n",
    "print('Top & Bottom 10 Coefficients for Logistic Regression')\n",
    "log_head.append(log_middle).append(log_tail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top & Bottom 10 Coefficients for Support Vector Machines\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q3-United States of America</td>\n",
       "      <td>2.17058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q11-&gt; $100,000 ($USD)</td>\n",
       "      <td>1.21802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q11-$10,000-$99,999</td>\n",
       "      <td>1.14402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q11-$1000-$9,999</td>\n",
       "      <td>0.977181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q11-$0 (USD)</td>\n",
       "      <td>0.675363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Q8-We have well established ML methods (i.e., ...</td>\n",
       "      <td>0.610191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Q14-Cloud-based data software &amp; APIs (AWS, GCP...</td>\n",
       "      <td>0.541453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Q13-Fast.ai</td>\n",
       "      <td>0.528534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Q14-Other</td>\n",
       "      <td>0.513991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Q14-Business intelligence software (Salesforce...</td>\n",
       "      <td>0.506581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-------------------------</td>\n",
       "      <td>-------------------------</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Q7-0</td>\n",
       "      <td>-0.2954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Q15-5-10 years</td>\n",
       "      <td>-0.31085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Q1-35-39</td>\n",
       "      <td>-0.373541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Q15-3-5 years</td>\n",
       "      <td>-0.489467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Q1-30-34</td>\n",
       "      <td>-0.520536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Q15-&lt; 1 years</td>\n",
       "      <td>-0.540948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Q15-1-2 years</td>\n",
       "      <td>-0.674815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Q1-25-29</td>\n",
       "      <td>-1.05358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Q3-India</td>\n",
       "      <td>-1.12921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Q1-22-24</td>\n",
       "      <td>-1.30673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                index                       coef\n",
       "0                         Q3-United States of America                    2.17058\n",
       "1                               Q11-> $100,000 ($USD)                    1.21802\n",
       "2                                 Q11-$10,000-$99,999                    1.14402\n",
       "3                                    Q11-$1000-$9,999                   0.977181\n",
       "4                                        Q11-$0 (USD)                   0.675363\n",
       "5   Q8-We have well established ML methods (i.e., ...                   0.610191\n",
       "6   Q14-Cloud-based data software & APIs (AWS, GCP...                   0.541453\n",
       "7                                         Q13-Fast.ai                   0.528534\n",
       "8                                           Q14-Other                   0.513991\n",
       "9   Q14-Business intelligence software (Salesforce...                   0.506581\n",
       "0                           -------------------------  -------------------------\n",
       "84                                               Q7-0                    -0.2954\n",
       "85                                     Q15-5-10 years                   -0.31085\n",
       "86                                           Q1-35-39                  -0.373541\n",
       "87                                      Q15-3-5 years                  -0.489467\n",
       "88                                           Q1-30-34                  -0.520536\n",
       "89                                      Q15-< 1 years                  -0.540948\n",
       "90                                      Q15-1-2 years                  -0.674815\n",
       "91                                           Q1-25-29                   -1.05358\n",
       "92                                           Q3-India                   -1.12921\n",
       "93                                           Q1-22-24                   -1.30673"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#feature importance SVC\n",
    "#######################################\n",
    "\n",
    "#fit model\n",
    "svc_best.fit(Xtrain, ytrain)\n",
    "\n",
    "#calculate coefficients\n",
    "df_svc_coef = pd.DataFrame(svc_best.coef_[0],Xtrain.columns).rename({0:'coef'},axis=1)\\\n",
    ".sort_values(by='coef',ascending=False).reset_index().rename({'index':'feature'})\n",
    "\n",
    "svc_head = pd.DataFrame(df_svc_coef.head(10))\n",
    "svc_tail = pd.DataFrame(df_svc_coef.tail(10))\n",
    "svc_middle = pd.DataFrame([['-----'*5,'-----'*5]], columns = ['index', 'coef'])\n",
    "\n",
    "print('Top & Bottom 10 Coefficients for Support Vector Machines')\n",
    "svc_head.append(svc_middle).append(svc_tail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "FEATURE IMPORTANCE RFC\n",
      "----------\n",
      "Q3-United States of America   0.16905115253927885\n",
      "Q3-India   0.045461279365508686\n",
      "Q1-22-24   0.02096555664828136\n",
      "Q1-25-29   0.01909942038446613\n",
      "Q11-> $100,000 ($USD)   0.01892122687747782\n",
      "Q9-Build prototypes to explore applying machine learning to new areas   0.017310970592237504\n",
      "Q9-Analyze and understand data to influence product or business decisions   0.014810595733004552\n",
      "Q15-10-20 years   0.014656462398914655\n",
      "Q15-1-2 years   0.013873046162397797\n",
      "Q11-$10,000-$99,999   0.012575351262613022\n",
      "----------\n",
      "FEATURE IMPORTANCE ADA\n",
      "----------\n",
      "Q11-$0 (USD)   0.075\n",
      "Q11-$1000-$9,999   0.074\n",
      "Q11-$100-$999   0.069\n",
      "Q11-$10,000-$99,999   0.057\n",
      "Q11-$1-$99   0.055\n",
      "Q11-> $100,000 ($USD)   0.051\n",
      "Q14-Local development environments (RStudio, JupyterLab, etc.)   0.025\n",
      "Q15-3-5 years   0.022\n",
      "Q15-10-20 years   0.018\n",
      "Q15-5-10 years   0.017\n"
     ]
    }
   ],
   "source": [
    "#feature importance (RFC & ADA)\n",
    "#############################\n",
    "\n",
    "#fit models\n",
    "rfc_best.fit(Xtrain, ytrain)\n",
    "ada_best.fit(Xtrain, ytrain)\n",
    "\n",
    "#get feature importance\n",
    "feature_importances_RFC = list(rfc_best.feature_importances_)\n",
    "feature_importances_ADA = list(ada_best.feature_importances_)\n",
    "\n",
    "#get attribute/feature names\n",
    "attributes = clean_dataset_dropped.drop('top25',axis=1).columns\n",
    "#sort feature names according to importance\n",
    "feature_importances_RFC, attributes = zip(*sorted(zip(feature_importances_RFC, attributes), reverse=True))\n",
    "\n",
    "#output feature and according feature importance\n",
    "print('-'*10),print('FEATURE IMPORTANCE RFC'),print('-'*10)\n",
    "for i in range(10):\n",
    "    print(attributes[i], ' ', feature_importances_RFC[i])\n",
    "print('-'*10)\n",
    "########################\n",
    "    \n",
    "#get attribute/feature names\n",
    "attributes = clean_dataset_dropped.drop('top25',axis=1).columns\n",
    "#sort feature names according to importance\n",
    "feature_importances_ADA, attributes = zip(*sorted(zip(feature_importances_ADA, attributes), reverse=True))\n",
    "\n",
    "#output feature and according feature importance\n",
    "print('FEATURE IMPORTANCE ADA'), print('-'*10)\n",
    "for i in range(10):\n",
    "    print(attributes[i], ' ', feature_importances_ADA[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test models\n",
    "#display_scores(LOG, Xtest, ytest)\n",
    "#display_scores(log_best, Xtest, ytest)\n",
    "#display_scores(RFC, Xtest, ytest)\n",
    "#display_scores(ETC, Xtest, ytest)\n",
    "#display_scores(ADA, Xtest, ytest)\n",
    "#display_scores(ada_best, Xtest, ytest)\n",
    "#display_scores(voting_clf, Xtest, ytest)\n",
    "\n",
    "#print('training')\n",
    "#display_scores(voting_clf, Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability Distribution of Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualization layout format\n",
    "#############################\n",
    "\n",
    "#source for visualization code: https://www.kaggle.com/andresionek/what-makes-a-kaggler-valuable\n",
    "\n",
    "# Some helper functions to make our plots cleaner with Plotly\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "import plotly.graph_objs as go\n",
    "from plotly import tools\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "\n",
    "def gen_xaxis(title):\n",
    "    \"\"\"\n",
    "    Creates the X Axis layout and title\n",
    "    \"\"\"\n",
    "    xaxis = dict(\n",
    "            title=title,\n",
    "            titlefont=dict(\n",
    "                color='#383838'\n",
    "            ),\n",
    "            showgrid=False,\n",
    "            color='#383838',\n",
    "            )\n",
    "    return xaxis\n",
    "\n",
    "def gen_yaxis(title):\n",
    "    \"\"\"\n",
    "    Creates the Y Axis layout and title\n",
    "    \"\"\"\n",
    "    yaxis=dict(\n",
    "            title=title,\n",
    "            titlefont=dict(\n",
    "                color='#383838'\n",
    "            ),\n",
    "            showgrid=False,\n",
    "            color='#383838',\n",
    "            )\n",
    "    return yaxis\n",
    "\n",
    "\n",
    "def gen_layout(charttitle, xtitle, ytitle, lmarg, h, annotations=None):  \n",
    "    \"\"\"\n",
    "    Creates whole layout, with both axis, annotations, size and margin\n",
    "    \"\"\"\n",
    "    return go.Layout(title=charttitle, \n",
    "                     height=h, \n",
    "                     width=800,\n",
    "                     showlegend=False,\n",
    "                     xaxis=gen_xaxis(xtitle), \n",
    "                     yaxis=gen_yaxis(ytitle),\n",
    "                     annotations = annotations,\n",
    "                     margin=dict(l=lmarg),\n",
    "                     #paper_bgcolor='rgba(0,0,0,0)',\n",
    "                     plot_bgcolor='rgba(0,0,0,0)'\n",
    "                    )\n",
    "\n",
    "def gen_bars(data, color, orient):\n",
    "    \"\"\"\n",
    "    Generates the bars for plotting, with their color and orient\n",
    "    \"\"\"\n",
    "    bars = []\n",
    "    for label, label_df in data.groupby(color):\n",
    "        if orient == 'h':\n",
    "            label_df = label_df.sort_values(by='x', ascending=True)\n",
    "        if label == 'a':\n",
    "            label = 'lightgray'\n",
    "        bars.append(go.Bar(x=label_df.x,\n",
    "                           y=label_df.y,\n",
    "                           name=label,\n",
    "                           marker={'color': label},\n",
    "                           orientation = orient\n",
    "                          )\n",
    "                   )\n",
    "    return bars\n",
    "\n",
    "def gen_annotations(annot):\n",
    "    \"\"\"\n",
    "    Generates annotations to insert in the chart\n",
    "    \"\"\"\n",
    "    if annot is None:\n",
    "        return []\n",
    "    \n",
    "    annotations = []\n",
    "    # Adding labels\n",
    "    for d in annot:\n",
    "        annotations.append(dict(xref='paper', x=d['x'], y=d['y'],\n",
    "                           xanchor='left', yanchor='bottom',\n",
    "                           text= d['text'],\n",
    "                           font=dict(size=13,\n",
    "                           color=d['color']),\n",
    "                           showarrow=False))\n",
    "    return annotations\n",
    "\n",
    "\n",
    "def generate_barplot(text, annot_dict, orient='v', lmarg=120, h=400):\n",
    "    \"\"\"\n",
    "    Generate the barplot with all data, using previous helper functions\n",
    "    \"\"\"\n",
    "    layout = gen_layout(text[0], text[1], text[2], lmarg, h, gen_annotations(annot_dict))\n",
    "    fig = go.Figure(data=gen_bars(barplot,'color',orient=orient),layout=layout)\n",
    "    return iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": false
       },
       "data": [
        {
         "marker": {
          "color": "grey"
         },
         "name": "Bottom 80%",
         "opacity": 0.5,
         "type": "histogram",
         "x": [
          0.368434612776232,
          0.1830715497939297,
          0.17423822596906116,
          0.15278130216558286,
          0.2566628659620028,
          0.3093786041628453,
          0.3052744069049727,
          0.18052635769766165,
          0.4689144253685549,
          0.20924019303275151,
          0.4069087361600383,
          0.29031762907112635,
          0.3333054343342894,
          0.2628980121883867,
          0.3002440305882656,
          0.13162821994502494,
          0.17403863010498355,
          0.3554671244509722,
          0.2526802747534185,
          0.17122716921275652,
          0.41692578988097834,
          0.45941412875772863,
          0.2902688785494653,
          0.5111277206583222,
          0.2116430613378567,
          0.1502542225970165,
          0.13845216285328493,
          0.3468051479159217,
          0.506404295820667,
          0.3819007720070079,
          0.3740450655163847,
          0.22294101804508404,
          0.7039877309411497,
          0.21055219705229136,
          0.17301413403405713,
          0.49518828732965287,
          0.7382000403268391,
          0.22953830129600558,
          0.21457213033723913,
          0.20816711607057564,
          0.2162159501472081,
          0.1789761551900637,
          0.7540739681862254,
          0.20851469006885348,
          0.1736333933220098,
          0.17887809358449594,
          0.1874805599349333,
          0.5494290741146516,
          0.3341349524793928,
          0.31292799685943795,
          0.191649427271099,
          0.17496215940681253,
          0.37622440838862936,
          0.19363950309866088,
          0.17446246991343936,
          0.4053444218948893,
          0.6084870261168377,
          0.2857231267144146,
          0.19326355494131017,
          0.23361630710151401,
          0.5488525776967917,
          0.35531707946359914,
          0.24619113572653878,
          0.2180431069464103,
          0.5055841878432691,
          0.3076406813295188,
          0.2176316213735236,
          0.18456972618836764,
          0.3161536455455035,
          0.5474076714520464,
          0.6574938271508,
          0.5116045446159884,
          0.4353311630260315,
          0.2349961377200248,
          0.4912785884340519,
          0.4238597207923348,
          0.37545407711540957,
          0.3080450867313626,
          0.25506629377498424,
          0.3192069695409768,
          0.17609818979740813,
          0.3541556728991241,
          0.7736157537476438,
          0.2579424476331581,
          0.3018854054195426,
          0.18522505407636108,
          0.33760541563748686,
          0.23829748519263558,
          0.5785015705472363,
          0.47544756813748407,
          0.7470741342630541,
          0.445623397457638,
          0.16088474713506523,
          0.2986877315997883,
          0.1835104569018516,
          0.2051352382461524,
          0.3688928925920144,
          0.6002806667391162,
          0.18615995371678626,
          0.21219069678792518,
          0.38849665569908165,
          0.4928599252842219,
          0.8027662861809057,
          0.48857143948937376,
          0.6178067243230277,
          0.16115411927267143,
          0.20185861694941448,
          0.2016389963283381,
          0.5334164523432671,
          0.17471928870430004,
          0.19017384915151408,
          0.339362103629274,
          0.6859301431885989,
          0.20142575695355003,
          0.17115448174009076,
          0.6358110203606888,
          0.22806097897340605,
          0.7852165360310517,
          0.43020874618839233,
          0.2986657811846119,
          0.22487914490141636,
          0.22372659165994108,
          0.29111313828600915,
          0.6163389939941458,
          0.7253468261577394,
          0.26152915134003407,
          0.25069421533419767,
          0.3812080426047217,
          0.15720433821538168,
          0.3525388423933885,
          0.2106651399989981,
          0.41060473552366106,
          0.20631891915416503,
          0.13442202796111127,
          0.21847913500879204,
          0.22713967413527536,
          0.4941500973341547,
          0.29043621000195435,
          0.35021336840898154,
          0.4413858833935622,
          0.21416072830799354,
          0.4190055089917858,
          0.5813286191146873,
          0.1718882686441281,
          0.3436557399081316,
          0.3101856938286281,
          0.21889891553526764,
          0.8290928618878233,
          0.47566661002822536,
          0.1948176819573354,
          0.354981724035913,
          0.1917302148807048,
          0.2802509893570597,
          0.15046665390969133,
          0.32623496178750055,
          0.2364315101697959,
          0.2545437308614445,
          0.28993205690853696,
          0.30069143777144053,
          0.28054986640064994,
          0.5204476760424884,
          0.39569604975816136,
          0.3360339717236435,
          0.5726420100939824,
          0.30125414160559755,
          0.2975459280735684,
          0.20849132931654066,
          0.7983129902953227,
          0.28012199334206345,
          0.2791264690465425,
          0.2146906836670546,
          0.31740283695798144,
          0.17164223184125108,
          0.2919153561599055,
          0.6752251964542977,
          0.26699977154003096,
          0.19306392445521645,
          0.5517079678764282,
          0.42184185390339285,
          0.26215966815660857,
          0.7071217095734018,
          0.16846659237632675,
          0.18630510970992248,
          0.1793240265666547,
          0.4860105961671635,
          0.2343242827027769,
          0.3235455841324092,
          0.3616843536954848,
          0.20813558152859787,
          0.5017817758250551,
          0.638934313381937,
          0.1961609158771638,
          0.2067488164611876,
          0.4448378222791112,
          0.47796055625215234,
          0.18454013712090137,
          0.2585802862224062,
          0.7842361619368869,
          0.2784180845151886,
          0.2552186477416347,
          0.22398744971156145,
          0.2310775597611196,
          0.22066012456492026,
          0.320913533906314,
          0.39900364177315945,
          0.18865325986751924,
          0.2667436841229102,
          0.22125625140990418,
          0.576005888231861,
          0.40367328478859477,
          0.22925317706024922,
          0.29387142292923496,
          0.24957357611081013,
          0.4415679352916988,
          0.18785985150503798,
          0.20487140209425259,
          0.1839323618075252,
          0.33231560030872465,
          0.21371199165126498,
          0.44689308805303884,
          0.4804020689545941,
          0.28482857873536915,
          0.24432670818741986,
          0.6415264222913593,
          0.3672111680643974,
          0.18096869716607425,
          0.4144699537494446,
          0.24010659623842917,
          0.34191399625718993,
          0.4016188298300537,
          0.43536619960976525,
          0.2600350444483832,
          0.1396612183587528,
          0.3653373258744938,
          0.19641278346055893,
          0.33793908706982156,
          0.426201732818985,
          0.3289727773066235,
          0.40706017322534366,
          0.5161510892394678,
          0.2501695442854337,
          0.18467382630153567,
          0.26634716889738985,
          0.7532330886609298,
          0.3808713199012539,
          0.5939217092662524,
          0.31134690093819156,
          0.19828900605236469,
          0.2556569551873808,
          0.46438541192481014,
          0.3752677248316424,
          0.23066275805882178,
          0.43476044591127655,
          0.15342929605048053,
          0.41607349225181334,
          0.37508180120247275,
          0.28142133133692543,
          0.3283872463859445,
          0.2922052672289217,
          0.36158232932903156,
          0.44084510915803865,
          0.20801033354695891,
          0.2529700935153807,
          0.3749780662789323,
          0.2477194318259382,
          0.3302589570334214,
          0.2023122737662889,
          0.40382675044174526,
          0.1770199987028011,
          0.44485444991551626,
          0.48520712824867085,
          0.5135426760379997,
          0.22488834302562308,
          0.34258957493819764,
          0.42876465269187963,
          0.2126544629348,
          0.46833138560338805,
          0.2737724657583044,
          0.5735692088855155,
          0.3366105290057011,
          0.6425682435594595,
          0.5592868412311295,
          0.20006793764434827,
          0.40824881786812445,
          0.3315787467301522,
          0.25065345775976056,
          0.38414137695405365,
          0.4497293397147503,
          0.3206762356241947,
          0.519982161862524,
          0.23049494837091378,
          0.17555779488488402,
          0.1676749058117359,
          0.34021799770818056,
          0.18797827765076092,
          0.2654798238774804,
          0.35207809507114407,
          0.3073415062564836,
          0.41947184567908286,
          0.4308616422554598,
          0.15169012650180014,
          0.3999975485932436,
          0.6850747359686918,
          0.2949786731753101,
          0.3397983071080436,
          0.1928130295623982,
          0.5872644822864386,
          0.2552769501580531,
          0.16297709318701048,
          0.5068452101011929,
          0.22474411574640463,
          0.24479788269433897,
          0.24959635081333673,
          0.2488341037052901,
          0.32227292952512665,
          0.5399151392307144,
          0.25550817258944947,
          0.23521123175050468,
          0.2902978501507567,
          0.6069522775724296,
          0.20765791171913164,
          0.24740936831969373,
          0.19831654766594178,
          0.2198950364692838,
          0.2870152707279399,
          0.1481472363355659,
          0.4183900210989796,
          0.41731600837129357,
          0.3110563439410109,
          0.2857461408041445,
          0.15682207925484887,
          0.4877876787074961,
          0.7396374910898971,
          0.6598726371124664,
          0.18365838359446005,
          0.2381535617957884,
          0.27790654133776144,
          0.3911517121024624,
          0.289637942914776,
          0.3043598332877079,
          0.3083211892497933,
          0.585492511716128,
          0.3218967342565441,
          0.18945531617027953,
          0.22956472286782512,
          0.5278752666114579,
          0.18853586473393974,
          0.4436501154656598,
          0.17860466185949517,
          0.7125076155336979,
          0.2780098497006132,
          0.2611900306470909,
          0.15772006998867563,
          0.311392216094794,
          0.3585551967552925,
          0.291938695986111,
          0.23714270353891256,
          0.30850568680980034,
          0.19576698532544515,
          0.3693570981469284,
          0.2698600291041265,
          0.21121497413415585,
          0.2336078680584766,
          0.19671218405008306,
          0.4677945360257376,
          0.22926050965200812,
          0.2231211708587437,
          0.44851408723569497,
          0.3829135297789945,
          0.33742814888064243,
          0.1906313590838707,
          0.3372457717426861,
          0.4192930702439502,
          0.17643467162998933,
          0.31949612417769097,
          0.24982422031542556,
          0.29823323430407106,
          0.22752599282232935,
          0.13548913539202811,
          0.18547454446895162,
          0.17610648485363767,
          0.31532604975341566,
          0.535150975097133,
          0.47839484676549204,
          0.6595838042140776,
          0.3180340283202142,
          0.14609099204562953,
          0.5797358367068621,
          0.27559296340396205,
          0.25543676963511014,
          0.22263698434858145,
          0.16112843882172917,
          0.28302811823109303,
          0.27051274725503494,
          0.4391340789431064,
          0.30595276216770906,
          0.3832433469924526,
          0.19899624455558984,
          0.22336094494827863,
          0.4504021985098027,
          0.34433218437405405,
          0.34815339885564023,
          0.17570583168043372,
          0.4726763114743791,
          0.1572466991882059,
          0.25185102865079406,
          0.3252876207900897,
          0.21262983375329175,
          0.41605989429563583,
          0.15284482841593458,
          0.20234247919497694,
          0.1367551933477059,
          0.3179582286306879,
          0.3985257320123635,
          0.4482829441734243,
          0.5747995954017912,
          0.16412597271685694,
          0.35346853389199934,
          0.3828294439082759,
          0.2139616812590057,
          0.15230105339491165,
          0.25190678853105747,
          0.1482736083995069,
          0.4209080866057358,
          0.1786363518300983,
          0.20999660402308867,
          0.3016917576629213,
          0.3375892354659891,
          0.41883291400817224,
          0.39291055094039196,
          0.24213316352795777,
          0.28061133691885654,
          0.2223855920831177,
          0.3159803400435401,
          0.25612696255471407,
          0.29177208301404184,
          0.18531444340383574,
          0.256047542294135,
          0.45353251405505457,
          0.22414561067566294,
          0.6312715616129981,
          0.7812163981940845,
          0.3154637132025682,
          0.5525366450910345,
          0.2463673557767651,
          0.39206811108108774,
          0.23266314182320058,
          0.2936023483895771,
          0.1676326188819936,
          0.246221863296881,
          0.19209881972114942,
          0.3834341150756525,
          0.22748249055221165,
          0.18212301196823272,
          0.1664207768313654,
          0.22791373795299663,
          0.505351454687639,
          0.4316068780081071,
          0.4503530530856319,
          0.25688821645481047,
          0.2645225115016081,
          0.5250697542386973,
          0.3786532635536582,
          0.1580810968696514,
          0.6817970420415143,
          0.35278508738933806,
          0.15791569996741503,
          0.6573180910599654,
          0.17756477146267535,
          0.17301836128505163,
          0.1655317785127742,
          0.25226754096668597,
          0.19566472116396244,
          0.15614855483460735,
          0.155020505920973,
          0.28318338151948896,
          0.22899243917672138,
          0.27264598654252725,
          0.19731199032545543,
          0.19514066433225027,
          0.27407685300203594,
          0.4635505845612007,
          0.3297371192325351,
          0.19592376943262413,
          0.4486789178878474,
          0.1462183197493049,
          0.3934297268677984,
          0.17989576613965094,
          0.18272574595470273,
          0.19623570972632023,
          0.16181270189158636,
          0.1557295338293233,
          0.19081027728688266,
          0.24929416940601629,
          0.21912132452639219,
          0.6119895472450756,
          0.204057355785438,
          0.2607460936676225,
          0.2780351054747035,
          0.23764081787544156,
          0.20741740967734143,
          0.5560571294921731,
          0.16560829636847532,
          0.3700051181572289,
          0.44601839163599877,
          0.7422487569624378,
          0.374856697994391,
          0.24268999728738228,
          0.36206829935374646,
          0.7768369496959731,
          0.21167515804922993,
          0.31875879230385484,
          0.24307848808521634,
          0.23380003860571497,
          0.43988108781376056,
          0.22762143236720384,
          0.25663067492354025,
          0.4424384302537492,
          0.3421889696067035,
          0.16214870687072389,
          0.15349709335311412,
          0.2016432780112491,
          0.5035033363335791,
          0.4585462315457166,
          0.3850718845641007,
          0.7787006276652768,
          0.395895331563917,
          0.24742045121993142,
          0.8473251029874448,
          0.38008583184689815
         ]
        },
        {
         "marker": {
          "color": "#295D7F"
         },
         "name": "Top 20%",
         "opacity": 0.5,
         "type": "histogram",
         "x": [
          0.7531712237952916,
          0.47499361446918753,
          0.8582734118925348,
          0.6651642779596366,
          0.639957531870158,
          0.6710587406603991,
          0.7908720668410834,
          0.8182881791554821,
          0.33346482217051054,
          0.5038601261485887,
          0.8323859280592386,
          0.6037513122586953,
          0.7806501509571311,
          0.7558739257908993,
          0.816319072918862,
          0.5645110280876992,
          0.19030424823691422,
          0.5634243375402341,
          0.16086194128767495,
          0.6041944781673917,
          0.6063390692592245,
          0.5871266214205701,
          0.7752621255810829,
          0.3844914254130808,
          0.7830997933653567,
          0.8664701864975087,
          0.3276803746346129,
          0.7958413741969514,
          0.8207165545768678,
          0.19353066401389435,
          0.7449967080452287,
          0.8597329274177158,
          0.46792329751497386,
          0.5511223222952795,
          0.794679825280066,
          0.4846077754180884,
          0.16278524756589216,
          0.8147234926180433,
          0.2402987205282442,
          0.5903119034021513,
          0.3000423336862814,
          0.28043402494287645,
          0.28004443440569565,
          0.8508716371009609,
          0.7677224587478573,
          0.8250110136528118,
          0.8165476234537306,
          0.6543304942839081,
          0.8578977213824202,
          0.5453055313589109,
          0.8460548142626897,
          0.6154280013258566,
          0.7249871749341352,
          0.5305334200221278,
          0.37708315028383177,
          0.8425072131168432,
          0.57495617826596,
          0.6764037844903297,
          0.8322144907503943,
          0.8478794775366977,
          0.8559517697873884,
          0.4225524926838631,
          0.3580508951282106,
          0.7063250496941715,
          0.3360432860549011,
          0.7859507741544938,
          0.39042244374102936,
          0.5234931894701087,
          0.8428356917145364,
          0.8501784601472847,
          0.8164401433144857,
          0.849160908004706,
          0.8529652802987748,
          0.5570469267556417,
          0.8532431302470085,
          0.2629841364902997,
          0.17313846275293454,
          0.6084670181494389,
          0.7996824682344876,
          0.7371548125497497,
          0.8479477048517912,
          0.5019882858054558,
          0.5555995252912911,
          0.6245946046046047,
          0.8268698391577679,
          0.6616903892135927,
          0.6233435113633026,
          0.827896173069474,
          0.8660163900592017,
          0.3935234352663918,
          0.8197599347821454,
          0.6445785004078408,
          0.7573750887119445,
          0.7657282079900852,
          0.716645823988918,
          0.8237400868819458,
          0.743632728704507,
          0.6700118076917222,
          0.3825675694691013,
          0.8064644738262283,
          0.20323737755729485,
          0.8259732032753107,
          0.20492036879017414,
          0.8039068165410405,
          0.5177079742265167,
          0.7076058530558547,
          0.7903138953867257,
          0.2808190414190054,
          0.7959843872074496,
          0.7694859789445305,
          0.8295852787455064,
          0.7599577272196295,
          0.4714991812739134,
          0.7652206533963928,
          0.6294180508250731,
          0.33880458671265135,
          0.8079751892014952,
          0.29888188140401173,
          0.2415579870829811,
          0.8465696268330187,
          0.847395016855755,
          0.6998503164621225,
          0.8024628653097152,
          0.26888279641088153,
          0.5385046458616294,
          0.6377250454089639,
          0.46399522533240206,
          0.2615308659278851,
          0.6104631851195095,
          0.8374691592338168,
          0.8323286781086312,
          0.6841120333303415,
          0.5923259644964267,
          0.8115840256575091,
          0.798363982475862,
          0.8292011254529058,
          0.6500436178021264,
          0.2002115962169478,
          0.8650518035390375,
          0.8311727768188053,
          0.37291365933657494,
          0.29987712111591547,
          0.8617839936667352,
          0.7561023199187793,
          0.7892477983022064,
          0.7713190932101428,
          0.8397637311432542,
          0.8455500933056707,
          0.6705696179077938,
          0.677430746057091,
          0.8385366841848438,
          0.7597815669958535,
          0.6654293299153151,
          0.7770602456048638,
          0.662933823136,
          0.19505314625975642,
          0.5417978208822061,
          0.6547688337004178,
          0.8296055997968919,
          0.7952095166337625,
          0.6935776161946535,
          0.4778787163988168,
          0.6237982163618871,
          0.53258006688734,
          0.38778453186341666,
          0.7824886454982436,
          0.8523686127011657,
          0.8152596449953237,
          0.7824469881460111,
          0.23171683710711544,
          0.7453201799062951,
          0.6742383444015827,
          0.5046995121638891,
          0.8079190155474035,
          0.8062985439690978,
          0.8445162592607275,
          0.8432857482902382,
          0.771327182870871,
          0.7533172987880192,
          0.5067129352388156,
          0.8064182095150831,
          0.3134397986319412,
          0.8500628045572011,
          0.7553407480599543,
          0.848550877566938,
          0.6405764273482912,
          0.7562797650188229,
          0.7943779871287735,
          0.8233531360628077,
          0.42685556255387225,
          0.6577217012776384,
          0.8156419934304381,
          0.6649024780177035,
          0.8525266222718848,
          0.7392154454578614,
          0.8451230794624446,
          0.7749830363697388,
          0.3640505285090512,
          0.844795202288579,
          0.43613362920191967,
          0.51148662077119,
          0.6506545792773086,
          0.7013378275227264,
          0.5630729672558096,
          0.5331710431029391,
          0.8235095382574811,
          0.708987611696904,
          0.7118023517827123,
          0.698002902353309,
          0.8230612773708301,
          0.844375603617685,
          0.36391648810718646,
          0.8438331481802411,
          0.3058397495643007,
          0.4126216170691638,
          0.48523306775004715,
          0.20676108687983924,
          0.27880216132834956,
          0.7856361219963826,
          0.6882537590621669,
          0.35025403880106687,
          0.850527776431002,
          0.671799254390155,
          0.8607730314352111,
          0.7510021725517171,
          0.626441686168057,
          0.4083591679588271,
          0.315379267254217,
          0.7350539108620072,
          0.7746495301376859,
          0.41873391946938915,
          0.6028501672484463,
          0.580127889360929,
          0.83044916352742,
          0.8121331397577372,
          0.6910289477313043,
          0.5187639430242037,
          0.7830612563208228,
          0.7281420641596688,
          0.5226060921859118,
          0.8055628569777051,
          0.7075207066295512,
          0.8191215227666214,
          0.664504214404532,
          0.6713422866273787,
          0.3580972192051518,
          0.6801683952232818,
          0.8504355897042812,
          0.4862117795838712,
          0.16806827227351945,
          0.7984707636721495,
          0.7701660999848967,
          0.48664111862994786,
          0.7580350907247076,
          0.7689336371703054,
          0.8476381040932401,
          0.5979428113679419,
          0.6774906226926365,
          0.5972894993764448,
          0.8204910639388376,
          0.8462158165577144,
          0.5762070572200017,
          0.8180239205719859,
          0.48086947482629383,
          0.39892412685186707,
          0.7486206442332095,
          0.8297438271472256,
          0.845002941419465,
          0.8156900892407231,
          0.4278799783440916,
          0.7961903356504916,
          0.8319570975431817,
          0.5330730692867546,
          0.8496712751380977,
          0.6148686514564454,
          0.8582684171406598,
          0.3085234319690837,
          0.7170046816852175,
          0.8070775244580026,
          0.8503665721187349,
          0.8374001522804677,
          0.5646898516062945,
          0.7833503273589862,
          0.7373581999219393,
          0.7089633913602416,
          0.6521025433533234,
          0.8487113029594702,
          0.7477985125330968,
          0.6196885612132681,
          0.8023356171445067,
          0.5468175185835791,
          0.7024173067553912,
          0.7993108233232913,
          0.8636203497918515,
          0.8269562542297368,
          0.5937496468998109,
          0.756062273634914,
          0.838077659540267,
          0.25774166818162925,
          0.748817280212784,
          0.7570388402212275,
          0.7793287486432031,
          0.8477989885123285,
          0.5974877774239107,
          0.730432553279277,
          0.7203231465683513,
          0.7889095164185798,
          0.8425497975833042,
          0.46774295552527,
          0.6162569558478139,
          0.3565084072771053,
          0.7778912143582594,
          0.45906045414727087,
          0.6041185717353516,
          0.6394912971579633,
          0.8144165942522151,
          0.7902588017391763,
          0.46453489687854826,
          0.3184447475329951,
          0.7235796522486648,
          0.8351153767142634,
          0.85518981416438,
          0.6540153685126084,
          0.8376426611171515,
          0.5418059966919752,
          0.6093306736730026,
          0.5056228627260941,
          0.7290376045611949,
          0.5087367734280528,
          0.4770455132158038,
          0.7604353972546526,
          0.8114471654781514,
          0.6444990313071925,
          0.8433532504376624,
          0.2474463987487736,
          0.7829416956400199,
          0.6501960930172686,
          0.7627660668228133,
          0.8470653168382778,
          0.4129561983423771,
          0.8549760072400467,
          0.8553084693235414,
          0.7668400789330208,
          0.8662628369799807,
          0.8611747696088543,
          0.8250476978311941,
          0.8212936153692468,
          0.8527988668099107,
          0.8601427953577985,
          0.6957913905034327,
          0.6147728148131798,
          0.7632824005136946,
          0.44926834260122545,
          0.4015233180676989,
          0.6960139523455503,
          0.7342261804653443,
          0.8537038455115691,
          0.7376380655387724,
          0.7103635050029198,
          0.8331919503435133,
          0.4772450884406804,
          0.6755985058198073,
          0.5430168356773768,
          0.6899930623437627,
          0.8490392669105511,
          0.6973043177885052,
          0.8697610061809997,
          0.7937732531013526,
          0.5460776662816286,
          0.3174720931458583,
          0.2581048667856545,
          0.8382093320448423,
          0.8349095781708966,
          0.8451737324700254,
          0.23009525533550193,
          0.49686443711873807,
          0.7822686914395112,
          0.6040427879712098,
          0.8302561337567209,
          0.7283295344070968,
          0.3674216219381084,
          0.8318398727990542,
          0.8004879939365257,
          0.8534794931965237,
          0.26187785356112897,
          0.8679050823294736,
          0.7976690432818617,
          0.5045385427969296,
          0.31068720079560785,
          0.8337413602301569,
          0.8299735162055463,
          0.529422142875682,
          0.4902767516530818,
          0.8555234723523117,
          0.7201960574548654,
          0.5230779520981819,
          0.4927115395201207,
          0.8362262331746746,
          0.7012364958990277,
          0.5319340220259381,
          0.6368015677502255,
          0.7871996570925823,
          0.8383525310478486,
          0.8310763315986988,
          0.2995539067730345,
          0.3018909447562452,
          0.8282480425869765,
          0.35072680602090944,
          0.8073807849753856,
          0.8374462535169015,
          0.8209542201444072,
          0.7807013776042083,
          0.8514878142766226,
          0.4803115109671333,
          0.6518699204477667,
          0.5792721863763921,
          0.8252316492936428,
          0.427138358185192,
          0.6350369273981817,
          0.5094843220323859,
          0.6785687403874436,
          0.744950072533364,
          0.7544768488033693,
          0.7095825841430045,
          0.5362357366849033,
          0.36399120384310346,
          0.5349776082524577,
          0.6768887975791069,
          0.8235474561274196,
          0.2839788287170807,
          0.3035366587117033,
          0.775576660376331,
          0.501600047968546,
          0.8145465598714857,
          0.25413813884897074,
          0.3326837201212166,
          0.7436398017154443,
          0.8407472012555905,
          0.6549642310603513,
          0.7799616126267972,
          0.8476606777608613,
          0.269905713171161,
          0.8639083323178817,
          0.36686678975923426,
          0.5127748199105115,
          0.6554907677917468,
          0.6321963653708673,
          0.8182402446494718,
          0.7193933829587609,
          0.695613436279048,
          0.8388616360474805,
          0.7522371884427588,
          0.5697360011503042,
          0.6368795542681432,
          0.3595067748885201,
          0.8193603588599897,
          0.7255117906071817,
          0.8100483030148727,
          0.7562761773620186,
          0.6388895202056913,
          0.34323044062948926,
          0.5028782111372097,
          0.7828050800187423,
          0.8316296011613493,
          0.8371686766122897,
          0.8565468414781009,
          0.5694895647313869,
          0.6298285370214934,
          0.857916603222915,
          0.18737497371487896,
          0.6404115070631515,
          0.7871691311404032,
          0.8073593695817513,
          0.5721022732782757,
          0.3188277367064052,
          0.41768290405643993,
          0.4157167794524992,
          0.8520951229608734,
          0.6428627323146876,
          0.37201114180238615,
          0.826369304797164,
          0.8234462171277765,
          0.7513951380752835,
          0.4605413263112079,
          0.7750319054462496,
          0.600766891403725,
          0.7149480781838615,
          0.5377459938659552,
          0.7544871265674628,
          0.6835793750383075,
          0.5603460239515351,
          0.4843243950444014,
          0.6952767151349037,
          0.68401907870753,
          0.862920961067097,
          0.661670899380292,
          0.7948741236429384,
          0.7356687952906658,
          0.481307677540429,
          0.8203111582055906,
          0.590794858338146,
          0.22507589815412357,
          0.7240359891364274,
          0.8465719469996459,
          0.6573760414440897,
          0.8458585473516942,
          0.5320732362181435,
          0.7825678851881006
         ]
        }
       ],
       "layout": {
        "barmode": "overlay",
        "height": 400,
        "margin": {
         "l": 150
        },
        "plot_bgcolor": "rgba(0,0,0,0)",
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "<b>Distribution of Scores From the Top 20% and Bottom 80%</b><br><i>test data</i>"
        },
        "width": 800,
        "xaxis": {
         "color": "#383838",
         "showgrid": false,
         "title": {
          "font": {
           "color": "#383838"
          },
          "text": "Probability Score"
         }
        },
        "yaxis": {
         "color": "#383838",
         "showgrid": false,
         "title": {
          "font": {
           "color": "#383838"
          },
          "text": "Quantity of Respondents"
         }
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"d1bbc7a4-2b55-4fc2-9609-311b04e82e36\" class=\"plotly-graph-div\" style=\"height:400px; width:800px;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    \n",
       "                if (document.getElementById(\"d1bbc7a4-2b55-4fc2-9609-311b04e82e36\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        'd1bbc7a4-2b55-4fc2-9609-311b04e82e36',\n",
       "                        [{\"marker\": {\"color\": \"grey\"}, \"name\": \"Bottom 80%\", \"opacity\": 0.5, \"type\": \"histogram\", \"x\": [0.368434612776232, 0.1830715497939297, 0.17423822596906116, 0.15278130216558286, 0.2566628659620028, 0.3093786041628453, 0.3052744069049727, 0.18052635769766165, 0.4689144253685549, 0.20924019303275151, 0.4069087361600383, 0.29031762907112635, 0.3333054343342894, 0.2628980121883867, 0.3002440305882656, 0.13162821994502494, 0.17403863010498355, 0.3554671244509722, 0.2526802747534185, 0.17122716921275652, 0.41692578988097834, 0.45941412875772863, 0.2902688785494653, 0.5111277206583222, 0.2116430613378567, 0.1502542225970165, 0.13845216285328493, 0.3468051479159217, 0.506404295820667, 0.3819007720070079, 0.3740450655163847, 0.22294101804508404, 0.7039877309411497, 0.21055219705229136, 0.17301413403405713, 0.49518828732965287, 0.7382000403268391, 0.22953830129600558, 0.21457213033723913, 0.20816711607057564, 0.2162159501472081, 0.1789761551900637, 0.7540739681862254, 0.20851469006885348, 0.1736333933220098, 0.17887809358449594, 0.1874805599349333, 0.5494290741146516, 0.3341349524793928, 0.31292799685943795, 0.191649427271099, 0.17496215940681253, 0.37622440838862936, 0.19363950309866088, 0.17446246991343936, 0.4053444218948893, 0.6084870261168377, 0.2857231267144146, 0.19326355494131017, 0.23361630710151401, 0.5488525776967917, 0.35531707946359914, 0.24619113572653878, 0.2180431069464103, 0.5055841878432691, 0.3076406813295188, 0.2176316213735236, 0.18456972618836764, 0.3161536455455035, 0.5474076714520464, 0.6574938271508, 0.5116045446159884, 0.4353311630260315, 0.2349961377200248, 0.4912785884340519, 0.4238597207923348, 0.37545407711540957, 0.3080450867313626, 0.25506629377498424, 0.3192069695409768, 0.17609818979740813, 0.3541556728991241, 0.7736157537476438, 0.2579424476331581, 0.3018854054195426, 0.18522505407636108, 0.33760541563748686, 0.23829748519263558, 0.5785015705472363, 0.47544756813748407, 0.7470741342630541, 0.445623397457638, 0.16088474713506523, 0.2986877315997883, 0.1835104569018516, 0.2051352382461524, 0.3688928925920144, 0.6002806667391162, 0.18615995371678626, 0.21219069678792518, 0.38849665569908165, 0.4928599252842219, 0.8027662861809057, 0.48857143948937376, 0.6178067243230277, 0.16115411927267143, 0.20185861694941448, 0.2016389963283381, 0.5334164523432671, 0.17471928870430004, 0.19017384915151408, 0.339362103629274, 0.6859301431885989, 0.20142575695355003, 0.17115448174009076, 0.6358110203606888, 0.22806097897340605, 0.7852165360310517, 0.43020874618839233, 0.2986657811846119, 0.22487914490141636, 0.22372659165994108, 0.29111313828600915, 0.6163389939941458, 0.7253468261577394, 0.26152915134003407, 0.25069421533419767, 0.3812080426047217, 0.15720433821538168, 0.3525388423933885, 0.2106651399989981, 0.41060473552366106, 0.20631891915416503, 0.13442202796111127, 0.21847913500879204, 0.22713967413527536, 0.4941500973341547, 0.29043621000195435, 0.35021336840898154, 0.4413858833935622, 0.21416072830799354, 0.4190055089917858, 0.5813286191146873, 0.1718882686441281, 0.3436557399081316, 0.3101856938286281, 0.21889891553526764, 0.8290928618878233, 0.47566661002822536, 0.1948176819573354, 0.354981724035913, 0.1917302148807048, 0.2802509893570597, 0.15046665390969133, 0.32623496178750055, 0.2364315101697959, 0.2545437308614445, 0.28993205690853696, 0.30069143777144053, 0.28054986640064994, 0.5204476760424884, 0.39569604975816136, 0.3360339717236435, 0.5726420100939824, 0.30125414160559755, 0.2975459280735684, 0.20849132931654066, 0.7983129902953227, 0.28012199334206345, 0.2791264690465425, 0.2146906836670546, 0.31740283695798144, 0.17164223184125108, 0.2919153561599055, 0.6752251964542977, 0.26699977154003096, 0.19306392445521645, 0.5517079678764282, 0.42184185390339285, 0.26215966815660857, 0.7071217095734018, 0.16846659237632675, 0.18630510970992248, 0.1793240265666547, 0.4860105961671635, 0.2343242827027769, 0.3235455841324092, 0.3616843536954848, 0.20813558152859787, 0.5017817758250551, 0.638934313381937, 0.1961609158771638, 0.2067488164611876, 0.4448378222791112, 0.47796055625215234, 0.18454013712090137, 0.2585802862224062, 0.7842361619368869, 0.2784180845151886, 0.2552186477416347, 0.22398744971156145, 0.2310775597611196, 0.22066012456492026, 0.320913533906314, 0.39900364177315945, 0.18865325986751924, 0.2667436841229102, 0.22125625140990418, 0.576005888231861, 0.40367328478859477, 0.22925317706024922, 0.29387142292923496, 0.24957357611081013, 0.4415679352916988, 0.18785985150503798, 0.20487140209425259, 0.1839323618075252, 0.33231560030872465, 0.21371199165126498, 0.44689308805303884, 0.4804020689545941, 0.28482857873536915, 0.24432670818741986, 0.6415264222913593, 0.3672111680643974, 0.18096869716607425, 0.4144699537494446, 0.24010659623842917, 0.34191399625718993, 0.4016188298300537, 0.43536619960976525, 0.2600350444483832, 0.1396612183587528, 0.3653373258744938, 0.19641278346055893, 0.33793908706982156, 0.426201732818985, 0.3289727773066235, 0.40706017322534366, 0.5161510892394678, 0.2501695442854337, 0.18467382630153567, 0.26634716889738985, 0.7532330886609298, 0.3808713199012539, 0.5939217092662524, 0.31134690093819156, 0.19828900605236469, 0.2556569551873808, 0.46438541192481014, 0.3752677248316424, 0.23066275805882178, 0.43476044591127655, 0.15342929605048053, 0.41607349225181334, 0.37508180120247275, 0.28142133133692543, 0.3283872463859445, 0.2922052672289217, 0.36158232932903156, 0.44084510915803865, 0.20801033354695891, 0.2529700935153807, 0.3749780662789323, 0.2477194318259382, 0.3302589570334214, 0.2023122737662889, 0.40382675044174526, 0.1770199987028011, 0.44485444991551626, 0.48520712824867085, 0.5135426760379997, 0.22488834302562308, 0.34258957493819764, 0.42876465269187963, 0.2126544629348, 0.46833138560338805, 0.2737724657583044, 0.5735692088855155, 0.3366105290057011, 0.6425682435594595, 0.5592868412311295, 0.20006793764434827, 0.40824881786812445, 0.3315787467301522, 0.25065345775976056, 0.38414137695405365, 0.4497293397147503, 0.3206762356241947, 0.519982161862524, 0.23049494837091378, 0.17555779488488402, 0.1676749058117359, 0.34021799770818056, 0.18797827765076092, 0.2654798238774804, 0.35207809507114407, 0.3073415062564836, 0.41947184567908286, 0.4308616422554598, 0.15169012650180014, 0.3999975485932436, 0.6850747359686918, 0.2949786731753101, 0.3397983071080436, 0.1928130295623982, 0.5872644822864386, 0.2552769501580531, 0.16297709318701048, 0.5068452101011929, 0.22474411574640463, 0.24479788269433897, 0.24959635081333673, 0.2488341037052901, 0.32227292952512665, 0.5399151392307144, 0.25550817258944947, 0.23521123175050468, 0.2902978501507567, 0.6069522775724296, 0.20765791171913164, 0.24740936831969373, 0.19831654766594178, 0.2198950364692838, 0.2870152707279399, 0.1481472363355659, 0.4183900210989796, 0.41731600837129357, 0.3110563439410109, 0.2857461408041445, 0.15682207925484887, 0.4877876787074961, 0.7396374910898971, 0.6598726371124664, 0.18365838359446005, 0.2381535617957884, 0.27790654133776144, 0.3911517121024624, 0.289637942914776, 0.3043598332877079, 0.3083211892497933, 0.585492511716128, 0.3218967342565441, 0.18945531617027953, 0.22956472286782512, 0.5278752666114579, 0.18853586473393974, 0.4436501154656598, 0.17860466185949517, 0.7125076155336979, 0.2780098497006132, 0.2611900306470909, 0.15772006998867563, 0.311392216094794, 0.3585551967552925, 0.291938695986111, 0.23714270353891256, 0.30850568680980034, 0.19576698532544515, 0.3693570981469284, 0.2698600291041265, 0.21121497413415585, 0.2336078680584766, 0.19671218405008306, 0.4677945360257376, 0.22926050965200812, 0.2231211708587437, 0.44851408723569497, 0.3829135297789945, 0.33742814888064243, 0.1906313590838707, 0.3372457717426861, 0.4192930702439502, 0.17643467162998933, 0.31949612417769097, 0.24982422031542556, 0.29823323430407106, 0.22752599282232935, 0.13548913539202811, 0.18547454446895162, 0.17610648485363767, 0.31532604975341566, 0.535150975097133, 0.47839484676549204, 0.6595838042140776, 0.3180340283202142, 0.14609099204562953, 0.5797358367068621, 0.27559296340396205, 0.25543676963511014, 0.22263698434858145, 0.16112843882172917, 0.28302811823109303, 0.27051274725503494, 0.4391340789431064, 0.30595276216770906, 0.3832433469924526, 0.19899624455558984, 0.22336094494827863, 0.4504021985098027, 0.34433218437405405, 0.34815339885564023, 0.17570583168043372, 0.4726763114743791, 0.1572466991882059, 0.25185102865079406, 0.3252876207900897, 0.21262983375329175, 0.41605989429563583, 0.15284482841593458, 0.20234247919497694, 0.1367551933477059, 0.3179582286306879, 0.3985257320123635, 0.4482829441734243, 0.5747995954017912, 0.16412597271685694, 0.35346853389199934, 0.3828294439082759, 0.2139616812590057, 0.15230105339491165, 0.25190678853105747, 0.1482736083995069, 0.4209080866057358, 0.1786363518300983, 0.20999660402308867, 0.3016917576629213, 0.3375892354659891, 0.41883291400817224, 0.39291055094039196, 0.24213316352795777, 0.28061133691885654, 0.2223855920831177, 0.3159803400435401, 0.25612696255471407, 0.29177208301404184, 0.18531444340383574, 0.256047542294135, 0.45353251405505457, 0.22414561067566294, 0.6312715616129981, 0.7812163981940845, 0.3154637132025682, 0.5525366450910345, 0.2463673557767651, 0.39206811108108774, 0.23266314182320058, 0.2936023483895771, 0.1676326188819936, 0.246221863296881, 0.19209881972114942, 0.3834341150756525, 0.22748249055221165, 0.18212301196823272, 0.1664207768313654, 0.22791373795299663, 0.505351454687639, 0.4316068780081071, 0.4503530530856319, 0.25688821645481047, 0.2645225115016081, 0.5250697542386973, 0.3786532635536582, 0.1580810968696514, 0.6817970420415143, 0.35278508738933806, 0.15791569996741503, 0.6573180910599654, 0.17756477146267535, 0.17301836128505163, 0.1655317785127742, 0.25226754096668597, 0.19566472116396244, 0.15614855483460735, 0.155020505920973, 0.28318338151948896, 0.22899243917672138, 0.27264598654252725, 0.19731199032545543, 0.19514066433225027, 0.27407685300203594, 0.4635505845612007, 0.3297371192325351, 0.19592376943262413, 0.4486789178878474, 0.1462183197493049, 0.3934297268677984, 0.17989576613965094, 0.18272574595470273, 0.19623570972632023, 0.16181270189158636, 0.1557295338293233, 0.19081027728688266, 0.24929416940601629, 0.21912132452639219, 0.6119895472450756, 0.204057355785438, 0.2607460936676225, 0.2780351054747035, 0.23764081787544156, 0.20741740967734143, 0.5560571294921731, 0.16560829636847532, 0.3700051181572289, 0.44601839163599877, 0.7422487569624378, 0.374856697994391, 0.24268999728738228, 0.36206829935374646, 0.7768369496959731, 0.21167515804922993, 0.31875879230385484, 0.24307848808521634, 0.23380003860571497, 0.43988108781376056, 0.22762143236720384, 0.25663067492354025, 0.4424384302537492, 0.3421889696067035, 0.16214870687072389, 0.15349709335311412, 0.2016432780112491, 0.5035033363335791, 0.4585462315457166, 0.3850718845641007, 0.7787006276652768, 0.395895331563917, 0.24742045121993142, 0.8473251029874448, 0.38008583184689815]}, {\"marker\": {\"color\": \"#295D7F\"}, \"name\": \"Top 20%\", \"opacity\": 0.5, \"type\": \"histogram\", \"x\": [0.7531712237952916, 0.47499361446918753, 0.8582734118925348, 0.6651642779596366, 0.639957531870158, 0.6710587406603991, 0.7908720668410834, 0.8182881791554821, 0.33346482217051054, 0.5038601261485887, 0.8323859280592386, 0.6037513122586953, 0.7806501509571311, 0.7558739257908993, 0.816319072918862, 0.5645110280876992, 0.19030424823691422, 0.5634243375402341, 0.16086194128767495, 0.6041944781673917, 0.6063390692592245, 0.5871266214205701, 0.7752621255810829, 0.3844914254130808, 0.7830997933653567, 0.8664701864975087, 0.3276803746346129, 0.7958413741969514, 0.8207165545768678, 0.19353066401389435, 0.7449967080452287, 0.8597329274177158, 0.46792329751497386, 0.5511223222952795, 0.794679825280066, 0.4846077754180884, 0.16278524756589216, 0.8147234926180433, 0.2402987205282442, 0.5903119034021513, 0.3000423336862814, 0.28043402494287645, 0.28004443440569565, 0.8508716371009609, 0.7677224587478573, 0.8250110136528118, 0.8165476234537306, 0.6543304942839081, 0.8578977213824202, 0.5453055313589109, 0.8460548142626897, 0.6154280013258566, 0.7249871749341352, 0.5305334200221278, 0.37708315028383177, 0.8425072131168432, 0.57495617826596, 0.6764037844903297, 0.8322144907503943, 0.8478794775366977, 0.8559517697873884, 0.4225524926838631, 0.3580508951282106, 0.7063250496941715, 0.3360432860549011, 0.7859507741544938, 0.39042244374102936, 0.5234931894701087, 0.8428356917145364, 0.8501784601472847, 0.8164401433144857, 0.849160908004706, 0.8529652802987748, 0.5570469267556417, 0.8532431302470085, 0.2629841364902997, 0.17313846275293454, 0.6084670181494389, 0.7996824682344876, 0.7371548125497497, 0.8479477048517912, 0.5019882858054558, 0.5555995252912911, 0.6245946046046047, 0.8268698391577679, 0.6616903892135927, 0.6233435113633026, 0.827896173069474, 0.8660163900592017, 0.3935234352663918, 0.8197599347821454, 0.6445785004078408, 0.7573750887119445, 0.7657282079900852, 0.716645823988918, 0.8237400868819458, 0.743632728704507, 0.6700118076917222, 0.3825675694691013, 0.8064644738262283, 0.20323737755729485, 0.8259732032753107, 0.20492036879017414, 0.8039068165410405, 0.5177079742265167, 0.7076058530558547, 0.7903138953867257, 0.2808190414190054, 0.7959843872074496, 0.7694859789445305, 0.8295852787455064, 0.7599577272196295, 0.4714991812739134, 0.7652206533963928, 0.6294180508250731, 0.33880458671265135, 0.8079751892014952, 0.29888188140401173, 0.2415579870829811, 0.8465696268330187, 0.847395016855755, 0.6998503164621225, 0.8024628653097152, 0.26888279641088153, 0.5385046458616294, 0.6377250454089639, 0.46399522533240206, 0.2615308659278851, 0.6104631851195095, 0.8374691592338168, 0.8323286781086312, 0.6841120333303415, 0.5923259644964267, 0.8115840256575091, 0.798363982475862, 0.8292011254529058, 0.6500436178021264, 0.2002115962169478, 0.8650518035390375, 0.8311727768188053, 0.37291365933657494, 0.29987712111591547, 0.8617839936667352, 0.7561023199187793, 0.7892477983022064, 0.7713190932101428, 0.8397637311432542, 0.8455500933056707, 0.6705696179077938, 0.677430746057091, 0.8385366841848438, 0.7597815669958535, 0.6654293299153151, 0.7770602456048638, 0.662933823136, 0.19505314625975642, 0.5417978208822061, 0.6547688337004178, 0.8296055997968919, 0.7952095166337625, 0.6935776161946535, 0.4778787163988168, 0.6237982163618871, 0.53258006688734, 0.38778453186341666, 0.7824886454982436, 0.8523686127011657, 0.8152596449953237, 0.7824469881460111, 0.23171683710711544, 0.7453201799062951, 0.6742383444015827, 0.5046995121638891, 0.8079190155474035, 0.8062985439690978, 0.8445162592607275, 0.8432857482902382, 0.771327182870871, 0.7533172987880192, 0.5067129352388156, 0.8064182095150831, 0.3134397986319412, 0.8500628045572011, 0.7553407480599543, 0.848550877566938, 0.6405764273482912, 0.7562797650188229, 0.7943779871287735, 0.8233531360628077, 0.42685556255387225, 0.6577217012776384, 0.8156419934304381, 0.6649024780177035, 0.8525266222718848, 0.7392154454578614, 0.8451230794624446, 0.7749830363697388, 0.3640505285090512, 0.844795202288579, 0.43613362920191967, 0.51148662077119, 0.6506545792773086, 0.7013378275227264, 0.5630729672558096, 0.5331710431029391, 0.8235095382574811, 0.708987611696904, 0.7118023517827123, 0.698002902353309, 0.8230612773708301, 0.844375603617685, 0.36391648810718646, 0.8438331481802411, 0.3058397495643007, 0.4126216170691638, 0.48523306775004715, 0.20676108687983924, 0.27880216132834956, 0.7856361219963826, 0.6882537590621669, 0.35025403880106687, 0.850527776431002, 0.671799254390155, 0.8607730314352111, 0.7510021725517171, 0.626441686168057, 0.4083591679588271, 0.315379267254217, 0.7350539108620072, 0.7746495301376859, 0.41873391946938915, 0.6028501672484463, 0.580127889360929, 0.83044916352742, 0.8121331397577372, 0.6910289477313043, 0.5187639430242037, 0.7830612563208228, 0.7281420641596688, 0.5226060921859118, 0.8055628569777051, 0.7075207066295512, 0.8191215227666214, 0.664504214404532, 0.6713422866273787, 0.3580972192051518, 0.6801683952232818, 0.8504355897042812, 0.4862117795838712, 0.16806827227351945, 0.7984707636721495, 0.7701660999848967, 0.48664111862994786, 0.7580350907247076, 0.7689336371703054, 0.8476381040932401, 0.5979428113679419, 0.6774906226926365, 0.5972894993764448, 0.8204910639388376, 0.8462158165577144, 0.5762070572200017, 0.8180239205719859, 0.48086947482629383, 0.39892412685186707, 0.7486206442332095, 0.8297438271472256, 0.845002941419465, 0.8156900892407231, 0.4278799783440916, 0.7961903356504916, 0.8319570975431817, 0.5330730692867546, 0.8496712751380977, 0.6148686514564454, 0.8582684171406598, 0.3085234319690837, 0.7170046816852175, 0.8070775244580026, 0.8503665721187349, 0.8374001522804677, 0.5646898516062945, 0.7833503273589862, 0.7373581999219393, 0.7089633913602416, 0.6521025433533234, 0.8487113029594702, 0.7477985125330968, 0.6196885612132681, 0.8023356171445067, 0.5468175185835791, 0.7024173067553912, 0.7993108233232913, 0.8636203497918515, 0.8269562542297368, 0.5937496468998109, 0.756062273634914, 0.838077659540267, 0.25774166818162925, 0.748817280212784, 0.7570388402212275, 0.7793287486432031, 0.8477989885123285, 0.5974877774239107, 0.730432553279277, 0.7203231465683513, 0.7889095164185798, 0.8425497975833042, 0.46774295552527, 0.6162569558478139, 0.3565084072771053, 0.7778912143582594, 0.45906045414727087, 0.6041185717353516, 0.6394912971579633, 0.8144165942522151, 0.7902588017391763, 0.46453489687854826, 0.3184447475329951, 0.7235796522486648, 0.8351153767142634, 0.85518981416438, 0.6540153685126084, 0.8376426611171515, 0.5418059966919752, 0.6093306736730026, 0.5056228627260941, 0.7290376045611949, 0.5087367734280528, 0.4770455132158038, 0.7604353972546526, 0.8114471654781514, 0.6444990313071925, 0.8433532504376624, 0.2474463987487736, 0.7829416956400199, 0.6501960930172686, 0.7627660668228133, 0.8470653168382778, 0.4129561983423771, 0.8549760072400467, 0.8553084693235414, 0.7668400789330208, 0.8662628369799807, 0.8611747696088543, 0.8250476978311941, 0.8212936153692468, 0.8527988668099107, 0.8601427953577985, 0.6957913905034327, 0.6147728148131798, 0.7632824005136946, 0.44926834260122545, 0.4015233180676989, 0.6960139523455503, 0.7342261804653443, 0.8537038455115691, 0.7376380655387724, 0.7103635050029198, 0.8331919503435133, 0.4772450884406804, 0.6755985058198073, 0.5430168356773768, 0.6899930623437627, 0.8490392669105511, 0.6973043177885052, 0.8697610061809997, 0.7937732531013526, 0.5460776662816286, 0.3174720931458583, 0.2581048667856545, 0.8382093320448423, 0.8349095781708966, 0.8451737324700254, 0.23009525533550193, 0.49686443711873807, 0.7822686914395112, 0.6040427879712098, 0.8302561337567209, 0.7283295344070968, 0.3674216219381084, 0.8318398727990542, 0.8004879939365257, 0.8534794931965237, 0.26187785356112897, 0.8679050823294736, 0.7976690432818617, 0.5045385427969296, 0.31068720079560785, 0.8337413602301569, 0.8299735162055463, 0.529422142875682, 0.4902767516530818, 0.8555234723523117, 0.7201960574548654, 0.5230779520981819, 0.4927115395201207, 0.8362262331746746, 0.7012364958990277, 0.5319340220259381, 0.6368015677502255, 0.7871996570925823, 0.8383525310478486, 0.8310763315986988, 0.2995539067730345, 0.3018909447562452, 0.8282480425869765, 0.35072680602090944, 0.8073807849753856, 0.8374462535169015, 0.8209542201444072, 0.7807013776042083, 0.8514878142766226, 0.4803115109671333, 0.6518699204477667, 0.5792721863763921, 0.8252316492936428, 0.427138358185192, 0.6350369273981817, 0.5094843220323859, 0.6785687403874436, 0.744950072533364, 0.7544768488033693, 0.7095825841430045, 0.5362357366849033, 0.36399120384310346, 0.5349776082524577, 0.6768887975791069, 0.8235474561274196, 0.2839788287170807, 0.3035366587117033, 0.775576660376331, 0.501600047968546, 0.8145465598714857, 0.25413813884897074, 0.3326837201212166, 0.7436398017154443, 0.8407472012555905, 0.6549642310603513, 0.7799616126267972, 0.8476606777608613, 0.269905713171161, 0.8639083323178817, 0.36686678975923426, 0.5127748199105115, 0.6554907677917468, 0.6321963653708673, 0.8182402446494718, 0.7193933829587609, 0.695613436279048, 0.8388616360474805, 0.7522371884427588, 0.5697360011503042, 0.6368795542681432, 0.3595067748885201, 0.8193603588599897, 0.7255117906071817, 0.8100483030148727, 0.7562761773620186, 0.6388895202056913, 0.34323044062948926, 0.5028782111372097, 0.7828050800187423, 0.8316296011613493, 0.8371686766122897, 0.8565468414781009, 0.5694895647313869, 0.6298285370214934, 0.857916603222915, 0.18737497371487896, 0.6404115070631515, 0.7871691311404032, 0.8073593695817513, 0.5721022732782757, 0.3188277367064052, 0.41768290405643993, 0.4157167794524992, 0.8520951229608734, 0.6428627323146876, 0.37201114180238615, 0.826369304797164, 0.8234462171277765, 0.7513951380752835, 0.4605413263112079, 0.7750319054462496, 0.600766891403725, 0.7149480781838615, 0.5377459938659552, 0.7544871265674628, 0.6835793750383075, 0.5603460239515351, 0.4843243950444014, 0.6952767151349037, 0.68401907870753, 0.862920961067097, 0.661670899380292, 0.7948741236429384, 0.7356687952906658, 0.481307677540429, 0.8203111582055906, 0.590794858338146, 0.22507589815412357, 0.7240359891364274, 0.8465719469996459, 0.6573760414440897, 0.8458585473516942, 0.5320732362181435, 0.7825678851881006]}],\n",
       "                        {\"barmode\": \"overlay\", \"height\": 400, \"margin\": {\"l\": 150}, \"plot_bgcolor\": \"rgba(0,0,0,0)\", \"showlegend\": false, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"<b>Distribution of Scores From the Top 20% and Bottom 80%</b><br><i>test data</i>\"}, \"width\": 800, \"xaxis\": {\"color\": \"#383838\", \"showgrid\": false, \"title\": {\"font\": {\"color\": \"#383838\"}, \"text\": \"Probability Score\"}}, \"yaxis\": {\"color\": \"#383838\", \"showgrid\": false, \"title\": {\"font\": {\"color\": \"#383838\"}, \"text\": \"Quantity of Respondents\"}}},\n",
       "                        {\"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('d1bbc7a4-2b55-4fc2-9609-311b04e82e36');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualization plotting \n",
    "#############################\n",
    "\n",
    "#calculating scores\n",
    "scores = pd.DataFrame(vote_best.predict_proba(Xtest)).iloc[:,1]\n",
    "scores = pd.DataFrame([scores.values, ytest.values]).transpose()\n",
    "scores.columns = ['score', 'target']\n",
    "\n",
    "# Add histogram data\n",
    "x0 = scores[scores['target'] == 0]['score']\n",
    "x1 = scores[scores['target'] == 1]['score']\n",
    "\n",
    "bottom80 = go.Histogram(\n",
    "    x=x0,\n",
    "    opacity=0.5,\n",
    "    marker={'color': 'grey'},\n",
    "    name='Bottom 80%'\n",
    "\n",
    ")\n",
    "top20 = go.Histogram(\n",
    "    x=x1,\n",
    "    opacity=0.5,\n",
    "    marker={'color': '#295D7F'},\n",
    "    name='Top 20%'   \n",
    ")\n",
    "\n",
    "#annot_dict = [{'x': 0.2, 'y': 180, 'text': 'The 80% less paid tend<br>to have lower scores','color': 'gray'},\n",
    "#              {'x': 0.75, 'y': 95, 'text': 'Top 20% tend to have<br>higher scores','color': 'mediumaquamarine'}]\n",
    "\n",
    "layout = gen_layout('<b>Distribution of Scores From the Top 20% and Bottom 80%</b><br><i>test data</i>', \n",
    "                    'Probability Score',\n",
    "                    'Quantity of Respondents',\n",
    "                    #annotations=gen_annotations(annot_dict),\n",
    "                    lmarg=150, h=400,\n",
    "                    )\n",
    "layout['barmode'] = 'overlay'\n",
    "\n",
    "data = [bottom80, top20]\n",
    "layout = go.Layout(layout)\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Voting Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "Train Accuracy: 0.8093975903614458 Precision: 0.8235882058970515 Recall: 0.7900287631831256 F1: 0.8064595057499389\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#voting classifier on test dataset\n",
    "#############################\n",
    "\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "#select models for voting\n",
    "voting_clf_param =[('LOG', log_best),('ADA', ada_best),('RFC', rfc_best),('SVC', svc_best)]\n",
    "\n",
    "#define voting classifier model\n",
    "vote_best_test = VotingClassifier(estimators=voting_clf_param, voting='soft',flatten_transform=False)\n",
    "\n",
    "#fit model\n",
    "vote_best_test.fit(Xtest, ytest)\n",
    "\n",
    "#predict model (k-fold, 5 folds)\n",
    "ypred = cross_val_predict(vote_best, Xtrain, ytrain, cv=folds)\n",
    "\n",
    "vote_accuracy = accuracy_score(ytrain,ypred)\n",
    "vote_precision = precision_score(ytrain,ypred)\n",
    "vote_recall = recall_score(ytrain,ypred)\n",
    "vote_f1 = f1_score(ytrain,ypred)\n",
    "\n",
    "    #output scores\n",
    "print('-'*10), print('Train Accuracy:',vote_accuracy,\n",
    "                     'Precision:',vote_precision,\n",
    "                     'Recall:',vote_recall,\n",
    "                     'F1:', vote_f1), print('-'*10)\n",
    "\n",
    "#saved scores used during write-up of report\n",
    "#Train Accuracy: 0.8103067484662577 Precision: 0.8242245199409158 Recall: 0.8009569377990431 F1: 0.812424168891046"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Receiver Operating Characteristics (ROC) and Area Under Curve (AUC) are measures for model performance at certain thresholds. In detail, ROC represents the probability curve between the True-Positive-Rate and False-Negative-Rate. Please refer to the report for details.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define function to plot ROC curve\n",
    "#############################\n",
    "\n",
    "#import required libraries\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn import metrics\n",
    "\n",
    "#define function to plot ROC curve\n",
    "def plot_roc_curve(fpr, tpr, label=None):\n",
    "    plt.plot(fpr, tpr, linewidth=2, label=label, color='#295D7F')\n",
    "    plt.plot([0, 1], [0, 1], 'k--', color='grey')\n",
    "    \n",
    "    plt.axis([-0.01, 1.05, -0.01, 1.05])\n",
    "    plt.xlabel('False Positive Rate', fontsize=12, color='#383838')\n",
    "    plt.ylabel('True Positive Rate', fontsize=12, color='#383838')\n",
    "    \n",
    "    #plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualize ROC Curve\n",
    "#############################\n",
    "\n",
    "#calculate prediction probability\n",
    "y_pred_proba = vote_best_test.predict_proba(Xtest)[::,1]\n",
    "#set true and false predictions\n",
    "fpr, tpr, _ = metrics.roc_curve(ytest, y_pred_proba)\n",
    "\n",
    "#plot actual graph\n",
    "plt.figure(figsize=(8, 4))\n",
    "plot_roc_curve(fpr, tpr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "The below code transforms the current dataframe into data input for the NN and performs the respective prediction of NN performance on the classification task. In sum, the NNs is used to provide another approach towards classifying professionals.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required library\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5188, 94) (5188, 1)\n"
     ]
    }
   ],
   "source": [
    "#dataframe to array transformation\n",
    "X_n = clean_dataset_dropped.iloc[:,1:].values\n",
    "y_n = clean_dataset_dropped.iloc[:,:1].values\n",
    "\n",
    "#output\n",
    "print(X_n.shape, y_n.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One hot encoded array:\n",
      "[[1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "ohe = OneHotEncoder()\n",
    "y_n = ohe.fit_transform(y_n).toarray()\n",
    "print('One hot encoded array:')\n",
    "print(y_n[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train/test split \n",
    "#from sklearn.model_selection import train_test_split\n",
    "X_train_n,X_test_n,y_train_n,y_test_n = train_test_split(X_n,y_n,test_size = 0.2,random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda/envs/Python3/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 4)                 380       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 10        \n",
      "=================================================================\n",
      "Total params: 390\n",
      "Trainable params: 390\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#NN model summary\n",
    "model = keras.models.Sequential()\n",
    "model.add(Dense(4, input_dim=94, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile model\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer=\"sgd\", metrics=['accuracy']) #optimizer='adam' #keras.optimizer.SGD(lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4150 samples, validate on 1038 samples\n",
      "WARNING:tensorflow:From /opt/anaconda/envs/Python3/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/200\n",
      "4150/4150 [==============================] - 0s 43us/sample - loss: 0.6852 - acc: 0.5742 - val_loss: 0.6670 - val_acc: 0.6002\n",
      "Epoch 2/200\n",
      "4150/4150 [==============================] - 0s 10us/sample - loss: 0.6649 - acc: 0.5973 - val_loss: 0.6516 - val_acc: 0.6243\n",
      "Epoch 3/200\n",
      "4150/4150 [==============================] - 0s 10us/sample - loss: 0.6540 - acc: 0.6212 - val_loss: 0.6415 - val_acc: 0.6445\n",
      "Epoch 4/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.6454 - acc: 0.6366 - val_loss: 0.6329 - val_acc: 0.6609\n",
      "Epoch 5/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.6375 - acc: 0.6463 - val_loss: 0.6249 - val_acc: 0.6705\n",
      "Epoch 6/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.6297 - acc: 0.6573 - val_loss: 0.6170 - val_acc: 0.6744\n",
      "Epoch 7/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.6220 - acc: 0.6680 - val_loss: 0.6095 - val_acc: 0.6773\n",
      "Epoch 8/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.6143 - acc: 0.6723 - val_loss: 0.6016 - val_acc: 0.6840\n",
      "Epoch 9/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.6067 - acc: 0.6810 - val_loss: 0.5940 - val_acc: 0.6936\n",
      "Epoch 10/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.5990 - acc: 0.6892 - val_loss: 0.5866 - val_acc: 0.7004\n",
      "Epoch 11/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.5910 - acc: 0.6993 - val_loss: 0.5790 - val_acc: 0.7081\n",
      "Epoch 12/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.5826 - acc: 0.7067 - val_loss: 0.5713 - val_acc: 0.7110\n",
      "Epoch 13/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.5738 - acc: 0.7142 - val_loss: 0.5636 - val_acc: 0.7139\n",
      "Epoch 14/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.5648 - acc: 0.7190 - val_loss: 0.5562 - val_acc: 0.7187\n",
      "Epoch 15/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.5556 - acc: 0.7255 - val_loss: 0.5485 - val_acc: 0.7293\n",
      "Epoch 16/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.5465 - acc: 0.7304 - val_loss: 0.5410 - val_acc: 0.7312\n",
      "Epoch 17/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.5379 - acc: 0.7357 - val_loss: 0.5337 - val_acc: 0.7408\n",
      "Epoch 18/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.5296 - acc: 0.7410 - val_loss: 0.5266 - val_acc: 0.7476\n",
      "Epoch 19/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.5212 - acc: 0.7480 - val_loss: 0.5196 - val_acc: 0.7582\n",
      "Epoch 20/200\n",
      "4150/4150 [==============================] - 0s 10us/sample - loss: 0.5133 - acc: 0.7523 - val_loss: 0.5129 - val_acc: 0.7620\n",
      "Epoch 21/200\n",
      "4150/4150 [==============================] - 0s 10us/sample - loss: 0.5059 - acc: 0.7588 - val_loss: 0.5066 - val_acc: 0.7630\n",
      "Epoch 22/200\n",
      "4150/4150 [==============================] - 0s 11us/sample - loss: 0.4988 - acc: 0.7643 - val_loss: 0.5011 - val_acc: 0.7640\n",
      "Epoch 23/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.4924 - acc: 0.7677 - val_loss: 0.4957 - val_acc: 0.7688\n",
      "Epoch 24/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.4863 - acc: 0.7725 - val_loss: 0.4907 - val_acc: 0.7688\n",
      "Epoch 25/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.4806 - acc: 0.7764 - val_loss: 0.4860 - val_acc: 0.7697\n",
      "Epoch 26/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.4753 - acc: 0.7822 - val_loss: 0.4817 - val_acc: 0.7726\n",
      "Epoch 27/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.4705 - acc: 0.7841 - val_loss: 0.4778 - val_acc: 0.7755\n",
      "Epoch 28/200\n",
      "4150/4150 [==============================] - 0s 10us/sample - loss: 0.4660 - acc: 0.7870 - val_loss: 0.4743 - val_acc: 0.7794\n",
      "Epoch 29/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.4618 - acc: 0.7892 - val_loss: 0.4711 - val_acc: 0.7832\n",
      "Epoch 30/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.4580 - acc: 0.7930 - val_loss: 0.4679 - val_acc: 0.7871\n",
      "Epoch 31/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.4543 - acc: 0.7947 - val_loss: 0.4648 - val_acc: 0.7852\n",
      "Epoch 32/200\n",
      "4150/4150 [==============================] - 0s 10us/sample - loss: 0.4509 - acc: 0.7957 - val_loss: 0.4621 - val_acc: 0.7871\n",
      "Epoch 33/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.4478 - acc: 0.7995 - val_loss: 0.4596 - val_acc: 0.7881\n",
      "Epoch 34/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.4447 - acc: 0.7981 - val_loss: 0.4573 - val_acc: 0.7890\n",
      "Epoch 35/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.4420 - acc: 0.7995 - val_loss: 0.4551 - val_acc: 0.7948\n",
      "Epoch 36/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.4393 - acc: 0.8010 - val_loss: 0.4531 - val_acc: 0.7967\n",
      "Epoch 37/200\n",
      "4150/4150 [==============================] - 0s 10us/sample - loss: 0.4368 - acc: 0.8017 - val_loss: 0.4516 - val_acc: 0.7919\n",
      "Epoch 38/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.4349 - acc: 0.8012 - val_loss: 0.4497 - val_acc: 0.7958\n",
      "Epoch 39/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.4326 - acc: 0.8024 - val_loss: 0.4480 - val_acc: 0.7948\n",
      "Epoch 40/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.4305 - acc: 0.8034 - val_loss: 0.4464 - val_acc: 0.7987\n",
      "Epoch 41/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.4286 - acc: 0.8048 - val_loss: 0.4451 - val_acc: 0.8015\n",
      "Epoch 42/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.4269 - acc: 0.8060 - val_loss: 0.4439 - val_acc: 0.8054\n",
      "Epoch 43/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.4253 - acc: 0.8060 - val_loss: 0.4427 - val_acc: 0.8035\n",
      "Epoch 44/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.4235 - acc: 0.8072 - val_loss: 0.4416 - val_acc: 0.8025\n",
      "Epoch 45/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.4222 - acc: 0.8082 - val_loss: 0.4406 - val_acc: 0.8044\n",
      "Epoch 46/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.4208 - acc: 0.8087 - val_loss: 0.4396 - val_acc: 0.8025\n",
      "Epoch 47/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.4197 - acc: 0.8099 - val_loss: 0.4388 - val_acc: 0.8073\n",
      "Epoch 48/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.4183 - acc: 0.8108 - val_loss: 0.4387 - val_acc: 0.8102\n",
      "Epoch 49/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.4175 - acc: 0.8108 - val_loss: 0.4375 - val_acc: 0.8083\n",
      "Epoch 50/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.4164 - acc: 0.8092 - val_loss: 0.4364 - val_acc: 0.8092\n",
      "Epoch 51/200\n",
      "4150/4150 [==============================] - 0s 10us/sample - loss: 0.4153 - acc: 0.8128 - val_loss: 0.4357 - val_acc: 0.8112\n",
      "Epoch 52/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.4143 - acc: 0.8123 - val_loss: 0.4351 - val_acc: 0.8121\n",
      "Epoch 53/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.4135 - acc: 0.8123 - val_loss: 0.4345 - val_acc: 0.8121\n",
      "Epoch 54/200\n",
      "4150/4150 [==============================] - 0s 10us/sample - loss: 0.4124 - acc: 0.8137 - val_loss: 0.4345 - val_acc: 0.8131\n",
      "Epoch 55/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.4119 - acc: 0.8137 - val_loss: 0.4343 - val_acc: 0.8141\n",
      "Epoch 56/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.4112 - acc: 0.8149 - val_loss: 0.4331 - val_acc: 0.8170\n",
      "Epoch 57/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.4104 - acc: 0.8152 - val_loss: 0.4330 - val_acc: 0.8170\n",
      "Epoch 58/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.4097 - acc: 0.8145 - val_loss: 0.4323 - val_acc: 0.8179\n",
      "Epoch 59/200\n",
      "4150/4150 [==============================] - 0s 10us/sample - loss: 0.4091 - acc: 0.8145 - val_loss: 0.4322 - val_acc: 0.8179\n",
      "Epoch 60/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.4086 - acc: 0.8147 - val_loss: 0.4316 - val_acc: 0.8189\n",
      "Epoch 61/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.4080 - acc: 0.8159 - val_loss: 0.4313 - val_acc: 0.8198\n",
      "Epoch 62/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.4074 - acc: 0.8173 - val_loss: 0.4310 - val_acc: 0.8179\n",
      "Epoch 63/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.4070 - acc: 0.8157 - val_loss: 0.4305 - val_acc: 0.8208\n",
      "Epoch 64/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.4064 - acc: 0.8152 - val_loss: 0.4301 - val_acc: 0.8198\n",
      "Epoch 65/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.4059 - acc: 0.8169 - val_loss: 0.4298 - val_acc: 0.8189\n",
      "Epoch 66/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.4055 - acc: 0.8157 - val_loss: 0.4295 - val_acc: 0.8198\n",
      "Epoch 67/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.4051 - acc: 0.8154 - val_loss: 0.4294 - val_acc: 0.8198\n",
      "Epoch 68/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.4047 - acc: 0.8157 - val_loss: 0.4291 - val_acc: 0.8198\n",
      "Epoch 69/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.4042 - acc: 0.8181 - val_loss: 0.4288 - val_acc: 0.8189\n",
      "Epoch 70/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.4039 - acc: 0.8166 - val_loss: 0.4286 - val_acc: 0.8198\n",
      "Epoch 71/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.4036 - acc: 0.8154 - val_loss: 0.4283 - val_acc: 0.8198\n",
      "Epoch 72/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.4031 - acc: 0.8176 - val_loss: 0.4281 - val_acc: 0.8208\n",
      "Epoch 73/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.4028 - acc: 0.8154 - val_loss: 0.4281 - val_acc: 0.8179\n",
      "Epoch 74/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.4025 - acc: 0.8173 - val_loss: 0.4279 - val_acc: 0.8237\n",
      "Epoch 75/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.4022 - acc: 0.8171 - val_loss: 0.4279 - val_acc: 0.8189\n",
      "Epoch 76/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.4019 - acc: 0.8169 - val_loss: 0.4277 - val_acc: 0.8160\n",
      "Epoch 77/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.4017 - acc: 0.8186 - val_loss: 0.4276 - val_acc: 0.8160\n",
      "Epoch 78/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.4013 - acc: 0.8178 - val_loss: 0.4275 - val_acc: 0.8170\n",
      "Epoch 79/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.4011 - acc: 0.8173 - val_loss: 0.4272 - val_acc: 0.8150\n",
      "Epoch 80/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.4007 - acc: 0.8171 - val_loss: 0.4270 - val_acc: 0.8150\n",
      "Epoch 81/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.4006 - acc: 0.8171 - val_loss: 0.4267 - val_acc: 0.8256\n",
      "Epoch 82/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.4003 - acc: 0.8181 - val_loss: 0.4265 - val_acc: 0.8208\n",
      "Epoch 83/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.4001 - acc: 0.8183 - val_loss: 0.4264 - val_acc: 0.8208\n",
      "Epoch 84/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.4000 - acc: 0.8183 - val_loss: 0.4268 - val_acc: 0.8131\n",
      "Epoch 85/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3997 - acc: 0.8198 - val_loss: 0.4263 - val_acc: 0.8189\n",
      "Epoch 86/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3994 - acc: 0.8188 - val_loss: 0.4261 - val_acc: 0.8276\n",
      "Epoch 87/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3993 - acc: 0.8190 - val_loss: 0.4259 - val_acc: 0.8247\n",
      "Epoch 88/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3991 - acc: 0.8202 - val_loss: 0.4260 - val_acc: 0.8189\n",
      "Epoch 89/200\n",
      "4150/4150 [==============================] - 0s 10us/sample - loss: 0.3989 - acc: 0.8195 - val_loss: 0.4260 - val_acc: 0.8189\n",
      "Epoch 90/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3986 - acc: 0.8202 - val_loss: 0.4258 - val_acc: 0.8189\n",
      "Epoch 91/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3984 - acc: 0.8205 - val_loss: 0.4256 - val_acc: 0.8208\n",
      "Epoch 92/200\n",
      "4150/4150 [==============================] - 0s 10us/sample - loss: 0.3982 - acc: 0.8198 - val_loss: 0.4254 - val_acc: 0.8218\n",
      "Epoch 93/200\n",
      "4150/4150 [==============================] - 0s 10us/sample - loss: 0.3981 - acc: 0.8202 - val_loss: 0.4253 - val_acc: 0.8247\n",
      "Epoch 94/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3980 - acc: 0.8210 - val_loss: 0.4253 - val_acc: 0.8227\n",
      "Epoch 95/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3979 - acc: 0.8200 - val_loss: 0.4255 - val_acc: 0.8189\n",
      "Epoch 96/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3976 - acc: 0.8205 - val_loss: 0.4253 - val_acc: 0.8198\n",
      "Epoch 97/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3975 - acc: 0.8202 - val_loss: 0.4251 - val_acc: 0.8276\n",
      "Epoch 98/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3972 - acc: 0.8214 - val_loss: 0.4253 - val_acc: 0.8179\n",
      "Epoch 99/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3970 - acc: 0.8198 - val_loss: 0.4248 - val_acc: 0.8266\n",
      "Epoch 100/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3971 - acc: 0.8214 - val_loss: 0.4247 - val_acc: 0.8247\n",
      "Epoch 101/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3970 - acc: 0.8224 - val_loss: 0.4247 - val_acc: 0.8198\n",
      "Epoch 102/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3967 - acc: 0.8219 - val_loss: 0.4248 - val_acc: 0.8189\n",
      "Epoch 103/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3966 - acc: 0.8210 - val_loss: 0.4247 - val_acc: 0.8189\n",
      "Epoch 104/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3964 - acc: 0.8210 - val_loss: 0.4244 - val_acc: 0.8218\n",
      "Epoch 105/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3964 - acc: 0.8212 - val_loss: 0.4245 - val_acc: 0.8189\n",
      "Epoch 106/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3961 - acc: 0.8202 - val_loss: 0.4246 - val_acc: 0.8189\n",
      "Epoch 107/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3960 - acc: 0.8212 - val_loss: 0.4246 - val_acc: 0.8189\n",
      "Epoch 108/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3959 - acc: 0.8210 - val_loss: 0.4244 - val_acc: 0.8198\n",
      "Epoch 109/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3958 - acc: 0.8222 - val_loss: 0.4243 - val_acc: 0.8189\n",
      "Epoch 110/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3958 - acc: 0.8200 - val_loss: 0.4243 - val_acc: 0.8208\n",
      "Epoch 111/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3956 - acc: 0.8217 - val_loss: 0.4245 - val_acc: 0.8198\n",
      "Epoch 112/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3956 - acc: 0.8217 - val_loss: 0.4241 - val_acc: 0.8198\n",
      "Epoch 113/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3953 - acc: 0.8212 - val_loss: 0.4239 - val_acc: 0.8208\n",
      "Epoch 114/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3953 - acc: 0.8214 - val_loss: 0.4238 - val_acc: 0.8227\n",
      "Epoch 115/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3953 - acc: 0.8217 - val_loss: 0.4238 - val_acc: 0.8208\n",
      "Epoch 116/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3950 - acc: 0.8210 - val_loss: 0.4244 - val_acc: 0.8189\n",
      "Epoch 117/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3949 - acc: 0.8219 - val_loss: 0.4236 - val_acc: 0.8208\n",
      "Epoch 118/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3948 - acc: 0.8214 - val_loss: 0.4236 - val_acc: 0.8218\n",
      "Epoch 119/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3947 - acc: 0.8207 - val_loss: 0.4238 - val_acc: 0.8218\n",
      "Epoch 120/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3945 - acc: 0.8227 - val_loss: 0.4246 - val_acc: 0.8179\n",
      "Epoch 121/200\n",
      "4150/4150 [==============================] - 0s 10us/sample - loss: 0.3945 - acc: 0.8205 - val_loss: 0.4235 - val_acc: 0.8208\n",
      "Epoch 122/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3945 - acc: 0.8217 - val_loss: 0.4236 - val_acc: 0.8208\n",
      "Epoch 123/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3943 - acc: 0.8222 - val_loss: 0.4234 - val_acc: 0.8208\n",
      "Epoch 124/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3942 - acc: 0.8202 - val_loss: 0.4235 - val_acc: 0.8208\n",
      "Epoch 125/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3941 - acc: 0.8210 - val_loss: 0.4234 - val_acc: 0.8208\n",
      "Epoch 126/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3940 - acc: 0.8205 - val_loss: 0.4236 - val_acc: 0.8227\n",
      "Epoch 127/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3940 - acc: 0.8205 - val_loss: 0.4234 - val_acc: 0.8227\n",
      "Epoch 128/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3938 - acc: 0.8198 - val_loss: 0.4232 - val_acc: 0.8208\n",
      "Epoch 129/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3938 - acc: 0.8207 - val_loss: 0.4234 - val_acc: 0.8227\n",
      "Epoch 130/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3937 - acc: 0.8214 - val_loss: 0.4233 - val_acc: 0.8218\n",
      "Epoch 131/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3936 - acc: 0.8217 - val_loss: 0.4230 - val_acc: 0.8218\n",
      "Epoch 132/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3934 - acc: 0.8193 - val_loss: 0.4228 - val_acc: 0.8237\n",
      "Epoch 133/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3937 - acc: 0.8210 - val_loss: 0.4228 - val_acc: 0.8227\n",
      "Epoch 134/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3934 - acc: 0.8219 - val_loss: 0.4227 - val_acc: 0.8208\n",
      "Epoch 135/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3932 - acc: 0.8214 - val_loss: 0.4226 - val_acc: 0.8208\n",
      "Epoch 136/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3933 - acc: 0.8224 - val_loss: 0.4230 - val_acc: 0.8218\n",
      "Epoch 137/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3931 - acc: 0.8202 - val_loss: 0.4225 - val_acc: 0.8208\n",
      "Epoch 138/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3931 - acc: 0.8210 - val_loss: 0.4227 - val_acc: 0.8227\n",
      "Epoch 139/200\n",
      "4150/4150 [==============================] - 0s 10us/sample - loss: 0.3931 - acc: 0.8210 - val_loss: 0.4225 - val_acc: 0.8218\n",
      "Epoch 140/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3928 - acc: 0.8219 - val_loss: 0.4225 - val_acc: 0.8208\n",
      "Epoch 141/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3931 - acc: 0.8210 - val_loss: 0.4225 - val_acc: 0.8227\n",
      "Epoch 142/200\n",
      "4150/4150 [==============================] - 0s 10us/sample - loss: 0.3929 - acc: 0.8205 - val_loss: 0.4223 - val_acc: 0.8218\n",
      "Epoch 143/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3926 - acc: 0.8229 - val_loss: 0.4224 - val_acc: 0.8218\n",
      "Epoch 144/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3926 - acc: 0.8214 - val_loss: 0.4222 - val_acc: 0.8218\n",
      "Epoch 145/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3927 - acc: 0.8217 - val_loss: 0.4220 - val_acc: 0.8218\n",
      "Epoch 146/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3925 - acc: 0.8212 - val_loss: 0.4219 - val_acc: 0.8227\n",
      "Epoch 147/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3925 - acc: 0.8219 - val_loss: 0.4220 - val_acc: 0.8237\n",
      "Epoch 148/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3924 - acc: 0.8214 - val_loss: 0.4220 - val_acc: 0.8237\n",
      "Epoch 149/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3924 - acc: 0.8224 - val_loss: 0.4222 - val_acc: 0.8227\n",
      "Epoch 150/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3922 - acc: 0.8217 - val_loss: 0.4220 - val_acc: 0.8227\n",
      "Epoch 151/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3922 - acc: 0.8217 - val_loss: 0.4220 - val_acc: 0.8227\n",
      "Epoch 152/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3921 - acc: 0.8222 - val_loss: 0.4219 - val_acc: 0.8218\n",
      "Epoch 153/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3920 - acc: 0.8217 - val_loss: 0.4219 - val_acc: 0.8227\n",
      "Epoch 154/200\n",
      "4150/4150 [==============================] - 0s 10us/sample - loss: 0.3921 - acc: 0.8219 - val_loss: 0.4219 - val_acc: 0.8227\n",
      "Epoch 155/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3919 - acc: 0.8222 - val_loss: 0.4218 - val_acc: 0.8227\n",
      "Epoch 156/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3919 - acc: 0.8239 - val_loss: 0.4218 - val_acc: 0.8227\n",
      "Epoch 157/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3918 - acc: 0.8236 - val_loss: 0.4218 - val_acc: 0.8237\n",
      "Epoch 158/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3918 - acc: 0.8217 - val_loss: 0.4218 - val_acc: 0.8237\n",
      "Epoch 159/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3917 - acc: 0.8210 - val_loss: 0.4219 - val_acc: 0.8218\n",
      "Epoch 160/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3916 - acc: 0.8222 - val_loss: 0.4223 - val_acc: 0.8237\n",
      "Epoch 161/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3914 - acc: 0.8222 - val_loss: 0.4216 - val_acc: 0.8247\n",
      "Epoch 162/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3915 - acc: 0.8229 - val_loss: 0.4216 - val_acc: 0.8247\n",
      "Epoch 163/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3914 - acc: 0.8234 - val_loss: 0.4219 - val_acc: 0.8208\n",
      "Epoch 164/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3913 - acc: 0.8212 - val_loss: 0.4216 - val_acc: 0.8247\n",
      "Epoch 165/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3913 - acc: 0.8234 - val_loss: 0.4217 - val_acc: 0.8227\n",
      "Epoch 166/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3911 - acc: 0.8234 - val_loss: 0.4217 - val_acc: 0.8208\n",
      "Epoch 167/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3913 - acc: 0.8227 - val_loss: 0.4216 - val_acc: 0.8218\n",
      "Epoch 168/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3910 - acc: 0.8231 - val_loss: 0.4220 - val_acc: 0.8237\n",
      "Epoch 169/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3910 - acc: 0.8231 - val_loss: 0.4215 - val_acc: 0.8247\n",
      "Epoch 170/200\n",
      "4150/4150 [==============================] - 0s 10us/sample - loss: 0.3911 - acc: 0.8246 - val_loss: 0.4215 - val_acc: 0.8247\n",
      "Epoch 171/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3909 - acc: 0.8239 - val_loss: 0.4216 - val_acc: 0.8247\n",
      "Epoch 172/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3908 - acc: 0.8248 - val_loss: 0.4215 - val_acc: 0.8256\n",
      "Epoch 173/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3908 - acc: 0.8246 - val_loss: 0.4215 - val_acc: 0.8237\n",
      "Epoch 174/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3908 - acc: 0.8227 - val_loss: 0.4215 - val_acc: 0.8218\n",
      "Epoch 175/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3907 - acc: 0.8236 - val_loss: 0.4216 - val_acc: 0.8227\n",
      "Epoch 176/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3906 - acc: 0.8251 - val_loss: 0.4214 - val_acc: 0.8256\n",
      "Epoch 177/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3905 - acc: 0.8234 - val_loss: 0.4216 - val_acc: 0.8218\n",
      "Epoch 178/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3905 - acc: 0.8234 - val_loss: 0.4214 - val_acc: 0.8227\n",
      "Epoch 179/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3904 - acc: 0.8236 - val_loss: 0.4213 - val_acc: 0.8247\n",
      "Epoch 180/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3904 - acc: 0.8229 - val_loss: 0.4213 - val_acc: 0.8256\n",
      "Epoch 181/200\n",
      "4150/4150 [==============================] - 0s 10us/sample - loss: 0.3903 - acc: 0.8231 - val_loss: 0.4213 - val_acc: 0.8247\n",
      "Epoch 182/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3903 - acc: 0.8241 - val_loss: 0.4212 - val_acc: 0.8256\n",
      "Epoch 183/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3903 - acc: 0.8236 - val_loss: 0.4212 - val_acc: 0.8285\n",
      "Epoch 184/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3902 - acc: 0.8229 - val_loss: 0.4211 - val_acc: 0.8247\n",
      "Epoch 185/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3902 - acc: 0.8239 - val_loss: 0.4210 - val_acc: 0.8247\n",
      "Epoch 186/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3899 - acc: 0.8229 - val_loss: 0.4213 - val_acc: 0.8227\n",
      "Epoch 187/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3899 - acc: 0.8229 - val_loss: 0.4210 - val_acc: 0.8237\n",
      "Epoch 188/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3899 - acc: 0.8227 - val_loss: 0.4211 - val_acc: 0.8218\n",
      "Epoch 189/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3898 - acc: 0.8246 - val_loss: 0.4208 - val_acc: 0.8256\n",
      "Epoch 190/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3898 - acc: 0.8229 - val_loss: 0.4212 - val_acc: 0.8227\n",
      "Epoch 191/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3898 - acc: 0.8239 - val_loss: 0.4209 - val_acc: 0.8227\n",
      "Epoch 192/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3896 - acc: 0.8243 - val_loss: 0.4211 - val_acc: 0.8227\n",
      "Epoch 193/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3897 - acc: 0.8234 - val_loss: 0.4207 - val_acc: 0.8256\n",
      "Epoch 194/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3895 - acc: 0.8243 - val_loss: 0.4206 - val_acc: 0.8295\n",
      "Epoch 195/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3895 - acc: 0.8248 - val_loss: 0.4208 - val_acc: 0.8247\n",
      "Epoch 196/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3895 - acc: 0.8236 - val_loss: 0.4210 - val_acc: 0.8227\n",
      "Epoch 197/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3894 - acc: 0.8236 - val_loss: 0.4206 - val_acc: 0.8256\n",
      "Epoch 198/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3893 - acc: 0.8239 - val_loss: 0.4211 - val_acc: 0.8227\n",
      "Epoch 199/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3895 - acc: 0.8246 - val_loss: 0.4207 - val_acc: 0.8256\n",
      "Epoch 200/200\n",
      "4150/4150 [==============================] - 0s 9us/sample - loss: 0.3892 - acc: 0.8246 - val_loss: 0.4205 - val_acc: 0.8276\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_n, y_train_n, epochs=200, batch_size=128, validation_data=(X_test_n, y_test_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_n = model.predict(X_test_n)\n",
    "#Converting predictions to label\n",
    "pred_n = list()\n",
    "for i in range(len(y_pred_n)):\n",
    "    pred_n.append(np.argmax(y_pred_n[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is: 82.7552986512524\n"
     ]
    }
   ],
   "source": [
    "#Converting one hot encoded test label to label\n",
    "test = list()\n",
    "for i in range(len(y_test_n)):\n",
    "    test.append(np.argmax(y_test_n[i]))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "a = accuracy_score(pred_n,test)\n",
    "print('Accuracy is:', a*100)\n",
    "\n",
    "\n",
    "#Scores from independent testruns (used for report)\n",
    "\n",
    "#Accuracy is: 80.0785083415113\n",
    "#Accuracy is: 80.5691854759568\n",
    "#Accuracy is: 79.78410206084396"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1) # set the vertical range to [0-1]\n",
    "plt.title(\"Learning Curves\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Python3]",
   "language": "python",
   "name": "conda-env-Python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
